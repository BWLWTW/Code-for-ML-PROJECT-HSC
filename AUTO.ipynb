{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfcc4e5b-9e8a-41d7-833d-9c0d6bda0cef",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f24f54-ae70-460a-be8c-13724240b380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "# import ML related libraries\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from bayes_opt import BayesianOptimization\n",
    "# import plotting related libraries\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5913b6f-6210-4c65-ab12-9a06f8d6eb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SetUp\n",
    "datapathway=r\"C:\\Users\\wingt\\OneDrive\\Desktop\\DataForIPML\\dataset_1a_db2.csv\"\n",
    "input_column_list=[1,2,3,4,5]\n",
    "output_column_list=[6] #column of ystart\n",
    "yname='Thermo-couple'      # name of the ultimate output array (HSCP value)\n",
    "yparameter='Near or Far'       #position here but it will be what is the parameter to be tuned (HSCP_name)\n",
    "xcolumn=['heat', 'speed', 'ra','rl','rv'] #name of inputs\n",
    "ycolumn=['Near Field Thermo-Couple'] #name of outputs (HSCP_name)\n",
    "optimizer_search_list=['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "activation_list1=['relu',LeakyReLU(alpha=0.3),'hard_sigmoid','elu','sigmoid','softmax']\n",
    "train_test_split_test_size=0.2\n",
    "validation_split=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b9e405-21c9-448d-840c-d91ab062b096",
   "metadata": {},
   "source": [
    "### Get Plot\n",
    "It is a function plotting the actual simulation result and the prediction result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f1dbb1-a89b-4729-9a5a-1304e83edd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot(oringin_data, predict_data, i):\n",
    "    '''\n",
    "    Plot target outputs against predicted outputs\n",
    "    inputs:\n",
    "        oringin_data: target outputs\n",
    "        predict_data: predicted outputs\n",
    "        i: plot index\n",
    "        root: root for saving figure\n",
    "    '''\n",
    "    root = r'ANN_results/BD/test/test--' + str(i) + '.jpg'\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    x = y_label_new\n",
    "    oringin_data = oringin_data \n",
    "    predict_data = predict_data \n",
    "    p1 = ax.plot(x,oringin_data.ravel(),'r--', label = 'Target stress')\n",
    "    p2 = ax.plot(x,predict_data.ravel(),'g--',label = 'Predict stress')\n",
    "    ax.set_title(\"Test-Set\" + str(i))\n",
    "    # ax.set_xticks(x)\n",
    "    ax.set_ylabel('Logitudinal stress (MPa)')\n",
    "    ax.set_xlabel('Distance from top surface Z(mm)')\n",
    "    \n",
    "    ax.xaxis.set_major_locator(plt.MultipleLocator(1))\n",
    "    ax.yaxis.set_tick_params(direction='out')\n",
    "\n",
    "    ax2 = plt.twinx()\n",
    "    difference = predict_data.ravel() - oringin_data.ravel()\n",
    "    difference=np.array(list(map(lambda x,y:x/y,difference,oringin_data.ravel())))\n",
    "\n",
    "\n",
    "    legend_elements = [Line2D([0], [0], color='red', lw=2, label='Simulation result'),\n",
    "                       Line2D([0], [0], color='green', lw=2, label='ANN prediction')\n",
    "                      ]\n",
    "\n",
    "    ax.legend(handles=legend_elements, loc='best')\n",
    "    plt.savefig(root)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35487277-42de-4f51-96d9-e442b84e55d0",
   "metadata": {},
   "source": [
    "### Function of tuning activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98b65e3-ae89-435b-af42-5735d0a1b1a9",
   "metadata": {},
   "source": [
    "### Optimizer and activation function tuning function\n",
    "a function to tune the hyperparameter of the ANN machine-> optimizer\n",
    "model used is from KerasRegressor\n",
    "Used gridsearch cross validation\n",
    "printing the best optimizer name and the score of this machine\n",
    "printing the mean_test_score, std_test_score, parameter for all the optimizer tested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60193e0-0d01-4b42-be77-8e605e8d7149",
   "metadata": {},
   "source": [
    "### function for creating a model for tuning optimiser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b25972-ff6a-480a-8333-82e6c0bd99e3",
   "metadata": {},
   "source": [
    "### Neural Network training function for Bayesian Optimisation\n",
    "use a function for defning the machine name and parameters for the machine\n",
    "use KerasRegressor to build the machine with specified hyperparameters\n",
    "use processed training input and output (will define function to make them later) for training the model\n",
    "history is the name of the model\n",
    "return a scoe showing cross validation mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd070c15-5a69-4813-902d-46aa50c8a8ea",
   "metadata": {},
   "source": [
    "### Other hyperparameters tuning function\n",
    "a function tuning the other hyperparameter, including number of hidden nodes, learning rate, batch size,\n",
    "set number of epochs to 1000\n",
    "still use GridSearch CV and print the same thing as step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0de5226-6576-4d7e-a1ac-6a107ecacd7b",
   "metadata": {},
   "source": [
    "### function for creating a model for tuning other hyper parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a220b9-eb7f-4b52-b372-a4d173b44752",
   "metadata": {},
   "source": [
    "### Plot_history\n",
    "plot learning curve\n",
    "make learning history(generated later after building a model) a dataframe and insert a column called epoch in it\n",
    "plot MSE against epoch\n",
    "plot val_mse (should be validation mse) against no of epoch (validation error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d66632a-f4ca-415d-88b8-a403aaf91988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    '''\n",
    "    Plot learning curve using NN training history info\n",
    "    '''\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.xlabel('Epoch',fontsize=20)\n",
    "    plt.ylabel('Mean Square Error [$MPG^2$]',fontsize=20)\n",
    "    plt.plot(hist['epoch'], hist['mse'],\n",
    "            label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mse'],\n",
    "            label = 'Val Error')\n",
    "\n",
    "    plt.ylim([0,10*10**-4])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3960f30b-0024-433a-b949-e115c73310e0",
   "metadata": {},
   "source": [
    "### import data + preprocessing(select the suitable columns)\n",
    "import the data using pd.read_csv\n",
    "only get columns required\n",
    "assign column names\n",
    "get y data for training as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "383156d4-0b1b-4e58-a1a2-04050456de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import(csv_file_name,input_column_list,output_column_list):\n",
    "    '''\n",
    "    used to import dataset and split training and test dataset\n",
    "    csv_file_name is the dateset root\n",
    "    reture traing and test datasets\n",
    "    '''\n",
    "    raw_data = pd.read_csv(csv_file_name,header=None).dropna()\n",
    "    x = raw_data.iloc[:,input_column_list].astype(float)\n",
    "    y = raw_data.iloc[:,output_column_list].astype(float)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efea17f-28d9-4604-85fa-fb28389f159f",
   "metadata": {},
   "source": [
    "### function for creating a model for all tuned hyperparameter(actual model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3fc473-f9e8-41bb-bef7-9f5f5551103e",
   "metadata": {},
   "source": [
    "### assign column names to data set \n",
    "can see only one column of y here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aa92f38-e177-4227-a397-b9edc4145bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_melt(x, y,xcolumn,ycolumn,yparameter,yname):\n",
    "    '''\n",
    "    Add position as input\n",
    "    input:\n",
    "        x: old input \n",
    "        y: old output\n",
    "    output:\n",
    "        x_new: new input \n",
    "        y_new: new output\n",
    "    '''\n",
    "    y_label_str = [str(x) for x in ycolumn] # make a list of string of y_label_new\n",
    "    dataset = pd.concat([x, y],axis=1, ignore_index=True)\n",
    "    col_names = xcolumn + y_label_str\n",
    "    dataset.columns = col_names\n",
    "    dataset = dataset.melt(id_vars=xcolumn, \n",
    "        var_name=yparameter, \n",
    "        value_name=yname) #for given case, select which HSP to be found\n",
    "    x_new = dataset.iloc[:, 0:(len(xcolumn)+1)]\n",
    "    y_new = dataset.iloc[:, (len(xcolumn)+1)]\n",
    "    print('DATASET')\n",
    "    print(dataset)\n",
    "    return x_new, y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256cf4b0-f4b4-436f-9fb6-7c104aad0a55",
   "metadata": {},
   "source": [
    "### define mean square error function MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd031e64-35a7-4714-91ef-af04c4cb7dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(testY, predicY):\n",
    "    '''\n",
    "    Get MSE fun\n",
    "    '''\n",
    "    MSE=np.sum(np.power((testY - predicY),2))/testY.shape[1]/testY.shape[0]\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c530b6-af40-49e7-8a66-fc18e24d4bf6",
   "metadata": {},
   "source": [
    "### Define a function getting number of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f04c15b5-d56e-41f5-a848-4241b0527302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_N_output(Y_train):\n",
    "    '''\n",
    "    Get the number of outputs\n",
    "    '''\n",
    "    if Y_train.ndim == 1:\n",
    "        N_outputs = 1\n",
    "    else:\n",
    "        N_outputs = Y_train.shape[1]\n",
    "    return N_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08708d5c-00d0-42ab-96fd-a8538a9a8119",
   "metadata": {},
   "source": [
    "### Prepocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "272701b5-e0a1-4e41-a3b8-0d50ec6e04b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(model_type, x, y,train_test_split_test_size,xcolumn,ycolumn,yparameter,yname):\n",
    "    '''\n",
    "    Data preprocessing (Uniformly spaced sampling, normalisation, train test split)\n",
    "    inputs:\n",
    "        model_type: 'ANN1' the first architecture (3 inputs and 21 outputs)\n",
    "                    'ANN2' the second architecture (4 inputs and 1 output)        \n",
    "        x: a dataframe of inputs of the whole dataset\n",
    "        y: a dataframe of outputs of the whole dataset\n",
    "    outputs:\n",
    "        model_type: 'ANN1' the first architecture (3 inputs and 21 outputs)\n",
    "                    'ANN2' the second architecture (4 inputs and 1 output)\n",
    "        Proc_X_train: Processed Training input\n",
    "        Proc_Y_train: Processed Training output\n",
    "        Proc_X_test: Processed Test input\n",
    "        Y_test: Test output\n",
    "    '''\n",
    "    # Split dataset\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(x,y,test_size=train_test_split_test_size, random_state=3)\n",
    "    X_train=pd.DataFrame(X_train[:].values)\n",
    "    X_test =pd.DataFrame(X_test[:].values)\n",
    "    Y_train=pd.DataFrame(Y_train[:].values)\n",
    "    Y_test=pd.DataFrame(Y_test[:].values)\n",
    "    # data reconstruction\n",
    "    if 'ANN2' in model_type:\n",
    "        X_train, Y_train = data_melt(X_train, Y_train,xcolumn,ycolumn,yparameter,yname)\n",
    "        X_test, Y_test_1 = data_melt(X_test, Y_test,xcolumn,ycolumn,yparameter,yname)\n",
    "\n",
    "    # Normalization\n",
    "    global scaler_X, scaler_Y\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_Y = StandardScaler()\n",
    "    scaled_train_X = scaler_X.fit_transform(X_train.to_numpy())\n",
    "    scaled_test_X = scaler_X.transform(X_test)\n",
    "\n",
    "    if Y_train.ndim == 1:\n",
    "      Y_train = np.array(Y_train).reshape(-1,1)#column array\n",
    "    scaled_train_Y = scaler_Y.fit_transform(Y_train)\n",
    "    Proc_X_train = scaled_train_X\n",
    "    Proc_Y_train = scaled_train_Y\n",
    "    Proc_X_test = scaled_test_X\n",
    "\n",
    "    return model_type, Proc_X_train, Proc_Y_train, Proc_X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc516a76-61b1-41dd-8ac2-4a233df90024",
   "metadata": {},
   "source": [
    "### Get Result function\n",
    "build a model based on preprocessed data and tuned hyperparameter\n",
    "output the model, predicted scalar transformed y, predicted y in 21 columns, history of fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16200cb-6212-474d-a2fb-be7d67b9a95f",
   "metadata": {},
   "source": [
    "### fix random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cf2a92d-d8c3-4a8c-880b-6cb97d04439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_tensorflow(seed):\n",
    "    '''\n",
    "    Fix ramdom seed\n",
    "    '''\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa94d0c-d4f3-4993-b24c-f0777935c519",
   "metadata": {},
   "source": [
    "### actual import and train test split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccb063f-cf9f-427c-ac63-3dfa18387281",
   "metadata": {},
   "source": [
    "### Optimizer and activation function Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe4a886f-9fde-4b32-9623-e3ccb51f7871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_optimizer_ACT(optimizer_search_list,activation_list1,optimizer_tuning_number_of_full_update=200,\n",
    "                       optimizer_tuning_number_sample_used_in_one_training=10):\n",
    "    # callbacks = [\n",
    "    #     EarlyStopping(monitor='mse', patience=100, verbose=0),\n",
    "    # ]\n",
    "    model = KerasRegressor(build_fn=create_model, nb_epoch=optimizer_tuning_number_of_full_update, batch_size=optimizer_tuning_number_sample_used_in_one_training, verbose=0) \n",
    "    optimizer = optimizer_search_list # 200 hidden nodes\n",
    "    param_grid = dict(optimizer=optimizer,activation1=activation_list1) \n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1,verbose=10)\n",
    "    grid_result = grid.fit(Proc_X_train, Proc_Y_train)\n",
    "    global BEST_ACT_1,BEST_OPT\n",
    "    BEST_ACT_1=grid.best_params_['activation1']\n",
    "    BEST_OPT=grid.best_params_['optimizer']\n",
    "    print('tuned activation function for hidden layer:')\n",
    "    print('BEST_ACT_1:',BEST_ACT_1)\n",
    "    print('tuned optimizer')\n",
    "    print('BEST_OPT:',BEST_OPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0fd0870-1d0b-4b17-846d-8e54132f641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam',activation1='relu'):\n",
    "    '''\n",
    "    Build a NN\n",
    "    inputs:\n",
    "        N_hidden_nodes: number of neurons\n",
    "        input_dim: number of inputs\n",
    "        N_outputs: number of outputs\n",
    "        l_rate: learning rate\n",
    "        Batch_size: Batch size\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        history: training history\n",
    "    '''\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(200, activation=activation1, input_shape=(Proc_X_train.shape[1],)),\n",
    "        keras.layers.Dense(get_N_output(Proc_Y_train),activation='linear')\n",
    "    ])\n",
    "    model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mse'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a2ff88-ab80-4970-92cf-918ce37f5762",
   "metadata": {},
   "source": [
    "### function of tuning other parameter (timed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "774a677e-defd-4192-9399-18d1bc863af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hype_T_dict(BEST_OPT,BEST_ACT_1,optimizer_search_list):\n",
    "    SGD_TD= {'momentum':[0,0.2,0.4,0.6,0.8],\n",
    "         'nesterov':[True,False]}\n",
    "    RMSprop_TD={'rho':[0.001,0.01,0.1,0.5,0.9],\n",
    "            'momentum':[0,0.2,0.4,0.6,0.8],\n",
    "            'epsilon':[1e-9,1e-8,1e-7,1e-6,1e-5]}\n",
    "    Adagrad_TD={'initial_accumulator_value':[0.001,0.01,0.1,0.5,0.9],\n",
    "            'epsilon':[1e-9,1e-8,1e-7,1e-6,1e-5]}\n",
    "    Adadelta_TD={'rho':[0.001,0.01,0.1,0.5,0.9],\n",
    "             'epsilon':[1e-9,1e-8,1e-7,1e-6,1e-5]}\n",
    "    Adam_TD={'beta_1':[0.001,0.01,0.1,0.5,0.9],\n",
    "         'beta_2':[0.001,0.01,0.1,0.5,0.9,0.99,0.999],\n",
    "         'epsilon':[1e-9,1e-8,1e-7,1e-6,1e-5]}\n",
    "    Adamax_TD=Adam_TD\n",
    "    Nadam_TD=Adam_TD\n",
    "    TD=[SGD_TD,RMSprop_TD,Adagrad_TD,Adadelta_TD,Adam_TD,Adamax_TD,Nadam_TD]\n",
    "    hype_search_dict={'learning_rate':[0.001,0.01,0.1,0.2],\n",
    "                      'N_hidden_nodes':[100,500,1000,1500,2000],\n",
    "                      'batch_size':[1,8,16,31], \n",
    "                      'nb_epoch':[1000,2000,3000],\n",
    "                     'BEST_ACT_1':[BEST_ACT_1]}\n",
    "    for i, opt in enumerate(optimizer_search_list):\n",
    "        if BEST_OPT==opt:\n",
    "            hype_search_dict.update(TD[i])\n",
    "    return hype_search_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2adc9b3c-559f-433f-91bf-72262261a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_2_SGD(N_hidden_nodes,learning_rate,momentum, nesterov,BEST_ACT_1):\n",
    "    '''\n",
    "    Build a NN\n",
    "    inputs:\n",
    "        N_hidden_nodes: number of neurons\n",
    "        input_dim: number of inputs\n",
    "        N_outputs: number of outputs\n",
    "        l_rate: learning rate\n",
    "        Batch_size: Batch size\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        history: training history\n",
    "    '''\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(N_hidden_nodes, activation=BEST_ACT_1, input_shape=(Proc_X_train.shape[1],)),\n",
    "        keras.layers.Dense(get_N_output(Proc_Y_train),activation='linear')\n",
    "    ])\n",
    "    model.compile(loss='mse',\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=learning_rate,momentum=momentum,nesterov=nesterov),\n",
    "                metrics=['mse'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def create_model_2_RMSprop(N_hidden_nodes,learning_rate,rho,momentum, epsilon,BEST_ACT_1):\n",
    "    '''\n",
    "    Build a NN\n",
    "    inputs:\n",
    "        N_hidden_nodes: number of neurons\n",
    "        input_dim: number of inputs\n",
    "        N_outputs: number of outputs\n",
    "        l_rate: learning rate\n",
    "        Batch_size: Batch size\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        history: training history\n",
    "    '''\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(N_hidden_nodes, activation=BEST_ACT_1, input_shape=(Proc_X_train.shape[1],)),\n",
    "        keras.layers.Dense(get_N_output(Proc_Y_train),activation='linear')\n",
    "    ])\n",
    "    model.compile(loss='mse',\n",
    "                optimizer=keras.optimizers.RMSprop(learning_rate=learning_rate,rho=rho,momentum=momentum,epsilon=epsilon),\n",
    "                metrics=['mse'])\n",
    "    model.summary()\n",
    "    return model\n",
    "    \n",
    "def create_model_2_Adagrad(N_hidden_nodes,learning_rate,initial_accumulator_value, epsilon,BEST_ACT_1):\n",
    "    '''\n",
    "    Build a NN\n",
    "    inputs:\n",
    "        N_hidden_nodes: number of neurons\n",
    "        input_dim: number of inputs\n",
    "        N_outputs: number of outputs\n",
    "        l_rate: learning rate\n",
    "        Batch_size: Batch size\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        history: training history\n",
    "    '''\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(N_hidden_nodes, activation=BEST_ACT_1, input_shape=(Proc_X_train.shape[1],)),\n",
    "        keras.layers.Dense(get_N_output(Proc_Y_train),activation='linear')\n",
    "    ])\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=keras.optimizers.Adagrad(learning_rate=learning_rate,initial_accumulator_value=initial_accumulator_value,epsilon=epsilon),\n",
    "                  metrics=['mse'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def create_model_2_Adadelta(N_hidden_nodes,learning_rate,rho, epsilon,BEST_ACT_1):\n",
    "    '''\n",
    "    Build a NN\n",
    "    inputs:\n",
    "        N_hidden_nodes: number of neurons\n",
    "        input_dim: number of inputs\n",
    "        N_outputs: number of outputs\n",
    "        l_rate: learning rate\n",
    "        Batch_size: Batch size\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        history: training history\n",
    "    '''\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(N_hidden_nodes, activation=BEST_ACT_1, input_shape=(Proc_X_train.shape[1],)),\n",
    "        keras.layers.Dense(get_N_output(Proc_Y_train),activation='linear')\n",
    "    ])\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=keras.optimizers.Adadelta(learning_rate=learning_rate,rho=rho,epsilon=epsilon),\n",
    "                  metrics=['mse'])\n",
    "    model.summary()\n",
    "    return model\n",
    "def create_model_2_Adam(N_hidden_nodes,learning_rate,beta_1,beta_2, epsilon,BEST_ACT_1):\n",
    "    '''\n",
    "    Build a NN\n",
    "    inputs:\n",
    "        N_hidden_nodes: number of neurons\n",
    "        input_dim: number of inputs\n",
    "        N_outputs: number of outputs\n",
    "        l_rate: learning rate\n",
    "        Batch_size: Batch size\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        history: training history\n",
    "    '''\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(N_hidden_nodes, activation=BEST_ACT_1, input_shape=(Proc_X_train.shape[1],)),\n",
    "        keras.layers.Dense(get_N_output(Proc_Y_train),activation='linear')\n",
    "    ])\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=Keras.optimizers.Adam(learning_rate=learning_rate,beta_1=beta_1,beta_2=beta_2,epsilon=epsilon),\n",
    "                  metrics=['mse'])\n",
    "    model.summary()\n",
    "    return model\n",
    "def create_model_2_Adamax(N_hidden_nodes,learning_rate,beta_1,beta_2, epsilon,BEST_ACT_1):\n",
    "    '''\n",
    "    Build a NN\n",
    "    inputs:\n",
    "        N_hidden_nodes: number of neurons\n",
    "        input_dim: number of inputs\n",
    "        N_outputs: number of outputs\n",
    "        l_rate: learning rate\n",
    "        Batch_size: Batch size\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        history: training history\n",
    "    '''\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(N_hidden_nodes, activation=BEST_ACT_1, input_shape=(Proc_X_train.shape[1],)),\n",
    "        keras.layers.Dense(get_N_output(Proc_Y_train),activation='linear')\n",
    "    ])\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=keras.optimizers.Adamax(learning_rate=learning_rate,beta_1=beta_1,beta_2=beta_2,epsilon=epsilon),\n",
    "                  metrics=['mse'])\n",
    "    model.summary()\n",
    "    return model\n",
    "def create_model_2_Nadam(N_hidden_nodes,learning_rate,beta_1,beta_2, epsilon,BEST_ACT_1):\n",
    "    '''\n",
    "    Build a NN\n",
    "    inputs:\n",
    "        N_hidden_nodes: number of neurons\n",
    "        input_dim: number of inputs\n",
    "        N_outputs: number of outputs\n",
    "        l_rate: learning rate\n",
    "        Batch_size: Batch size\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        history: training history\n",
    "    '''\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(N_hidden_nodes, activation=BEST_ACT_1, input_shape=(Proc_X_train.shape[1],)),\n",
    "        keras.layers.Dense(get_N_output(Proc_Y_train),activation='linear')\n",
    "    ])\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=keras.optimizers.Nadam(learning_rate=learning_rate,beta_1=beta_1,beta_2=beta_2,epsilon=epsilon),\n",
    "                  metrics=['mse'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c3c19638-ea6c-402d-86af-b234a58bd806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_other_para(BEST_OPT,BEST_ACT_1,optimizer_search_list):\n",
    "    if BEST_OPT=='SGD':\n",
    "        model = KerasRegressor(build_fn=create_model_2_SGD,verbose=2)\n",
    "    if BEST_OPT=='RMSprop':\n",
    "        model = KerasRegressor(build_fn=create_model_2_RMSprop,verbose=2)\n",
    "    if BEST_OPT=='Adagrad':\n",
    "        model = KerasRegressor(build_fn=create_model_2_Adagrad,verbose=2)\n",
    "    if BEST_OPT=='Adadelta':\n",
    "        model = KerasRegressor(build_fn=create_model_2_Adadelta,verbose=2)\n",
    "    if BEST_OPT=='Adam':\n",
    "        model = KerasRegressor(build_fn=create_model_2_Adam,verbose=2)\n",
    "    if BEST_OPT=='Adamax':\n",
    "        model = KerasRegressor(build_fn=create_model_2_Adamax,verbose=2)\n",
    "    if BEST_OPT=='Nadam':\n",
    "        model = KerasRegressor(build_fn=create_model_2_Nadam,verbose=2)\n",
    "    param_grid = get_hype_T_dict(BEST_OPT,BEST_ACT_1,optimizer_search_list)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=10,verbose=3)\n",
    "    grid_result = grid.fit(Proc_X_train, Proc_Y_train)\n",
    "    global OTHERTUNEDDICT\n",
    "    OTHERTUNEDDICT=grid.best_params_\n",
    "    print('tuned hyperparameters:')\n",
    "    B_N_hidden_nodes=grid.best_params_['N_hidden_nodes']\n",
    "    B_learning_rate=grid.best_params_['learning_rate']\n",
    "    B_Batch_size=grid.best_params_['batch_size']\n",
    "    B_epochs=grid.best_params_['nb_epoch']\n",
    "    print('B_N_hidden_nodes:',B_N_hidden_nodes)\n",
    "    print('B_learning_rate:',B_learning_rate)\n",
    "    print('B_Batch_size:',B_Batch_size)\n",
    "    print('B_epochs:',B_epochs)\n",
    "    if BEST_OPT=='SGD':\n",
    "        B_momentum_SGD=grid.best_params_['momentum']\n",
    "        B_nesterov_SGD=grid.best_params_['nesterov']\n",
    "        print('B_momentum_SGD:',B_momentum_SGD)\n",
    "        print('B_nesterov_SGD:',B_nesterov_SGD)\n",
    "    if BEST_OPT=='RMSprop':\n",
    "        B_rho_RMSprop=grid.best_params_['rho']\n",
    "        B_momentum_RMSprop=grid.best_params_['momentum']\n",
    "        B_epsilon_RMSprop=grid.best_params_['epsilon']\n",
    "        print('B_rho_RMSprop:',B_rho_RMSprop)\n",
    "        print('B_momentum_RMSprop:',B_momentum_RMSprop)\n",
    "        print('B_epsilon_RMSprop:',B_epsilon_RMSprop)\n",
    "    if BEST_OPT=='Adagrad':\n",
    "        B_initial_accumulator_value_Adagrad=grid.best_params_['initial_accumulator_value']\n",
    "        B_epsilon_Adagrad=grid.best_params_['epsilon']\n",
    "        print('B_initial_accumulator_value_Adagrad:',B_initial_accumulator_value_Adagrad)\n",
    "        print('B_epsilon_Adagrad:',B_epsilon_Adagrad)\n",
    "    if BEST_OPT=='Adadelta':\n",
    "        B_rho_Adadelta=grid.best_params_['rho']\n",
    "        B_epsilon_Adadelta=grid.best_params_['epsilon']\n",
    "        print('B_rho_Adadelta:',B_rho_Adadelta)\n",
    "        print('B_epsilon_Adadelta:',B_epsilon_Adadelta)\n",
    "    if BEST_OPT =='Adam':\n",
    "        B_beta_1_Adam=grid.best_params_['beta_1']\n",
    "        B_beta_2_Adam=grid.best_params_['beta_2']\n",
    "        B_epsilon_Adam=grid.best_params_['epsilon']\n",
    "        print('B_beta_1_Adam:',B_beta_1_Adam)\n",
    "        print('B_beta_2_Adam:',B_beta_2_Adam)\n",
    "        print('B_epsilon_Adam:',B_epsilon_Adam)\n",
    "    if BEST_OPT =='Adamax':\n",
    "        B_beta_1_Adamax=grid.best_params_['beta_1']\n",
    "        B_beta_2_Adamax=grid.best_params_['beta_2']\n",
    "        B_epsilon_Adamax=grid.best_params_['epsilon']\n",
    "        print('B_beta_1_Adamax:',B_beta_1_Adamax)\n",
    "        print('B_beta_2_Adamax:',B_beta_2_Adamax)\n",
    "        print('B_epsilon_Adamax:',B_epsilon_Adamax)\n",
    "    if BEST_OPT =='Nadam':\n",
    "        B_beta_1_Nadam=grid.best_params_['beta_1']\n",
    "        B_beta_2_Nadam=grid.best_params_['beta_2']\n",
    "        B_epsilon_Nadam=grid.best_params_['epsilon']\n",
    "        print('B_beta_1_Nadam:',B_beta_1_Nadam)\n",
    "        print('B_beta_2_Nadam:',B_beta_2_Nadam)\n",
    "        print('B_epsilon_Nadam:',B_epsilon_Nadam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e880454b-cb7d-4bc7-b7c2-5e71d3c4abe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_SGD(N_hidden_nodes,learning_rate,momentum, nesterov,Batch_size, Epochs,BEST_ACT_1,validation_split):\n",
    "    '''\n",
    "    Build a NN\n",
    "    inputs:\n",
    "        N_hidden_nodes: number of neurons\n",
    "        input_dim: number of inputs\n",
    "        N_outputs: number of outputs\n",
    "        l_rate: learning rate\n",
    "        Batch_size: Batch size\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        history: training history\n",
    "    '''\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_mse', patience=100, verbose=1),\n",
    "        ModelCheckpoint('best_model.h5', monitor='val_mse', save_best_only=True, verbose=0)\n",
    "    ]\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(N_hidden_nodes, activation=BEST_ACT_1, input_shape=(Proc_X_train.shape[1],)),\n",
    "        keras.layers.Dense(get_N_output(Proc_Y_train),activation='linear')\n",
    "    ])\n",
    "    model.compile(loss='mse',\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=learning_rate,momentum=momentum,nesterov=nesterov),\n",
    "                metrics=['mse'])\n",
    "    model.summary()\n",
    "    history = model.fit(Proc_X_train, Proc_Y_train, batch_size=Batch_size, epochs=Epochs, \n",
    "                        verbose=1, validation_split=validation_split, callbacks=callbacks)\n",
    "    return model, history\n",
    "    \n",
    "def build_model_RMSprop(N_hidden_nodes,learning_rate,rho,momentum,epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split):\n",
    "    '''\n",
    "    Build a NN\n",
    "    inputs:\n",
    "        N_hidden_nodes: number of neurons\n",
    "        input_dim: number of inputs\n",
    "        N_outputs: number of outputs\n",
    "        l_rate: learning rate\n",
    "        Batch_size: Batch size\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        history: training history\n",
    "    '''\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_mse', patience=100, verbose=1),\n",
    "        ModelCheckpoint('best_model.h5', monitor='val_mse', save_best_only=True, verbose=0)\n",
    "    ]\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(N_hidden_nodes, activation=BEST_ACT_1, input_shape=(Proc_X_train.shape[1],)),\n",
    "        keras.layers.Dense(get_N_output(Proc_Y_train),activation='linear')\n",
    "    ])\n",
    "    model.compile(loss='mse',\n",
    "                optimizer=keras.optimizers.RMSprop(learning_rate=learning_rate,rho=rho,momentum=momentum,epsilon=epsilon),\n",
    "                metrics=['mse'])\n",
    "    model.summary()\n",
    "    history = model.fit(Proc_X_train, Proc_Y_train, batch_size=Batch_size, epochs=Epochs, \n",
    "                        verbose=1, validation_split=validation_split, callbacks=callbacks)\n",
    "    return model, history\n",
    "def build_model_Adagrad(N_hidden_nodes,learning_rate,initial_accumulator_value, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split):\n",
    "    '''\n",
    "    Build a NN\n",
    "    inputs:\n",
    "        N_hidden_nodes: number of neurons\n",
    "        input_dim: number of inputs\n",
    "        N_outputs: number of outputs\n",
    "        l_rate: learning rate\n",
    "        Batch_size: Batch size\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        history: training history\n",
    "    '''\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_mse', patience=100, verbose=1),\n",
    "        ModelCheckpoint('best_model.h5', monitor='val_mse', save_best_only=True, verbose=0)\n",
    "    ]\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(N_hidden_nodes, activation=BEST_ACT_1, input_shape=(Proc_X_train.shape[1],)),\n",
    "        keras.layers.Dense(get_N_output(Proc_Y_train),activation='linear')\n",
    "    ])\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=keras.optimizers.Adagrad(learning_rate=learning_rate,initial_accumulator_value=initial_accumulator_value,epsilon=epsilon),\n",
    "                  metrics=['mse'])\n",
    "    model.summary()\n",
    "    history = model.fit(Proc_X_train, Proc_Y_train, batch_size=Batch_size, epochs=Epochs, \n",
    "                        verbose=1, validation_split=validation_split, callbacks=callbacks)\n",
    "    return model, history\n",
    "def build_model_Adadelta(N_hidden_nodes,learning_rate,rho, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split):\n",
    "    '''\n",
    "    Build a NN\n",
    "    inputs:\n",
    "        N_hidden_nodes: number of neurons\n",
    "        input_dim: number of inputs\n",
    "        N_outputs: number of outputs\n",
    "        l_rate: learning rate\n",
    "        Batch_size: Batch size\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        history: training history\n",
    "    '''\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_mse', patience=100, verbose=1),\n",
    "        ModelCheckpoint('best_model.h5', monitor='val_mse', save_best_only=True, verbose=0)\n",
    "    ]\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(N_hidden_nodes, activation=BEST_ACT_1, input_shape=(Proc_X_train.shape[1],)),\n",
    "        keras.layers.Dense(get_N_output(Proc_Y_train),activation='linear')\n",
    "    ])\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=keras.optimizers.Adadelta(learning_rate=learning_rate,rho=rho,epsilon=epsilon),\n",
    "                  metrics=['mse'])\n",
    "    model.summary()\n",
    "    history = model.fit(Proc_X_train, Proc_Y_train, batch_size=Batch_size, epochs=Epochs, \n",
    "                        verbose=1, validation_split=validation_split, callbacks=callbacks)\n",
    "    return model, history\n",
    "def build_model_Adam(N_hidden_nodes,learning_rate,beta_1,beta_2, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split):\n",
    "    '''\n",
    "    Build a NN\n",
    "    inputs:\n",
    "        N_hidden_nodes: number of neurons\n",
    "        input_dim: number of inputs\n",
    "        N_outputs: number of outputs\n",
    "        l_rate: learning rate\n",
    "        Batch_size: Batch size\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        history: training history\n",
    "    '''\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_mse', patience=100, verbose=1),\n",
    "        ModelCheckpoint('best_model.h5', monitor='val_mse', save_best_only=True, verbose=0)\n",
    "    ]\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(N_hidden_nodes, activation=BEST_ACT_1, input_shape=(Proc_X_train.shape[1],)),\n",
    "        keras.layers.Dense(get_N_output(Proc_Y_train),activation='linear')\n",
    "    ])\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=Keras.optimizers.Adam(learning_rate=learning_rate,beta_1=beta_1,beta_2=beta_2,epsilon=epsilon),\n",
    "                  metrics=['mse'])\n",
    "    model.summary()\n",
    "    history = model.fit(Proc_X_train, Proc_Y_train, batch_size=Batch_size, epochs=Epochs, \n",
    "                        verbose=1, validation_split=validation_split, callbacks=callbacks)\n",
    "    return model, history\n",
    "def build_model_Adamax(N_hidden_nodes,learning_rate,beta_1,beta_2, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split):\n",
    "    '''\n",
    "    Build a NN\n",
    "    inputs:\n",
    "        N_hidden_nodes: number of neurons\n",
    "        input_dim: number of inputs\n",
    "        N_outputs: number of outputs\n",
    "        l_rate: learning rate\n",
    "        Batch_size: Batch size\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        history: training history\n",
    "    '''\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_mse', patience=100, verbose=1),\n",
    "        ModelCheckpoint('best_model.h5', monitor='val_mse', save_best_only=True, verbose=0)\n",
    "    ]\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(N_hidden_nodes, activation=BEST_ACT_1, input_shape=(Proc_X_train.shape[1],)),\n",
    "        keras.layers.Dense(get_N_output(Proc_Y_train),activation='linear')\n",
    "    ])\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=Keras.optimizers.Adamax(learning_rate=learning_rate,beta_1=beta_1,beta_2=beta_2,epsilon=epsilon),\n",
    "                  metrics=['mse'])\n",
    "    model.summary()\n",
    "    history = model.fit(Proc_X_train, Proc_Y_train, batch_size=Batch_size, epochs=Epochs, \n",
    "                        verbose=1, validation_split=validation_split, callbacks=callbacks)\n",
    "    return model, history\n",
    "def build_model_NAdam(N_hidden_nodes,learning_rate,beta_1,beta_2, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split):\n",
    "    '''\n",
    "    Build a NN\n",
    "    inputs:\n",
    "        N_hidden_nodes: number of neurons\n",
    "        input_dim: number of inputs\n",
    "        N_outputs: number of outputs\n",
    "        l_rate: learning rate\n",
    "        Batch_size: Batch size\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        history: training history\n",
    "    '''\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_mse', patience=100, verbose=1),\n",
    "        ModelCheckpoint('best_model.h5', monitor='val_mse', save_best_only=True, verbose=0)\n",
    "    ]\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(N_hidden_nodes, activation=BEST_ACT_1, input_shape=(Proc_X_train.shape[1],)),\n",
    "        keras.layers.Dense(get_N_output(Proc_Y_train),activation='linear')\n",
    "    ])\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=Keras.optimizers.Nadam(learning_rate=learning_rate,beta_1=beta_1,beta_2=beta_2,epsilon=epsilon),\n",
    "                  metrics=['mse'])\n",
    "    model.summary()\n",
    "    history = model.fit(Proc_X_train, Proc_Y_train, batch_size=Batch_size, epochs=Epochs, \n",
    "                        verbose=1, validation_split=validation_split, callbacks=callbacks)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa6656fb-1ba1-4c13-99c3-e138824b1469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_SGD(model_type, Proc_X_train, Proc_Y_train, Proc_X_test, N_hidden_nodes,learning_rate,momentum, nesterov,Batch_size, Epochs,BEST_ACT_1,validation_split):\n",
    "    '''\n",
    "    Get the trained model, prediction results, and NN training history\n",
    "    inputs:\n",
    "        model_type: 'ANN1' the first architecture (3 inputs and 21 outputs)\n",
    "                    'ANN2' the second architecture (4 inputs and 1 output)\n",
    "        Proc_X_train: Processed Training input\n",
    "        Proc_Y_train: Processed Training output\n",
    "        Proc_X_test: Processed Test input\n",
    "        N_neurons: Number of Neurons in the hidden layer\n",
    "        l_rate: Learning rate\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        predict_test: predicted results\n",
    "        history: training history\n",
    "    '''\n",
    "    #build model\n",
    "    model, history = build_model_SGD(N_hidden_nodes,learning_rate,momentum, nesterov,Batch_size, Epochs,BEST_ACT_1,validation_split)\n",
    "    # Predict\n",
    "    \n",
    "    predict_test_scal = model.predict(Proc_X_test)\n",
    "    if 'ANN2' in model_type:\n",
    "      predict_test_scal = np.reshape(predict_test_scal, (get_N_output(Y_test), -1)).T\n",
    "    \n",
    "    predict_test = scaler_Y.inverse_transform(predict_test_scal)\n",
    "    return  model, predict_test_scal, predict_test, history\n",
    "\n",
    "\n",
    "def get_result_RMSprop(model_type, Proc_X_train, Proc_Y_train, Proc_X_test,N_hidden_nodes,learning_rate,rho,momentum, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split):\n",
    "    '''\n",
    "    Get the trained model, prediction results, and NN training history\n",
    "    inputs:\n",
    "        model_type: 'ANN1' the first architecture (3 inputs and 21 outputs)\n",
    "                    'ANN2' the second architecture (4 inputs and 1 output)\n",
    "        Proc_X_train: Processed Training input\n",
    "        Proc_Y_train: Processed Training output\n",
    "        Proc_X_test: Processed Test input\n",
    "        N_neurons: Number of Neurons in the hidden layer\n",
    "        l_rate: Learning rate\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        predict_test: predicted results\n",
    "        history: training history\n",
    "    '''\n",
    "    #build model\n",
    "    model, history = build_model_RMSprop(N_hidden_nodes,learning_rate,rho,momentum, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split)\n",
    "    # Predict\n",
    "    \n",
    "    predict_test_scal = model.predict(Proc_X_test)\n",
    "    if 'ANN2' in model_type:\n",
    "      predict_test_scal = np.reshape(predict_test_scal, (get_N_output(Y_test), -1)).T\n",
    "    \n",
    "    predict_test = scaler_Y.inverse_transform(predict_test_scal)\n",
    "    return  model, predict_test_scal, predict_test, history\n",
    "\n",
    "def get_result_Adagrad(model_type, Proc_X_train, Proc_Y_train, Proc_X_test,N_hidden_nodes,learning_rate,initial_accumulator_value, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split):\n",
    "    '''\n",
    "    Get the trained model, prediction results, and NN training history\n",
    "    inputs:\n",
    "        model_type: 'ANN1' the first architecture (3 inputs and 21 outputs)\n",
    "                    'ANN2' the second architecture (4 inputs and 1 output)\n",
    "        Proc_X_train: Processed Training input\n",
    "        Proc_Y_train: Processed Training output\n",
    "        Proc_X_test: Processed Test input\n",
    "        N_neurons: Number of Neurons in the hidden layer\n",
    "        l_rate: Learning rate\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        predict_test: predicted results\n",
    "        history: training history\n",
    "    '''\n",
    "    #build model\n",
    "    model, history = build_model_Adagrad(N_hidden_nodes,learning_rate,initial_accumulator_value, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split)\n",
    "    # Predict\n",
    "    \n",
    "    predict_test_scal = model.predict(Proc_X_test)\n",
    "    if 'ANN2' in model_type:\n",
    "      predict_test_scal = np.reshape(predict_test_scal, (get_N_output(Y_test), -1)).T\n",
    "    \n",
    "    predict_test = scaler_Y.inverse_transform(predict_test_scal)\n",
    "    return  model, predict_test_scal, predict_test, history\n",
    "\n",
    "def get_result_Adadelta(model_type, Proc_X_train, Proc_Y_train, Proc_X_test,N_hidden_nodes,learning_rate,rho, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split):\n",
    "    '''\n",
    "    Get the trained model, prediction results, and NN training history\n",
    "    inputs:\n",
    "        model_type: 'ANN1' the first architecture (3 inputs and 21 outputs)\n",
    "                    'ANN2' the second architecture (4 inputs and 1 output)\n",
    "        Proc_X_train: Processed Training input\n",
    "        Proc_Y_train: Processed Training output\n",
    "        Proc_X_test: Processed Test input\n",
    "        N_neurons: Number of Neurons in the hidden layer\n",
    "        l_rate: Learning rate\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        predict_test: predicted results\n",
    "        history: training history\n",
    "    '''\n",
    "    #build model\n",
    "    model, history = build_model_Adadelta(N_hidden_nodes,learning_rate,rho, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split)\n",
    "    # Predict\n",
    "    \n",
    "    predict_test_scal = model.predict(Proc_X_test)\n",
    "    if 'ANN2' in model_type:\n",
    "      predict_test_scal = np.reshape(predict_test_scal, (get_N_output(Y_test), -1)).T\n",
    "    \n",
    "    predict_test = scaler_Y.inverse_transform(predict_test_scal)\n",
    "    return  model, predict_test_scal, predict_test, history\n",
    "\n",
    "def get_result_Adam(model_type, Proc_X_train, Proc_Y_train, Proc_X_test,N_hidden_nodes,learning_rate,beta_1,beta_2, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split):\n",
    "    '''\n",
    "    Get the trained model, prediction results, and NN training history\n",
    "    inputs:\n",
    "        model_type: 'ANN1' the first architecture (3 inputs and 21 outputs)\n",
    "                    'ANN2' the second architecture (4 inputs and 1 output)\n",
    "        Proc_X_train: Processed Training input\n",
    "        Proc_Y_train: Processed Training output\n",
    "        Proc_X_test: Processed Test input\n",
    "        N_neurons: Number of Neurons in the hidden layer\n",
    "        l_rate: Learning rate\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        predict_test: predicted results\n",
    "        history: training history\n",
    "    '''\n",
    "    #build model\n",
    "    model, history = build_model_Adam(N_hidden_nodes,learning_rate,beta_1,beta_2, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split)\n",
    "    # Predict\n",
    "    \n",
    "    predict_test_scal = model.predict(Proc_X_test)\n",
    "    if 'ANN2' in model_type:\n",
    "      predict_test_scal = np.reshape(predict_test_scal, (get_N_output(Y_test), -1)).T\n",
    "    \n",
    "    predict_test = scaler_Y.inverse_transform(predict_test_scal)\n",
    "    return  model, predict_test_scal, predict_test, history\n",
    "\n",
    "def get_result_Adamax(model_type, Proc_X_train, Proc_Y_train, Proc_X_test,N_hidden_nodes,learning_rate,beta_1,beta_2, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split):\n",
    "    '''\n",
    "    Get the trained model, prediction results, and NN training history\n",
    "    inputs:\n",
    "        model_type: 'ANN1' the first architecture (3 inputs and 21 outputs)\n",
    "                    'ANN2' the second architecture (4 inputs and 1 output)\n",
    "        Proc_X_train: Processed Training input\n",
    "        Proc_Y_train: Processed Training output\n",
    "        Proc_X_test: Processed Test input\n",
    "        N_neurons: Number of Neurons in the hidden layer\n",
    "        l_rate: Learning rate\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        predict_test: predicted results\n",
    "        history: training history\n",
    "    '''\n",
    "    #build model\n",
    "    model, history = build_model_Adamax(N_hidden_nodes,learning_rate,beta_1,beta_2, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split)\n",
    "    # Predict\n",
    "    \n",
    "    predict_test_scal = model.predict(Proc_X_test)\n",
    "    if 'ANN2' in model_type:\n",
    "      predict_test_scal = np.reshape(predict_test_scal, (get_N_output(Y_test), -1)).T\n",
    "    \n",
    "    predict_test = scaler_Y.inverse_transform(predict_test_scal)\n",
    "    return  model, predict_test_scal, predict_test, history\n",
    "\n",
    "def get_result_NAdam(model_type, Proc_X_train, Proc_Y_train, Proc_X_test,N_hidden_nodes,learning_rate,beta_1,beta_2, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split):\n",
    "    '''\n",
    "    Get the trained model, prediction results, and NN training history\n",
    "    inputs:\n",
    "        model_type: 'ANN1' the first architecture (3 inputs and 21 outputs)\n",
    "                    'ANN2' the second architecture (4 inputs and 1 output)\n",
    "        Proc_X_train: Processed Training input\n",
    "        Proc_Y_train: Processed Training output\n",
    "        Proc_X_test: Processed Test input\n",
    "        N_neurons: Number of Neurons in the hidden layer\n",
    "        l_rate: Learning rate\n",
    "    outputs:\n",
    "        model: Trained model\n",
    "        predict_test: predicted results\n",
    "        history: training history\n",
    "    '''\n",
    "    #build model\n",
    "    model, history = build_model_NAdam(N_hidden_nodes,learning_rate,beta_1,beta_2, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split)\n",
    "    # Predict\n",
    "    \n",
    "    predict_test_scal = model.predict(Proc_X_test)\n",
    "    if 'ANN2' in model_type:\n",
    "      predict_test_scal = np.reshape(predict_test_scal, (get_N_output(Y_test), -1)).T\n",
    "    \n",
    "    predict_test = scaler_Y.inverse_transform(predict_test_scal)\n",
    "    return  model, predict_test_scal, predict_test, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0f9728d3-f295-4c15-a0bc-260fc485fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ActualTraining(OTHERTUNEDDICT,BEST_OPT,BEST_ACT_1,validation_split):\n",
    "    print('INFORMATION:')\n",
    "    print('Used otpimizer:',BEST_OPT)\n",
    "    print('Used hidden nodes activation function:',BEST_ACT_1)\n",
    "    D=OTHERTUNEDDICT\n",
    "    N_hidden_nodes=D['N_hidden_nodes']\n",
    "    learning_rate=D['learning_rate']\n",
    "    Batch_size=D['batch_size']\n",
    "    Epochs=D['nb_epoch']\n",
    "    print('Used N_hidden_nodes:',N_hidden_nodes)\n",
    "    print('Used learning_rate:',learning_rate)\n",
    "    print('Used Batch_size:',Batch_size)\n",
    "    print('Used Epochs:',Epochs)\n",
    "    if BEST_OPT=='SGD':\n",
    "        momentum=D['momentum']\n",
    "        nesterov=D['nesterov']\n",
    "        print('Used momentum:',momentum)\n",
    "        print('Used nesterov:',nesterov)\n",
    "        ANN, predict_test_scal,predict_test, history = get_result_SGD(model_type, Proc_X_train, Proc_Y_train, Proc_X_test, N_hidden_nodes,learning_rate,momentum, nesterov,Batch_size, Epochs,BEST_ACT_1,validation_split)\n",
    "    if BEST_OPT=='RMSprop':\n",
    "        rho=D['rho']\n",
    "        momentum=D['momentum']\n",
    "        epsilon=D['epsilon']\n",
    "        print('Used rho:',rho)\n",
    "        print('Used momentum:',momentum)\n",
    "        print('Used epsilon:',epsilon)\n",
    "        ANN, predict_test_scal,predict_test, history =get_result_RMSprop(model_type, Proc_X_train, Proc_Y_train, Proc_X_test,N_hidden_nodes,learning_rate,rho,momentum, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split)\n",
    "    if BEST_OPT=='Adagrad':\n",
    "        initial_accumulator_value=D['initial_accumulator_value']\n",
    "        epsilon=D['epsilon']\n",
    "        print('Used initial_accumulator_value:',initial_accumulator_value)\n",
    "        print('Used epsilon:',epsilon)\n",
    "        ANN, predict_test_scal,predict_test, history =get_result_Adagrad(model_type, Proc_X_train, Proc_Y_train, Proc_X_test,N_hidden_nodes,learning_rate,initial_accumulator_value, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split)\n",
    "    if BEST_OPT=='Adadelta':\n",
    "        rho=D['rho']\n",
    "        epsilon=D['epsilon']\n",
    "        print('Used rho:',rho)\n",
    "        print('Used epsilon:',epsilon)\n",
    "        ANN, predict_test_scal,predict_test, history =get_result_Adadelta(model_type, Proc_X_train, Proc_Y_train, Proc_X_test,N_hidden_nodes,learning_rate,rho, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split)\n",
    "    if BEST_OPT=='Adam':\n",
    "        beta_1=D['beta_1']\n",
    "        beta_2=D['beta_2']\n",
    "        epsilon=D['epsilon']\n",
    "        print('Used beta_1:',beta_1)\n",
    "        print('Used beta_2:',beta_2)\n",
    "        print('Used epsilon:',epsilon)\n",
    "        ANN, predict_test_scal,predict_test, history =get_result_Adam(model_type, Proc_X_train, Proc_Y_train, Proc_X_test,N_hidden_nodes,learning_rate,beta_1,beta_2, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split)\n",
    "    if BEST_OPT=='Adamax':\n",
    "        beta_1=D['beta_1']\n",
    "        beta_2=D['beta_2']\n",
    "        epsilon=D['epsilon']\n",
    "        print('Used beta_1:',beta_1)\n",
    "        print('Used beta_2:',beta_2)\n",
    "        print('Used epsilon:',epsilon)\n",
    "        ANN, predict_test_scal,predict_test, history =get_result_Adamax(model_type, Proc_X_train, Proc_Y_train, Proc_X_test,N_hidden_nodes,learning_rate,beta_1,beta_2, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split)\n",
    "    if BEST_OPT=='Nadam':\n",
    "        beta_1=D['beta_1']\n",
    "        beta_2=D['beta_2']\n",
    "        epsilon=D['epsilon']\n",
    "        print('Used beta_1:',beta_1)\n",
    "        print('Used beta_2:',beta_2)\n",
    "        print('Used epsilon:',epsilon)\n",
    "        ANN, predict_test_scal,predict_test, history =get_result_NAdam(model_type, Proc_X_train, Proc_Y_train, Proc_X_test,N_hidden_nodes,learning_rate,beta_1,beta_2, epsilon,Batch_size, Epochs,BEST_ACT_1,validation_split)\n",
    "    return ANN, predict_test_scal,predict_test, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43f0424-c30a-40cf-a7f5-56a3248b6b39",
   "metadata": {},
   "source": [
    "### The actual implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8350cc6-c3f8-45b0-9e48-195797e89d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SetUp\n",
    "datapathway=r\"C:\\Users\\wingt\\OneDrive\\Desktop\\DataForIPML\\dataset_1a_db2.csv\"\n",
    "input_column_list=[1,2,3,4,5]\n",
    "output_column_list=[6] #column of ystart\n",
    "yname='Thermo-couple'      # name of the ultimate output array (HSCP value)\n",
    "yparameter='Near or Far'       #position here but it will be what is the parameter to be tuned (HSCP_name)\n",
    "xcolumn=['heat', 'speed', 'ra','rl','rv'] #name of inputs\n",
    "ycolumn=['Near Field Thermo-Couple'] #name of outputs (HSCP_name)\n",
    "optimizer_search_list=['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "activation_list1=['relu',LeakyReLU(alpha=0.3),'hard_sigmoid','elu','sigmoid','softmax']\n",
    "train_test_split_test_size=0.2\n",
    "validation_split=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "928bdbd5-8e10-4fad-b04a-3c3121ab853b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 200)               1200      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 1,401\n",
      "Trainable params: 1,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "tuned activation function for hidden layer:\n",
      "BEST_ACT_1: elu\n",
      "tuned optimizer\n",
      "BEST_OPT: SGD\n"
     ]
    }
   ],
   "source": [
    "# Fix ramdom seed\n",
    "warnings.filterwarnings('ignore')\n",
    "seed_tensorflow(42)\n",
    "# Import dataset\n",
    "x,y=data_import(datapathway,input_column_list,output_column_list)\n",
    "# Pre-processing\n",
    "model_type, Proc_X_train, Proc_Y_train, Proc_X_test, Y_test = pre_processing('ANN1', x, y,train_test_split_test_size,xcolumn,ycolumn,yparameter,yname)\n",
    "#Tuning\n",
    "OPT_ACT=tune_optimizer_ACT(optimizer_search_list,activation_list1,\n",
    "                           optimizer_tuning_number_of_full_update=200,\n",
    "                       optimizer_tuning_number_sample_used_in_one_training=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b27f4e45-d40a-41ba-9194-4b475cd25b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2400 candidates, totalling 12000 fits\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 100)               600       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 701\n",
      "Trainable params: 701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "583/583 - 0s - loss: 0.0918 - mse: 0.0918\n",
      "tuned hyperparameters:\n",
      "B_N_hidden_nodes: 100\n",
      "B_learning_rate: 0.001\n",
      "B_Batch_size: 1\n",
      "B_epochs: 1000\n",
      "B_momentum_SGD: 0\n",
      "B_nesterov_SGD: True\n"
     ]
    }
   ],
   "source": [
    "tune_other_para(BEST_OPT=BEST_OPT,BEST_ACT_1=BEST_ACT_1, optimizer_search_list=optimizer_search_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7cdd7cda-fa84-49d3-b28c-a0cdc30ea021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFORMATION:\n",
      "Used otpimizer: SGD\n",
      "Used hidden nodes activation function: elu\n",
      "Used N_hidden_nodes: 100\n",
      "Used learning_rate: 0.001\n",
      "Used Batch_size: 1\n",
      "Used Epochs: 1000\n",
      "Used momentum: 0\n",
      "Used nesterov: True\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 100)               600       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 701\n",
      "Trainable params: 701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "524/524 [==============================] - 0s 621us/step - loss: 0.1464 - mse: 0.1464 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 2/1000\n",
      "524/524 [==============================] - 0s 602us/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 3/1000\n",
      "524/524 [==============================] - 0s 597us/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 4/1000\n",
      "524/524 [==============================] - 0s 568us/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 5/1000\n",
      "524/524 [==============================] - 0s 499us/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 6/1000\n",
      "524/524 [==============================] - 0s 405us/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 7/1000\n",
      "524/524 [==============================] - 0s 595us/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 8/1000\n",
      "524/524 [==============================] - 0s 592us/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 9/1000\n",
      "524/524 [==============================] - 0s 602us/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 10/1000\n",
      "524/524 [==============================] - 0s 419us/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 11/1000\n",
      "524/524 [==============================] - 0s 590us/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 12/1000\n",
      "524/524 [==============================] - 0s 488us/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 13/1000\n",
      "524/524 [==============================] - 0s 521us/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 14/1000\n",
      "524/524 [==============================] - 0s 492us/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 15/1000\n",
      "524/524 [==============================] - 0s 598us/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 16/1000\n",
      "524/524 [==============================] - 0s 597us/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 17/1000\n",
      "524/524 [==============================] - 0s 599us/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 18/1000\n",
      "524/524 [==============================] - 0s 608us/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 19/1000\n",
      "524/524 [==============================] - 0s 556us/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 20/1000\n",
      "524/524 [==============================] - 0s 647us/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 21/1000\n",
      "524/524 [==============================] - 0s 580us/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 22/1000\n",
      "524/524 [==============================] - 0s 596us/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 23/1000\n",
      "524/524 [==============================] - 0s 449us/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 24/1000\n",
      "524/524 [==============================] - 0s 482us/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 25/1000\n",
      "524/524 [==============================] - 0s 572us/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 26/1000\n",
      "524/524 [==============================] - 0s 597us/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 27/1000\n",
      "524/524 [==============================] - 0s 629us/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 28/1000\n",
      "524/524 [==============================] - 0s 548us/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 29/1000\n",
      "524/524 [==============================] - 0s 614us/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 30/1000\n",
      "524/524 [==============================] - 0s 396us/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 31/1000\n",
      "524/524 [==============================] - 0s 435us/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 32/1000\n",
      "524/524 [==============================] - 0s 599us/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 33/1000\n",
      "524/524 [==============================] - 0s 406us/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 34/1000\n",
      "524/524 [==============================] - 0s 492us/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 35/1000\n",
      "524/524 [==============================] - 0s 580us/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 36/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 37/1000\n",
      "524/524 [==============================] - 0s 398us/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 38/1000\n",
      "524/524 [==============================] - 0s 546us/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 39/1000\n",
      "524/524 [==============================] - 0s 607us/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 40/1000\n",
      "524/524 [==============================] - 0s 436us/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 41/1000\n",
      "524/524 [==============================] - 0s 592us/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 42/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 43/1000\n",
      "524/524 [==============================] - 0s 529us/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 44/1000\n",
      "524/524 [==============================] - 0s 609us/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 45/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 46/1000\n",
      "524/524 [==============================] - 0s 573us/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 47/1000\n",
      "524/524 [==============================] - 0s 575us/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 48/1000\n",
      "524/524 [==============================] - 0s 568us/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 49/1000\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 50/1000\n",
      "524/524 [==============================] - 0s 568us/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 51/1000\n",
      "524/524 [==============================] - 0s 593us/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 52/1000\n",
      "524/524 [==============================] - 0s 574us/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 53/1000\n",
      "524/524 [==============================] - 0s 342us/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 54/1000\n",
      "524/524 [==============================] - 0s 571us/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 55/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 56/1000\n",
      "524/524 [==============================] - 0s 569us/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 57/1000\n",
      "524/524 [==============================] - 0s 578us/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 58/1000\n",
      "524/524 [==============================] - 0s 567us/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 59/1000\n",
      "524/524 [==============================] - 0s 521us/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 60/1000\n",
      "524/524 [==============================] - 0s 555us/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 61/1000\n",
      "524/524 [==============================] - 0s 569us/step - loss: 9.8988e-04 - mse: 9.8988e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 62/1000\n",
      "524/524 [==============================] - 0s 398us/step - loss: 9.7382e-04 - mse: 9.7382e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 63/1000\n",
      "524/524 [==============================] - 0s 278us/step - loss: 9.5986e-04 - mse: 9.5986e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 64/1000\n",
      "524/524 [==============================] - 0s 586us/step - loss: 9.4403e-04 - mse: 9.4403e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 65/1000\n",
      "524/524 [==============================] - 0s 562us/step - loss: 9.2552e-04 - mse: 9.2552e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 66/1000\n",
      "524/524 [==============================] - 0s 425us/step - loss: 9.0659e-04 - mse: 9.0659e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 67/1000\n",
      "524/524 [==============================] - 0s 461us/step - loss: 8.9869e-04 - mse: 8.9869e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 68/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 8.7626e-04 - mse: 8.7626e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 69/1000\n",
      "524/524 [==============================] - 0s 569us/step - loss: 8.7498e-04 - mse: 8.7498e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 70/1000\n",
      "524/524 [==============================] - 0s 507us/step - loss: 8.5941e-04 - mse: 8.5941e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 71/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 8.4479e-04 - mse: 8.4479e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 72/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 8.2554e-04 - mse: 8.2554e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 73/1000\n",
      "524/524 [==============================] - 0s 454us/step - loss: 8.2416e-04 - mse: 8.2416e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 74/1000\n",
      "524/524 [==============================] - 0s 437us/step - loss: 8.1474e-04 - mse: 8.1474e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 75/1000\n",
      "524/524 [==============================] - 0s 331us/step - loss: 8.0310e-04 - mse: 8.0310e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 76/1000\n",
      "524/524 [==============================] - 0s 595us/step - loss: 7.8455e-04 - mse: 7.8455e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 77/1000\n",
      "524/524 [==============================] - 0s 628us/step - loss: 7.7499e-04 - mse: 7.7499e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 78/1000\n",
      "524/524 [==============================] - 0s 662us/step - loss: 7.7347e-04 - mse: 7.7347e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 79/1000\n",
      "524/524 [==============================] - 0s 589us/step - loss: 7.5976e-04 - mse: 7.5976e-04 - val_loss: 9.9707e-04 - val_mse: 9.9707e-04\n",
      "Epoch 80/1000\n",
      "524/524 [==============================] - 0s 684us/step - loss: 7.5385e-04 - mse: 7.5385e-04 - val_loss: 9.9147e-04 - val_mse: 9.9147e-04\n",
      "Epoch 81/1000\n",
      "524/524 [==============================] - 0s 569us/step - loss: 7.4127e-04 - mse: 7.4127e-04 - val_loss: 9.6688e-04 - val_mse: 9.6688e-04\n",
      "Epoch 82/1000\n",
      "524/524 [==============================] - 0s 509us/step - loss: 7.2933e-04 - mse: 7.2933e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 83/1000\n",
      "524/524 [==============================] - 0s 506us/step - loss: 7.3295e-04 - mse: 7.3295e-04 - val_loss: 9.8289e-04 - val_mse: 9.8289e-04\n",
      "Epoch 84/1000\n",
      "524/524 [==============================] - 0s 564us/step - loss: 7.2062e-04 - mse: 7.2062e-04 - val_loss: 9.7825e-04 - val_mse: 9.7825e-04\n",
      "Epoch 85/1000\n",
      "524/524 [==============================] - 0s 562us/step - loss: 7.0864e-04 - mse: 7.0864e-04 - val_loss: 9.5130e-04 - val_mse: 9.5130e-04\n",
      "Epoch 86/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 6.9930e-04 - mse: 6.9930e-04 - val_loss: 9.4867e-04 - val_mse: 9.4867e-04\n",
      "Epoch 87/1000\n",
      "524/524 [==============================] - 0s 519us/step - loss: 6.9109e-04 - mse: 6.9109e-04 - val_loss: 9.7621e-04 - val_mse: 9.7621e-04\n",
      "Epoch 88/1000\n",
      "524/524 [==============================] - 0s 547us/step - loss: 6.9569e-04 - mse: 6.9569e-04 - val_loss: 9.4594e-04 - val_mse: 9.4594e-04\n",
      "Epoch 89/1000\n",
      "524/524 [==============================] - 0s 447us/step - loss: 6.8008e-04 - mse: 6.8008e-04 - val_loss: 9.2173e-04 - val_mse: 9.2173e-04\n",
      "Epoch 90/1000\n",
      "524/524 [==============================] - 0s 539us/step - loss: 6.7304e-04 - mse: 6.7304e-04 - val_loss: 9.0468e-04 - val_mse: 9.0468e-04\n",
      "Epoch 91/1000\n",
      "524/524 [==============================] - 0s 582us/step - loss: 6.6541e-04 - mse: 6.6541e-04 - val_loss: 9.0789e-04 - val_mse: 9.0789e-04\n",
      "Epoch 92/1000\n",
      "524/524 [==============================] - 0s 542us/step - loss: 6.6644e-04 - mse: 6.6644e-04 - val_loss: 9.0367e-04 - val_mse: 9.0367e-04\n",
      "Epoch 93/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 6.5312e-04 - mse: 6.5312e-04 - val_loss: 9.2356e-04 - val_mse: 9.2356e-04\n",
      "Epoch 94/1000\n",
      "524/524 [==============================] - 0s 504us/step - loss: 6.5609e-04 - mse: 6.5609e-04 - val_loss: 9.0249e-04 - val_mse: 9.0249e-04\n",
      "Epoch 95/1000\n",
      "524/524 [==============================] - 0s 554us/step - loss: 6.4696e-04 - mse: 6.4696e-04 - val_loss: 9.0131e-04 - val_mse: 9.0131e-04\n",
      "Epoch 96/1000\n",
      "524/524 [==============================] - 0s 546us/step - loss: 6.3831e-04 - mse: 6.3831e-04 - val_loss: 9.1343e-04 - val_mse: 9.1343e-04\n",
      "Epoch 97/1000\n",
      "524/524 [==============================] - 0s 547us/step - loss: 6.3454e-04 - mse: 6.3454e-04 - val_loss: 8.6268e-04 - val_mse: 8.6268e-04\n",
      "Epoch 98/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 6.3103e-04 - mse: 6.3103e-04 - val_loss: 8.7901e-04 - val_mse: 8.7901e-04\n",
      "Epoch 99/1000\n",
      "524/524 [==============================] - 0s 545us/step - loss: 6.2193e-04 - mse: 6.2193e-04 - val_loss: 8.7671e-04 - val_mse: 8.7671e-04\n",
      "Epoch 100/1000\n",
      "524/524 [==============================] - 0s 551us/step - loss: 6.1872e-04 - mse: 6.1872e-04 - val_loss: 8.6484e-04 - val_mse: 8.6484e-04\n",
      "Epoch 101/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 6.1154e-04 - mse: 6.1154e-04 - val_loss: 8.8451e-04 - val_mse: 8.8451e-04\n",
      "Epoch 102/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 6.1316e-04 - mse: 6.1316e-04 - val_loss: 8.7097e-04 - val_mse: 8.7097e-04\n",
      "Epoch 103/1000\n",
      "524/524 [==============================] - 0s 588us/step - loss: 6.0800e-04 - mse: 6.0800e-04 - val_loss: 8.5637e-04 - val_mse: 8.5637e-04\n",
      "Epoch 104/1000\n",
      "524/524 [==============================] - 0s 529us/step - loss: 6.0312e-04 - mse: 6.0312e-04 - val_loss: 8.6098e-04 - val_mse: 8.6098e-04\n",
      "Epoch 105/1000\n",
      "524/524 [==============================] - 0s 556us/step - loss: 5.9617e-04 - mse: 5.9617e-04 - val_loss: 8.4363e-04 - val_mse: 8.4363e-04\n",
      "Epoch 106/1000\n",
      "524/524 [==============================] - 0s 545us/step - loss: 5.9449e-04 - mse: 5.9449e-04 - val_loss: 8.5994e-04 - val_mse: 8.5994e-04\n",
      "Epoch 107/1000\n",
      "524/524 [==============================] - 0s 480us/step - loss: 5.9122e-04 - mse: 5.9122e-04 - val_loss: 8.4480e-04 - val_mse: 8.4480e-04\n",
      "Epoch 108/1000\n",
      "524/524 [==============================] - 0s 473us/step - loss: 5.8406e-04 - mse: 5.8406e-04 - val_loss: 8.5005e-04 - val_mse: 8.5005e-04\n",
      "Epoch 109/1000\n",
      "524/524 [==============================] - 0s 569us/step - loss: 5.8005e-04 - mse: 5.8005e-04 - val_loss: 8.3097e-04 - val_mse: 8.3097e-04\n",
      "Epoch 110/1000\n",
      "524/524 [==============================] - 0s 538us/step - loss: 5.7979e-04 - mse: 5.7979e-04 - val_loss: 8.4239e-04 - val_mse: 8.4239e-04\n",
      "Epoch 111/1000\n",
      "524/524 [==============================] - 0s 495us/step - loss: 5.7667e-04 - mse: 5.7667e-04 - val_loss: 8.2935e-04 - val_mse: 8.2935e-04\n",
      "Epoch 112/1000\n",
      "524/524 [==============================] - 0s 558us/step - loss: 5.7324e-04 - mse: 5.7324e-04 - val_loss: 8.3417e-04 - val_mse: 8.3417e-04\n",
      "Epoch 113/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 5.6920e-04 - mse: 5.6920e-04 - val_loss: 8.2443e-04 - val_mse: 8.2443e-04\n",
      "Epoch 114/1000\n",
      "524/524 [==============================] - 0s 459us/step - loss: 5.6276e-04 - mse: 5.6276e-04 - val_loss: 8.2789e-04 - val_mse: 8.2789e-04\n",
      "Epoch 115/1000\n",
      "524/524 [==============================] - 0s 562us/step - loss: 5.5824e-04 - mse: 5.5824e-04 - val_loss: 8.4432e-04 - val_mse: 8.4432e-04\n",
      "Epoch 116/1000\n",
      "524/524 [==============================] - 0s 548us/step - loss: 5.5616e-04 - mse: 5.5616e-04 - val_loss: 8.1246e-04 - val_mse: 8.1246e-04\n",
      "Epoch 117/1000\n",
      "524/524 [==============================] - 0s 539us/step - loss: 5.5418e-04 - mse: 5.5418e-04 - val_loss: 8.3098e-04 - val_mse: 8.3098e-04\n",
      "Epoch 118/1000\n",
      "524/524 [==============================] - 0s 467us/step - loss: 5.5052e-04 - mse: 5.5052e-04 - val_loss: 8.2984e-04 - val_mse: 8.2984e-04\n",
      "Epoch 119/1000\n",
      "524/524 [==============================] - 0s 557us/step - loss: 5.4877e-04 - mse: 5.4877e-04 - val_loss: 8.0912e-04 - val_mse: 8.0912e-04\n",
      "Epoch 120/1000\n",
      "524/524 [==============================] - 0s 496us/step - loss: 5.4782e-04 - mse: 5.4782e-04 - val_loss: 8.0538e-04 - val_mse: 8.0538e-04\n",
      "Epoch 121/1000\n",
      "524/524 [==============================] - 0s 563us/step - loss: 5.4284e-04 - mse: 5.4284e-04 - val_loss: 8.0035e-04 - val_mse: 8.0035e-04\n",
      "Epoch 122/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 5.4051e-04 - mse: 5.4051e-04 - val_loss: 8.1121e-04 - val_mse: 8.1121e-04\n",
      "Epoch 123/1000\n",
      "524/524 [==============================] - 0s 559us/step - loss: 5.3774e-04 - mse: 5.3774e-04 - val_loss: 8.0250e-04 - val_mse: 8.0250e-04\n",
      "Epoch 124/1000\n",
      "524/524 [==============================] - 0s 459us/step - loss: 5.3344e-04 - mse: 5.3344e-04 - val_loss: 7.7735e-04 - val_mse: 7.7735e-04\n",
      "Epoch 125/1000\n",
      "524/524 [==============================] - 0s 441us/step - loss: 5.3216e-04 - mse: 5.3216e-04 - val_loss: 7.8115e-04 - val_mse: 7.8115e-04\n",
      "Epoch 126/1000\n",
      "524/524 [==============================] - 0s 488us/step - loss: 5.2984e-04 - mse: 5.2984e-04 - val_loss: 7.8118e-04 - val_mse: 7.8118e-04\n",
      "Epoch 127/1000\n",
      "524/524 [==============================] - 0s 485us/step - loss: 5.2688e-04 - mse: 5.2688e-04 - val_loss: 7.8427e-04 - val_mse: 7.8427e-04\n",
      "Epoch 128/1000\n",
      "524/524 [==============================] - 0s 545us/step - loss: 5.2247e-04 - mse: 5.2247e-04 - val_loss: 7.8686e-04 - val_mse: 7.8686e-04\n",
      "Epoch 129/1000\n",
      "524/524 [==============================] - 0s 535us/step - loss: 5.2157e-04 - mse: 5.2157e-04 - val_loss: 7.8177e-04 - val_mse: 7.8177e-04\n",
      "Epoch 130/1000\n",
      "524/524 [==============================] - 0s 553us/step - loss: 5.1927e-04 - mse: 5.1927e-04 - val_loss: 7.7573e-04 - val_mse: 7.7573e-04\n",
      "Epoch 131/1000\n",
      "524/524 [==============================] - 0s 565us/step - loss: 5.1352e-04 - mse: 5.1352e-04 - val_loss: 7.7489e-04 - val_mse: 7.7489e-04\n",
      "Epoch 132/1000\n",
      "524/524 [==============================] - 0s 586us/step - loss: 5.1374e-04 - mse: 5.1374e-04 - val_loss: 7.8172e-04 - val_mse: 7.8172e-04\n",
      "Epoch 133/1000\n",
      "524/524 [==============================] - 0s 607us/step - loss: 5.0779e-04 - mse: 5.0779e-04 - val_loss: 8.0032e-04 - val_mse: 8.0032e-04\n",
      "Epoch 134/1000\n",
      "524/524 [==============================] - 0s 582us/step - loss: 5.1305e-04 - mse: 5.1305e-04 - val_loss: 7.5936e-04 - val_mse: 7.5936e-04\n",
      "Epoch 135/1000\n",
      "524/524 [==============================] - 0s 602us/step - loss: 5.0715e-04 - mse: 5.0715e-04 - val_loss: 7.7457e-04 - val_mse: 7.7457e-04\n",
      "Epoch 136/1000\n",
      "524/524 [==============================] - 0s 581us/step - loss: 5.0150e-04 - mse: 5.0150e-04 - val_loss: 7.7422e-04 - val_mse: 7.7422e-04\n",
      "Epoch 137/1000\n",
      "524/524 [==============================] - 0s 579us/step - loss: 5.0237e-04 - mse: 5.0237e-04 - val_loss: 7.4856e-04 - val_mse: 7.4856e-04\n",
      "Epoch 138/1000\n",
      "524/524 [==============================] - 0s 573us/step - loss: 5.0052e-04 - mse: 5.0052e-04 - val_loss: 7.5778e-04 - val_mse: 7.5778e-04\n",
      "Epoch 139/1000\n",
      "524/524 [==============================] - 0s 560us/step - loss: 4.9705e-04 - mse: 4.9705e-04 - val_loss: 7.6837e-04 - val_mse: 7.6837e-04\n",
      "Epoch 140/1000\n",
      "524/524 [==============================] - 0s 592us/step - loss: 4.9554e-04 - mse: 4.9554e-04 - val_loss: 7.4561e-04 - val_mse: 7.4561e-04\n",
      "Epoch 141/1000\n",
      "524/524 [==============================] - 0s 563us/step - loss: 4.9371e-04 - mse: 4.9371e-04 - val_loss: 7.5211e-04 - val_mse: 7.5211e-04\n",
      "Epoch 142/1000\n",
      "524/524 [==============================] - 0s 584us/step - loss: 4.9280e-04 - mse: 4.9280e-04 - val_loss: 7.4394e-04 - val_mse: 7.4394e-04\n",
      "Epoch 143/1000\n",
      "524/524 [==============================] - 0s 558us/step - loss: 4.8778e-04 - mse: 4.8778e-04 - val_loss: 7.5053e-04 - val_mse: 7.5053e-04\n",
      "Epoch 144/1000\n",
      "524/524 [==============================] - 0s 577us/step - loss: 4.9046e-04 - mse: 4.9046e-04 - val_loss: 7.4901e-04 - val_mse: 7.4901e-04\n",
      "Epoch 145/1000\n",
      "524/524 [==============================] - 0s 564us/step - loss: 4.8849e-04 - mse: 4.8849e-04 - val_loss: 7.4174e-04 - val_mse: 7.4174e-04\n",
      "Epoch 146/1000\n",
      "524/524 [==============================] - 0s 583us/step - loss: 4.8594e-04 - mse: 4.8594e-04 - val_loss: 7.3455e-04 - val_mse: 7.3455e-04\n",
      "Epoch 147/1000\n",
      "524/524 [==============================] - 0s 594us/step - loss: 4.8157e-04 - mse: 4.8157e-04 - val_loss: 7.5301e-04 - val_mse: 7.5301e-04\n",
      "Epoch 148/1000\n",
      "524/524 [==============================] - 0s 581us/step - loss: 4.8258e-04 - mse: 4.8258e-04 - val_loss: 7.5164e-04 - val_mse: 7.5164e-04\n",
      "Epoch 149/1000\n",
      "524/524 [==============================] - 0s 587us/step - loss: 4.7767e-04 - mse: 4.7767e-04 - val_loss: 7.4432e-04 - val_mse: 7.4432e-04\n",
      "Epoch 150/1000\n",
      "524/524 [==============================] - 0s 562us/step - loss: 4.7525e-04 - mse: 4.7525e-04 - val_loss: 7.3815e-04 - val_mse: 7.3815e-04\n",
      "Epoch 151/1000\n",
      "524/524 [==============================] - 0s 575us/step - loss: 4.7681e-04 - mse: 4.7681e-04 - val_loss: 7.2743e-04 - val_mse: 7.2743e-04\n",
      "Epoch 152/1000\n",
      "524/524 [==============================] - 0s 568us/step - loss: 4.7495e-04 - mse: 4.7495e-04 - val_loss: 7.3691e-04 - val_mse: 7.3691e-04\n",
      "Epoch 153/1000\n",
      "524/524 [==============================] - 0s 568us/step - loss: 4.7291e-04 - mse: 4.7291e-04 - val_loss: 7.3536e-04 - val_mse: 7.3536e-04\n",
      "Epoch 154/1000\n",
      "524/524 [==============================] - 0s 583us/step - loss: 4.7192e-04 - mse: 4.7192e-04 - val_loss: 7.1965e-04 - val_mse: 7.1965e-04\n",
      "Epoch 155/1000\n",
      "524/524 [==============================] - 0s 562us/step - loss: 4.6960e-04 - mse: 4.6960e-04 - val_loss: 7.3666e-04 - val_mse: 7.3666e-04\n",
      "Epoch 156/1000\n",
      "524/524 [==============================] - 0s 529us/step - loss: 4.6747e-04 - mse: 4.6747e-04 - val_loss: 7.2172e-04 - val_mse: 7.2172e-04\n",
      "Epoch 157/1000\n",
      "524/524 [==============================] - 0s 564us/step - loss: 4.6635e-04 - mse: 4.6635e-04 - val_loss: 7.3580e-04 - val_mse: 7.3580e-04\n",
      "Epoch 158/1000\n",
      "524/524 [==============================] - 0s 558us/step - loss: 4.6456e-04 - mse: 4.6456e-04 - val_loss: 7.2060e-04 - val_mse: 7.2060e-04\n",
      "Epoch 159/1000\n",
      "524/524 [==============================] - 0s 575us/step - loss: 4.6279e-04 - mse: 4.6279e-04 - val_loss: 7.4504e-04 - val_mse: 7.4504e-04\n",
      "Epoch 160/1000\n",
      "524/524 [==============================] - 0s 556us/step - loss: 4.6006e-04 - mse: 4.6006e-04 - val_loss: 7.2521e-04 - val_mse: 7.2521e-04\n",
      "Epoch 161/1000\n",
      "524/524 [==============================] - 0s 592us/step - loss: 4.6214e-04 - mse: 4.6214e-04 - val_loss: 7.2506e-04 - val_mse: 7.2506e-04\n",
      "Epoch 162/1000\n",
      "524/524 [==============================] - 0s 587us/step - loss: 4.5843e-04 - mse: 4.5843e-04 - val_loss: 7.0741e-04 - val_mse: 7.0741e-04\n",
      "Epoch 163/1000\n",
      "524/524 [==============================] - 0s 558us/step - loss: 4.5655e-04 - mse: 4.5655e-04 - val_loss: 7.2411e-04 - val_mse: 7.2411e-04\n",
      "Epoch 164/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 4.5624e-04 - mse: 4.5624e-04 - val_loss: 7.3159e-04 - val_mse: 7.3159e-04\n",
      "Epoch 165/1000\n",
      "524/524 [==============================] - 0s 560us/step - loss: 4.5727e-04 - mse: 4.5727e-04 - val_loss: 7.1193e-04 - val_mse: 7.1193e-04\n",
      "Epoch 166/1000\n",
      "524/524 [==============================] - 0s 560us/step - loss: 4.5378e-04 - mse: 4.5378e-04 - val_loss: 7.1098e-04 - val_mse: 7.1098e-04\n",
      "Epoch 167/1000\n",
      "524/524 [==============================] - 0s 579us/step - loss: 4.5049e-04 - mse: 4.5049e-04 - val_loss: 7.2520e-04 - val_mse: 7.2520e-04\n",
      "Epoch 168/1000\n",
      "524/524 [==============================] - 0s 577us/step - loss: 4.5349e-04 - mse: 4.5349e-04 - val_loss: 7.1130e-04 - val_mse: 7.1130e-04\n",
      "Epoch 169/1000\n",
      "524/524 [==============================] - 0s 594us/step - loss: 4.4817e-04 - mse: 4.4817e-04 - val_loss: 7.1777e-04 - val_mse: 7.1777e-04\n",
      "Epoch 170/1000\n",
      "524/524 [==============================] - 0s 562us/step - loss: 4.4896e-04 - mse: 4.4896e-04 - val_loss: 7.0252e-04 - val_mse: 7.0252e-04\n",
      "Epoch 171/1000\n",
      "524/524 [==============================] - 0s 568us/step - loss: 4.4389e-04 - mse: 4.4389e-04 - val_loss: 7.1022e-04 - val_mse: 7.1022e-04\n",
      "Epoch 172/1000\n",
      "524/524 [==============================] - 0s 574us/step - loss: 4.4593e-04 - mse: 4.4593e-04 - val_loss: 6.9564e-04 - val_mse: 6.9564e-04\n",
      "Epoch 173/1000\n",
      "524/524 [==============================] - 0s 570us/step - loss: 4.4414e-04 - mse: 4.4414e-04 - val_loss: 6.9601e-04 - val_mse: 6.9601e-04\n",
      "Epoch 174/1000\n",
      "524/524 [==============================] - 0s 570us/step - loss: 4.4351e-04 - mse: 4.4351e-04 - val_loss: 7.0288e-04 - val_mse: 7.0288e-04\n",
      "Epoch 175/1000\n",
      "524/524 [==============================] - 0s 568us/step - loss: 4.3983e-04 - mse: 4.3983e-04 - val_loss: 7.2716e-04 - val_mse: 7.2716e-04\n",
      "Epoch 176/1000\n",
      "524/524 [==============================] - 0s 477us/step - loss: 4.4271e-04 - mse: 4.4271e-04 - val_loss: 7.0440e-04 - val_mse: 7.0440e-04\n",
      "Epoch 177/1000\n",
      "524/524 [==============================] - 0s 558us/step - loss: 4.3805e-04 - mse: 4.3805e-04 - val_loss: 7.0326e-04 - val_mse: 7.0326e-04\n",
      "Epoch 178/1000\n",
      "524/524 [==============================] - 0s 561us/step - loss: 4.3196e-04 - mse: 4.3196e-04 - val_loss: 7.0875e-04 - val_mse: 7.0875e-04\n",
      "Epoch 179/1000\n",
      "524/524 [==============================] - 0s 568us/step - loss: 4.3939e-04 - mse: 4.3939e-04 - val_loss: 6.8621e-04 - val_mse: 6.8621e-04\n",
      "Epoch 180/1000\n",
      "524/524 [==============================] - 0s 552us/step - loss: 4.3556e-04 - mse: 4.3556e-04 - val_loss: 6.9765e-04 - val_mse: 6.9765e-04\n",
      "Epoch 181/1000\n",
      "524/524 [==============================] - 0s 586us/step - loss: 4.3627e-04 - mse: 4.3627e-04 - val_loss: 6.9540e-04 - val_mse: 6.9540e-04\n",
      "Epoch 182/1000\n",
      "524/524 [==============================] - 0s 577us/step - loss: 4.3341e-04 - mse: 4.3341e-04 - val_loss: 6.9603e-04 - val_mse: 6.9603e-04\n",
      "Epoch 183/1000\n",
      "524/524 [==============================] - 0s 560us/step - loss: 4.3423e-04 - mse: 4.3423e-04 - val_loss: 7.0387e-04 - val_mse: 7.0387e-04\n",
      "Epoch 184/1000\n",
      "524/524 [==============================] - 0s 584us/step - loss: 4.2913e-04 - mse: 4.2913e-04 - val_loss: 6.7981e-04 - val_mse: 6.7981e-04\n",
      "Epoch 185/1000\n",
      "524/524 [==============================] - 0s 607us/step - loss: 4.3125e-04 - mse: 4.3125e-04 - val_loss: 6.9724e-04 - val_mse: 6.9724e-04\n",
      "Epoch 186/1000\n",
      "524/524 [==============================] - 0s 546us/step - loss: 4.2958e-04 - mse: 4.2958e-04 - val_loss: 6.8838e-04 - val_mse: 6.8838e-04\n",
      "Epoch 187/1000\n",
      "524/524 [==============================] - 0s 571us/step - loss: 4.2707e-04 - mse: 4.2707e-04 - val_loss: 6.8018e-04 - val_mse: 6.8018e-04\n",
      "Epoch 188/1000\n",
      "524/524 [==============================] - 0s 604us/step - loss: 4.2267e-04 - mse: 4.2267e-04 - val_loss: 6.8017e-04 - val_mse: 6.8017e-04\n",
      "Epoch 189/1000\n",
      "524/524 [==============================] - 0s 596us/step - loss: 4.2741e-04 - mse: 4.2741e-04 - val_loss: 6.7781e-04 - val_mse: 6.7781e-04\n",
      "Epoch 190/1000\n",
      "524/524 [==============================] - 0s 578us/step - loss: 4.2448e-04 - mse: 4.2448e-04 - val_loss: 6.8698e-04 - val_mse: 6.8698e-04\n",
      "Epoch 191/1000\n",
      "524/524 [==============================] - 0s 572us/step - loss: 4.2361e-04 - mse: 4.2361e-04 - val_loss: 6.8720e-04 - val_mse: 6.8720e-04\n",
      "Epoch 192/1000\n",
      "524/524 [==============================] - 0s 566us/step - loss: 4.2196e-04 - mse: 4.2196e-04 - val_loss: 6.8505e-04 - val_mse: 6.8505e-04\n",
      "Epoch 193/1000\n",
      "524/524 [==============================] - 0s 580us/step - loss: 4.1927e-04 - mse: 4.1927e-04 - val_loss: 7.0414e-04 - val_mse: 7.0414e-04\n",
      "Epoch 194/1000\n",
      "524/524 [==============================] - 0s 590us/step - loss: 4.2259e-04 - mse: 4.2259e-04 - val_loss: 6.7439e-04 - val_mse: 6.7439e-04\n",
      "Epoch 195/1000\n",
      "524/524 [==============================] - 0s 579us/step - loss: 4.1776e-04 - mse: 4.1776e-04 - val_loss: 6.7195e-04 - val_mse: 6.7195e-04\n",
      "Epoch 196/1000\n",
      "524/524 [==============================] - 0s 561us/step - loss: 4.1836e-04 - mse: 4.1836e-04 - val_loss: 6.8765e-04 - val_mse: 6.8765e-04\n",
      "Epoch 197/1000\n",
      "524/524 [==============================] - 0s 601us/step - loss: 4.2015e-04 - mse: 4.2015e-04 - val_loss: 6.6838e-04 - val_mse: 6.6838e-04\n",
      "Epoch 198/1000\n",
      "524/524 [==============================] - 0s 566us/step - loss: 4.1881e-04 - mse: 4.1881e-04 - val_loss: 6.6432e-04 - val_mse: 6.6432e-04\n",
      "Epoch 199/1000\n",
      "524/524 [==============================] - 0s 580us/step - loss: 4.1334e-04 - mse: 4.1334e-04 - val_loss: 6.9179e-04 - val_mse: 6.9179e-04\n",
      "Epoch 200/1000\n",
      "524/524 [==============================] - 0s 584us/step - loss: 4.1667e-04 - mse: 4.1667e-04 - val_loss: 6.6850e-04 - val_mse: 6.6850e-04\n",
      "Epoch 201/1000\n",
      "524/524 [==============================] - 0s 571us/step - loss: 4.1412e-04 - mse: 4.1412e-04 - val_loss: 6.7939e-04 - val_mse: 6.7939e-04\n",
      "Epoch 202/1000\n",
      "524/524 [==============================] - 0s 542us/step - loss: 4.1547e-04 - mse: 4.1547e-04 - val_loss: 6.7059e-04 - val_mse: 6.7059e-04\n",
      "Epoch 203/1000\n",
      "524/524 [==============================] - 0s 534us/step - loss: 4.0938e-04 - mse: 4.0938e-04 - val_loss: 6.8172e-04 - val_mse: 6.8172e-04\n",
      "Epoch 204/1000\n",
      "524/524 [==============================] - 0s 517us/step - loss: 4.0816e-04 - mse: 4.0816e-04 - val_loss: 6.7403e-04 - val_mse: 6.7403e-04\n",
      "Epoch 205/1000\n",
      "524/524 [==============================] - 0s 543us/step - loss: 4.1153e-04 - mse: 4.1153e-04 - val_loss: 6.6884e-04 - val_mse: 6.6884e-04\n",
      "Epoch 206/1000\n",
      "524/524 [==============================] - 0s 596us/step - loss: 4.1085e-04 - mse: 4.1085e-04 - val_loss: 6.5660e-04 - val_mse: 6.5660e-04\n",
      "Epoch 207/1000\n",
      "524/524 [==============================] - 0s 609us/step - loss: 4.0731e-04 - mse: 4.0731e-04 - val_loss: 6.7213e-04 - val_mse: 6.7213e-04\n",
      "Epoch 208/1000\n",
      "524/524 [==============================] - 0s 589us/step - loss: 4.0955e-04 - mse: 4.0955e-04 - val_loss: 6.6579e-04 - val_mse: 6.6579e-04\n",
      "Epoch 209/1000\n",
      "524/524 [==============================] - 0s 561us/step - loss: 4.0615e-04 - mse: 4.0615e-04 - val_loss: 6.7207e-04 - val_mse: 6.7207e-04\n",
      "Epoch 210/1000\n",
      "524/524 [==============================] - 0s 578us/step - loss: 4.0706e-04 - mse: 4.0706e-04 - val_loss: 6.5079e-04 - val_mse: 6.5079e-04\n",
      "Epoch 211/1000\n",
      "524/524 [==============================] - 0s 576us/step - loss: 4.0345e-04 - mse: 4.0345e-04 - val_loss: 6.7687e-04 - val_mse: 6.7687e-04\n",
      "Epoch 212/1000\n",
      "524/524 [==============================] - 0s 580us/step - loss: 4.0661e-04 - mse: 4.0661e-04 - val_loss: 6.6051e-04 - val_mse: 6.6051e-04\n",
      "Epoch 213/1000\n",
      "524/524 [==============================] - 0s 548us/step - loss: 3.9963e-04 - mse: 3.9963e-04 - val_loss: 6.5685e-04 - val_mse: 6.5685e-04\n",
      "Epoch 214/1000\n",
      "524/524 [==============================] - 0s 569us/step - loss: 4.0238e-04 - mse: 4.0238e-04 - val_loss: 6.5822e-04 - val_mse: 6.5822e-04\n",
      "Epoch 215/1000\n",
      "524/524 [==============================] - 0s 558us/step - loss: 4.0159e-04 - mse: 4.0159e-04 - val_loss: 6.6353e-04 - val_mse: 6.6353e-04\n",
      "Epoch 216/1000\n",
      "524/524 [==============================] - 0s 564us/step - loss: 4.0202e-04 - mse: 4.0202e-04 - val_loss: 6.5565e-04 - val_mse: 6.5565e-04\n",
      "Epoch 217/1000\n",
      "524/524 [==============================] - 0s 585us/step - loss: 3.9614e-04 - mse: 3.9614e-04 - val_loss: 6.5738e-04 - val_mse: 6.5738e-04\n",
      "Epoch 218/1000\n",
      "524/524 [==============================] - 0s 576us/step - loss: 3.9835e-04 - mse: 3.9835e-04 - val_loss: 6.5140e-04 - val_mse: 6.5140e-04\n",
      "Epoch 219/1000\n",
      "524/524 [==============================] - 0s 572us/step - loss: 3.9960e-04 - mse: 3.9960e-04 - val_loss: 6.5002e-04 - val_mse: 6.5002e-04\n",
      "Epoch 220/1000\n",
      "524/524 [==============================] - 0s 563us/step - loss: 3.9641e-04 - mse: 3.9641e-04 - val_loss: 6.4780e-04 - val_mse: 6.4780e-04\n",
      "Epoch 221/1000\n",
      "524/524 [==============================] - 0s 577us/step - loss: 3.9980e-04 - mse: 3.9980e-04 - val_loss: 6.4576e-04 - val_mse: 6.4576e-04\n",
      "Epoch 222/1000\n",
      "524/524 [==============================] - 0s 576us/step - loss: 3.9590e-04 - mse: 3.9590e-04 - val_loss: 6.5788e-04 - val_mse: 6.5788e-04\n",
      "Epoch 223/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 3.9729e-04 - mse: 3.9729e-04 - val_loss: 6.4954e-04 - val_mse: 6.4954e-04\n",
      "Epoch 224/1000\n",
      "524/524 [==============================] - 0s 573us/step - loss: 3.9060e-04 - mse: 3.9060e-04 - val_loss: 6.4362e-04 - val_mse: 6.4362e-04\n",
      "Epoch 225/1000\n",
      "524/524 [==============================] - 0s 573us/step - loss: 3.9563e-04 - mse: 3.9563e-04 - val_loss: 6.5443e-04 - val_mse: 6.5443e-04\n",
      "Epoch 226/1000\n",
      "524/524 [==============================] - 0s 564us/step - loss: 3.9025e-04 - mse: 3.9025e-04 - val_loss: 6.4663e-04 - val_mse: 6.4663e-04\n",
      "Epoch 227/1000\n",
      "524/524 [==============================] - 0s 577us/step - loss: 3.9410e-04 - mse: 3.9410e-04 - val_loss: 6.4552e-04 - val_mse: 6.4552e-04\n",
      "Epoch 228/1000\n",
      "524/524 [==============================] - 0s 587us/step - loss: 3.9135e-04 - mse: 3.9135e-04 - val_loss: 6.5622e-04 - val_mse: 6.5622e-04\n",
      "Epoch 229/1000\n",
      "524/524 [==============================] - 0s 570us/step - loss: 3.9066e-04 - mse: 3.9066e-04 - val_loss: 6.4920e-04 - val_mse: 6.4920e-04\n",
      "Epoch 230/1000\n",
      "524/524 [==============================] - 0s 561us/step - loss: 3.9215e-04 - mse: 3.9215e-04 - val_loss: 6.4266e-04 - val_mse: 6.4266e-04\n",
      "Epoch 231/1000\n",
      "524/524 [==============================] - 0s 560us/step - loss: 3.8801e-04 - mse: 3.8801e-04 - val_loss: 6.4633e-04 - val_mse: 6.4633e-04\n",
      "Epoch 232/1000\n",
      "524/524 [==============================] - 0s 537us/step - loss: 3.8999e-04 - mse: 3.8999e-04 - val_loss: 6.4574e-04 - val_mse: 6.4574e-04\n",
      "Epoch 233/1000\n",
      "524/524 [==============================] - 0s 573us/step - loss: 3.8643e-04 - mse: 3.8643e-04 - val_loss: 6.6141e-04 - val_mse: 6.6141e-04\n",
      "Epoch 234/1000\n",
      "524/524 [==============================] - 0s 553us/step - loss: 3.8794e-04 - mse: 3.8794e-04 - val_loss: 6.3794e-04 - val_mse: 6.3794e-04\n",
      "Epoch 235/1000\n",
      "524/524 [==============================] - 0s 552us/step - loss: 3.8788e-04 - mse: 3.8788e-04 - val_loss: 6.3835e-04 - val_mse: 6.3835e-04\n",
      "Epoch 236/1000\n",
      "524/524 [==============================] - 0s 499us/step - loss: 3.8221e-04 - mse: 3.8221e-04 - val_loss: 6.3307e-04 - val_mse: 6.3307e-04\n",
      "Epoch 237/1000\n",
      "524/524 [==============================] - 0s 547us/step - loss: 3.8600e-04 - mse: 3.8600e-04 - val_loss: 6.3953e-04 - val_mse: 6.3953e-04\n",
      "Epoch 238/1000\n",
      "524/524 [==============================] - 0s 535us/step - loss: 3.8433e-04 - mse: 3.8433e-04 - val_loss: 6.5258e-04 - val_mse: 6.5258e-04\n",
      "Epoch 239/1000\n",
      "524/524 [==============================] - 0s 541us/step - loss: 3.8373e-04 - mse: 3.8373e-04 - val_loss: 6.5174e-04 - val_mse: 6.5174e-04\n",
      "Epoch 240/1000\n",
      "524/524 [==============================] - 0s 568us/step - loss: 3.8437e-04 - mse: 3.8437e-04 - val_loss: 6.3141e-04 - val_mse: 6.3141e-04\n",
      "Epoch 241/1000\n",
      "524/524 [==============================] - 0s 504us/step - loss: 3.8040e-04 - mse: 3.8040e-04 - val_loss: 6.3504e-04 - val_mse: 6.3504e-04\n",
      "Epoch 242/1000\n",
      "524/524 [==============================] - 0s 593us/step - loss: 3.8051e-04 - mse: 3.8051e-04 - val_loss: 6.2128e-04 - val_mse: 6.2128e-04\n",
      "Epoch 243/1000\n",
      "524/524 [==============================] - 0s 535us/step - loss: 3.7723e-04 - mse: 3.7723e-04 - val_loss: 6.3515e-04 - val_mse: 6.3515e-04\n",
      "Epoch 244/1000\n",
      "524/524 [==============================] - 0s 552us/step - loss: 3.8231e-04 - mse: 3.8231e-04 - val_loss: 6.2673e-04 - val_mse: 6.2673e-04\n",
      "Epoch 245/1000\n",
      "524/524 [==============================] - 0s 549us/step - loss: 3.7769e-04 - mse: 3.7769e-04 - val_loss: 6.4764e-04 - val_mse: 6.4764e-04\n",
      "Epoch 246/1000\n",
      "524/524 [==============================] - 0s 493us/step - loss: 3.7955e-04 - mse: 3.7955e-04 - val_loss: 6.3720e-04 - val_mse: 6.3720e-04\n",
      "Epoch 247/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 3.7579e-04 - mse: 3.7579e-04 - val_loss: 6.4126e-04 - val_mse: 6.4126e-04\n",
      "Epoch 248/1000\n",
      "524/524 [==============================] - 0s 575us/step - loss: 3.7804e-04 - mse: 3.7804e-04 - val_loss: 6.3308e-04 - val_mse: 6.3308e-04\n",
      "Epoch 249/1000\n",
      "524/524 [==============================] - 0s 545us/step - loss: 3.7666e-04 - mse: 3.7666e-04 - val_loss: 6.3719e-04 - val_mse: 6.3719e-04\n",
      "Epoch 250/1000\n",
      "524/524 [==============================] - 0s 506us/step - loss: 3.7686e-04 - mse: 3.7686e-04 - val_loss: 6.1961e-04 - val_mse: 6.1961e-04\n",
      "Epoch 251/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 3.7245e-04 - mse: 3.7245e-04 - val_loss: 6.3252e-04 - val_mse: 6.3252e-04\n",
      "Epoch 252/1000\n",
      "524/524 [==============================] - 0s 534us/step - loss: 3.7418e-04 - mse: 3.7418e-04 - val_loss: 6.3376e-04 - val_mse: 6.3376e-04\n",
      "Epoch 253/1000\n",
      "524/524 [==============================] - 0s 540us/step - loss: 3.7538e-04 - mse: 3.7538e-04 - val_loss: 6.2128e-04 - val_mse: 6.2128e-04\n",
      "Epoch 254/1000\n",
      "524/524 [==============================] - 0s 537us/step - loss: 3.7523e-04 - mse: 3.7523e-04 - val_loss: 6.3147e-04 - val_mse: 6.3147e-04\n",
      "Epoch 255/1000\n",
      "524/524 [==============================] - 0s 545us/step - loss: 3.7173e-04 - mse: 3.7173e-04 - val_loss: 6.1990e-04 - val_mse: 6.1990e-04\n",
      "Epoch 256/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 3.7007e-04 - mse: 3.7007e-04 - val_loss: 6.3958e-04 - val_mse: 6.3958e-04\n",
      "Epoch 257/1000\n",
      "524/524 [==============================] - 0s 552us/step - loss: 3.7443e-04 - mse: 3.7443e-04 - val_loss: 6.2880e-04 - val_mse: 6.2880e-04\n",
      "Epoch 258/1000\n",
      "524/524 [==============================] - 0s 529us/step - loss: 3.7060e-04 - mse: 3.7060e-04 - val_loss: 6.4327e-04 - val_mse: 6.4327e-04\n",
      "Epoch 259/1000\n",
      "524/524 [==============================] - 0s 499us/step - loss: 3.7037e-04 - mse: 3.7037e-04 - val_loss: 6.2425e-04 - val_mse: 6.2425e-04\n",
      "Epoch 260/1000\n",
      "524/524 [==============================] - 0s 537us/step - loss: 3.7116e-04 - mse: 3.7116e-04 - val_loss: 6.2788e-04 - val_mse: 6.2788e-04\n",
      "Epoch 261/1000\n",
      "524/524 [==============================] - 0s 496us/step - loss: 3.6954e-04 - mse: 3.6954e-04 - val_loss: 6.2955e-04 - val_mse: 6.2955e-04\n",
      "Epoch 262/1000\n",
      "524/524 [==============================] - 0s 542us/step - loss: 3.6901e-04 - mse: 3.6901e-04 - val_loss: 6.2599e-04 - val_mse: 6.2599e-04\n",
      "Epoch 263/1000\n",
      "524/524 [==============================] - 0s 536us/step - loss: 3.6772e-04 - mse: 3.6772e-04 - val_loss: 6.2531e-04 - val_mse: 6.2531e-04\n",
      "Epoch 264/1000\n",
      "524/524 [==============================] - 0s 543us/step - loss: 3.6695e-04 - mse: 3.6695e-04 - val_loss: 6.2024e-04 - val_mse: 6.2024e-04\n",
      "Epoch 265/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 3.6473e-04 - mse: 3.6473e-04 - val_loss: 6.2528e-04 - val_mse: 6.2528e-04\n",
      "Epoch 266/1000\n",
      "524/524 [==============================] - 0s 567us/step - loss: 3.6554e-04 - mse: 3.6554e-04 - val_loss: 6.1892e-04 - val_mse: 6.1892e-04\n",
      "Epoch 267/1000\n",
      "524/524 [==============================] - 0s 542us/step - loss: 3.6582e-04 - mse: 3.6582e-04 - val_loss: 6.2496e-04 - val_mse: 6.2496e-04\n",
      "Epoch 268/1000\n",
      "524/524 [==============================] - 0s 563us/step - loss: 3.6624e-04 - mse: 3.6624e-04 - val_loss: 6.1219e-04 - val_mse: 6.1219e-04\n",
      "Epoch 269/1000\n",
      "524/524 [==============================] - 0s 543us/step - loss: 3.6421e-04 - mse: 3.6421e-04 - val_loss: 6.1097e-04 - val_mse: 6.1097e-04\n",
      "Epoch 270/1000\n",
      "524/524 [==============================] - 0s 552us/step - loss: 3.6375e-04 - mse: 3.6375e-04 - val_loss: 6.1373e-04 - val_mse: 6.1373e-04\n",
      "Epoch 271/1000\n",
      "524/524 [==============================] - 0s 541us/step - loss: 3.6389e-04 - mse: 3.6389e-04 - val_loss: 6.0951e-04 - val_mse: 6.0951e-04\n",
      "Epoch 272/1000\n",
      "524/524 [==============================] - 0s 549us/step - loss: 3.6136e-04 - mse: 3.6136e-04 - val_loss: 6.2986e-04 - val_mse: 6.2986e-04\n",
      "Epoch 273/1000\n",
      "524/524 [==============================] - 0s 551us/step - loss: 3.6168e-04 - mse: 3.6168e-04 - val_loss: 6.0760e-04 - val_mse: 6.0760e-04\n",
      "Epoch 274/1000\n",
      "524/524 [==============================] - 0s 540us/step - loss: 3.6372e-04 - mse: 3.6372e-04 - val_loss: 6.1849e-04 - val_mse: 6.1849e-04\n",
      "Epoch 275/1000\n",
      "524/524 [==============================] - 0s 579us/step - loss: 3.6042e-04 - mse: 3.6042e-04 - val_loss: 6.1290e-04 - val_mse: 6.1290e-04\n",
      "Epoch 276/1000\n",
      "524/524 [==============================] - 0s 559us/step - loss: 3.5423e-04 - mse: 3.5423e-04 - val_loss: 6.2493e-04 - val_mse: 6.2493e-04\n",
      "Epoch 277/1000\n",
      "524/524 [==============================] - 0s 549us/step - loss: 3.6231e-04 - mse: 3.6231e-04 - val_loss: 6.1642e-04 - val_mse: 6.1642e-04\n",
      "Epoch 278/1000\n",
      "524/524 [==============================] - 0s 532us/step - loss: 3.5777e-04 - mse: 3.5777e-04 - val_loss: 6.0226e-04 - val_mse: 6.0226e-04\n",
      "Epoch 279/1000\n",
      "524/524 [==============================] - 0s 556us/step - loss: 3.6094e-04 - mse: 3.6094e-04 - val_loss: 6.1141e-04 - val_mse: 6.1141e-04\n",
      "Epoch 280/1000\n",
      "524/524 [==============================] - 0s 549us/step - loss: 3.5784e-04 - mse: 3.5784e-04 - val_loss: 6.2085e-04 - val_mse: 6.2085e-04\n",
      "Epoch 281/1000\n",
      "524/524 [==============================] - 0s 558us/step - loss: 3.5658e-04 - mse: 3.5658e-04 - val_loss: 6.1951e-04 - val_mse: 6.1951e-04\n",
      "Epoch 282/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 3.5501e-04 - mse: 3.5501e-04 - val_loss: 6.1046e-04 - val_mse: 6.1046e-04\n",
      "Epoch 283/1000\n",
      "524/524 [==============================] - 0s 543us/step - loss: 3.5467e-04 - mse: 3.5467e-04 - val_loss: 6.0785e-04 - val_mse: 6.0785e-04\n",
      "Epoch 284/1000\n",
      "524/524 [==============================] - 0s 555us/step - loss: 3.5373e-04 - mse: 3.5373e-04 - val_loss: 6.1524e-04 - val_mse: 6.1524e-04\n",
      "Epoch 285/1000\n",
      "524/524 [==============================] - 0s 544us/step - loss: 3.5613e-04 - mse: 3.5613e-04 - val_loss: 6.0473e-04 - val_mse: 6.0473e-04\n",
      "Epoch 286/1000\n",
      "524/524 [==============================] - 0s 549us/step - loss: 3.5568e-04 - mse: 3.5568e-04 - val_loss: 5.9996e-04 - val_mse: 5.9996e-04\n",
      "Epoch 287/1000\n",
      "524/524 [==============================] - 0s 534us/step - loss: 3.5505e-04 - mse: 3.5505e-04 - val_loss: 6.1347e-04 - val_mse: 6.1347e-04\n",
      "Epoch 288/1000\n",
      "524/524 [==============================] - 0s 577us/step - loss: 3.5344e-04 - mse: 3.5344e-04 - val_loss: 6.0792e-04 - val_mse: 6.0792e-04\n",
      "Epoch 289/1000\n",
      "524/524 [==============================] - 0s 538us/step - loss: 3.5239e-04 - mse: 3.5239e-04 - val_loss: 6.2134e-04 - val_mse: 6.2134e-04\n",
      "Epoch 290/1000\n",
      "524/524 [==============================] - 0s 535us/step - loss: 3.5416e-04 - mse: 3.5416e-04 - val_loss: 6.0282e-04 - val_mse: 6.0282e-04\n",
      "Epoch 291/1000\n",
      "524/524 [==============================] - 0s 587us/step - loss: 3.5312e-04 - mse: 3.5312e-04 - val_loss: 5.9938e-04 - val_mse: 5.9938e-04\n",
      "Epoch 292/1000\n",
      "524/524 [==============================] - 0s 546us/step - loss: 3.5137e-04 - mse: 3.5137e-04 - val_loss: 5.9677e-04 - val_mse: 5.9677e-04\n",
      "Epoch 293/1000\n",
      "524/524 [==============================] - 0s 551us/step - loss: 3.5412e-04 - mse: 3.5412e-04 - val_loss: 6.0390e-04 - val_mse: 6.0390e-04\n",
      "Epoch 294/1000\n",
      "524/524 [==============================] - 0s 574us/step - loss: 3.4741e-04 - mse: 3.4741e-04 - val_loss: 6.2652e-04 - val_mse: 6.2652e-04\n",
      "Epoch 295/1000\n",
      "524/524 [==============================] - 0s 581us/step - loss: 3.4903e-04 - mse: 3.4903e-04 - val_loss: 5.9898e-04 - val_mse: 5.9898e-04\n",
      "Epoch 296/1000\n",
      "524/524 [==============================] - 0s 594us/step - loss: 3.5090e-04 - mse: 3.5090e-04 - val_loss: 5.9658e-04 - val_mse: 5.9658e-04\n",
      "Epoch 297/1000\n",
      "524/524 [==============================] - 0s 579us/step - loss: 3.5143e-04 - mse: 3.5143e-04 - val_loss: 6.0312e-04 - val_mse: 6.0312e-04\n",
      "Epoch 298/1000\n",
      "524/524 [==============================] - 0s 597us/step - loss: 3.4879e-04 - mse: 3.4879e-04 - val_loss: 5.9984e-04 - val_mse: 5.9984e-04\n",
      "Epoch 299/1000\n",
      "524/524 [==============================] - 0s 544us/step - loss: 3.4677e-04 - mse: 3.4677e-04 - val_loss: 6.1617e-04 - val_mse: 6.1617e-04\n",
      "Epoch 300/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 3.5026e-04 - mse: 3.5026e-04 - val_loss: 6.0096e-04 - val_mse: 6.0096e-04\n",
      "Epoch 301/1000\n",
      "524/524 [==============================] - 0s 488us/step - loss: 3.4840e-04 - mse: 3.4840e-04 - val_loss: 5.9747e-04 - val_mse: 5.9747e-04\n",
      "Epoch 302/1000\n",
      "524/524 [==============================] - 0s 529us/step - loss: 3.4371e-04 - mse: 3.4371e-04 - val_loss: 5.9662e-04 - val_mse: 5.9662e-04\n",
      "Epoch 303/1000\n",
      "524/524 [==============================] - 0s 609us/step - loss: 3.4635e-04 - mse: 3.4635e-04 - val_loss: 5.8917e-04 - val_mse: 5.8917e-04\n",
      "Epoch 304/1000\n",
      "524/524 [==============================] - 0s 556us/step - loss: 3.4861e-04 - mse: 3.4861e-04 - val_loss: 5.9234e-04 - val_mse: 5.9234e-04\n",
      "Epoch 305/1000\n",
      "524/524 [==============================] - 0s 521us/step - loss: 3.4670e-04 - mse: 3.4670e-04 - val_loss: 5.9265e-04 - val_mse: 5.9265e-04\n",
      "Epoch 306/1000\n",
      "524/524 [==============================] - 0s 570us/step - loss: 3.4606e-04 - mse: 3.4606e-04 - val_loss: 5.9497e-04 - val_mse: 5.9497e-04\n",
      "Epoch 307/1000\n",
      "524/524 [==============================] - 0s 547us/step - loss: 3.4548e-04 - mse: 3.4548e-04 - val_loss: 6.0233e-04 - val_mse: 6.0233e-04\n",
      "Epoch 308/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 3.4424e-04 - mse: 3.4424e-04 - val_loss: 5.9686e-04 - val_mse: 5.9686e-04\n",
      "Epoch 309/1000\n",
      "524/524 [==============================] - 0s 535us/step - loss: 3.4124e-04 - mse: 3.4124e-04 - val_loss: 5.9239e-04 - val_mse: 5.9239e-04\n",
      "Epoch 310/1000\n",
      "524/524 [==============================] - 0s 512us/step - loss: 3.4342e-04 - mse: 3.4342e-04 - val_loss: 6.0588e-04 - val_mse: 6.0588e-04\n",
      "Epoch 311/1000\n",
      "524/524 [==============================] - 0s 560us/step - loss: 3.4104e-04 - mse: 3.4104e-04 - val_loss: 5.8250e-04 - val_mse: 5.8250e-04\n",
      "Epoch 312/1000\n",
      "524/524 [==============================] - 0s 534us/step - loss: 3.4201e-04 - mse: 3.4201e-04 - val_loss: 6.0911e-04 - val_mse: 6.0911e-04\n",
      "Epoch 313/1000\n",
      "524/524 [==============================] - 0s 542us/step - loss: 3.4002e-04 - mse: 3.4002e-04 - val_loss: 6.2864e-04 - val_mse: 6.2864e-04\n",
      "Epoch 314/1000\n",
      "524/524 [==============================] - 0s 541us/step - loss: 3.4461e-04 - mse: 3.4461e-04 - val_loss: 6.0582e-04 - val_mse: 6.0582e-04\n",
      "Epoch 315/1000\n",
      "524/524 [==============================] - 0s 558us/step - loss: 3.4027e-04 - mse: 3.4027e-04 - val_loss: 5.8815e-04 - val_mse: 5.8815e-04\n",
      "Epoch 316/1000\n",
      "524/524 [==============================] - 0s 564us/step - loss: 3.3916e-04 - mse: 3.3916e-04 - val_loss: 5.9132e-04 - val_mse: 5.9132e-04\n",
      "Epoch 317/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 3.3927e-04 - mse: 3.3927e-04 - val_loss: 6.0786e-04 - val_mse: 6.0786e-04\n",
      "Epoch 318/1000\n",
      "524/524 [==============================] - 0s 548us/step - loss: 3.4069e-04 - mse: 3.4069e-04 - val_loss: 5.8764e-04 - val_mse: 5.8764e-04\n",
      "Epoch 319/1000\n",
      "524/524 [==============================] - 0s 517us/step - loss: 3.3808e-04 - mse: 3.3808e-04 - val_loss: 5.9718e-04 - val_mse: 5.9718e-04\n",
      "Epoch 320/1000\n",
      "524/524 [==============================] - 0s 537us/step - loss: 3.3847e-04 - mse: 3.3847e-04 - val_loss: 5.9794e-04 - val_mse: 5.9794e-04\n",
      "Epoch 321/1000\n",
      "524/524 [==============================] - 0s 562us/step - loss: 3.3895e-04 - mse: 3.3895e-04 - val_loss: 5.8212e-04 - val_mse: 5.8212e-04\n",
      "Epoch 322/1000\n",
      "524/524 [==============================] - 0s 498us/step - loss: 3.3885e-04 - mse: 3.3885e-04 - val_loss: 5.8471e-04 - val_mse: 5.8471e-04\n",
      "Epoch 323/1000\n",
      "524/524 [==============================] - 0s 498us/step - loss: 3.3769e-04 - mse: 3.3769e-04 - val_loss: 5.8476e-04 - val_mse: 5.8476e-04\n",
      "Epoch 324/1000\n",
      "524/524 [==============================] - 0s 562us/step - loss: 3.3803e-04 - mse: 3.3803e-04 - val_loss: 5.9252e-04 - val_mse: 5.9252e-04\n",
      "Epoch 325/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 3.3405e-04 - mse: 3.3405e-04 - val_loss: 5.9271e-04 - val_mse: 5.9271e-04\n",
      "Epoch 326/1000\n",
      "524/524 [==============================] - 0s 541us/step - loss: 3.3733e-04 - mse: 3.3733e-04 - val_loss: 5.8615e-04 - val_mse: 5.8615e-04\n",
      "Epoch 327/1000\n",
      "524/524 [==============================] - 0s 500us/step - loss: 3.3598e-04 - mse: 3.3598e-04 - val_loss: 5.8371e-04 - val_mse: 5.8371e-04\n",
      "Epoch 328/1000\n",
      "524/524 [==============================] - 0s 508us/step - loss: 3.3581e-04 - mse: 3.3581e-04 - val_loss: 5.9121e-04 - val_mse: 5.9121e-04\n",
      "Epoch 329/1000\n",
      "524/524 [==============================] - 0s 557us/step - loss: 3.3172e-04 - mse: 3.3172e-04 - val_loss: 6.0329e-04 - val_mse: 6.0329e-04\n",
      "Epoch 330/1000\n",
      "524/524 [==============================] - 0s 564us/step - loss: 3.3491e-04 - mse: 3.3491e-04 - val_loss: 5.7728e-04 - val_mse: 5.7728e-04\n",
      "Epoch 331/1000\n",
      "524/524 [==============================] - 0s 545us/step - loss: 3.3382e-04 - mse: 3.3382e-04 - val_loss: 5.9400e-04 - val_mse: 5.9400e-04\n",
      "Epoch 332/1000\n",
      "524/524 [==============================] - 0s 592us/step - loss: 3.3449e-04 - mse: 3.3449e-04 - val_loss: 5.8195e-04 - val_mse: 5.8195e-04\n",
      "Epoch 333/1000\n",
      "524/524 [==============================] - 0s 547us/step - loss: 3.3354e-04 - mse: 3.3354e-04 - val_loss: 5.9278e-04 - val_mse: 5.9278e-04\n",
      "Epoch 334/1000\n",
      "524/524 [==============================] - 0s 488us/step - loss: 3.3497e-04 - mse: 3.3497e-04 - val_loss: 5.8954e-04 - val_mse: 5.8954e-04\n",
      "Epoch 335/1000\n",
      "524/524 [==============================] - 0s 553us/step - loss: 3.3139e-04 - mse: 3.3139e-04 - val_loss: 5.7461e-04 - val_mse: 5.7461e-04\n",
      "Epoch 336/1000\n",
      "524/524 [==============================] - 0s 565us/step - loss: 3.3457e-04 - mse: 3.3457e-04 - val_loss: 5.7972e-04 - val_mse: 5.7972e-04\n",
      "Epoch 337/1000\n",
      "524/524 [==============================] - 0s 534us/step - loss: 3.3290e-04 - mse: 3.3290e-04 - val_loss: 5.8409e-04 - val_mse: 5.8409e-04\n",
      "Epoch 338/1000\n",
      "524/524 [==============================] - 0s 537us/step - loss: 3.3029e-04 - mse: 3.3029e-04 - val_loss: 5.7815e-04 - val_mse: 5.7815e-04\n",
      "Epoch 339/1000\n",
      "524/524 [==============================] - 0s 563us/step - loss: 3.2800e-04 - mse: 3.2800e-04 - val_loss: 5.7876e-04 - val_mse: 5.7876e-04\n",
      "Epoch 340/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 3.2858e-04 - mse: 3.2858e-04 - val_loss: 5.8667e-04 - val_mse: 5.8667e-04\n",
      "Epoch 341/1000\n",
      "524/524 [==============================] - 0s 559us/step - loss: 3.3104e-04 - mse: 3.3104e-04 - val_loss: 5.9241e-04 - val_mse: 5.9241e-04\n",
      "Epoch 342/1000\n",
      "524/524 [==============================] - 0s 532us/step - loss: 3.3037e-04 - mse: 3.3037e-04 - val_loss: 5.7787e-04 - val_mse: 5.7787e-04\n",
      "Epoch 343/1000\n",
      "524/524 [==============================] - 0s 565us/step - loss: 3.3117e-04 - mse: 3.3117e-04 - val_loss: 5.7435e-04 - val_mse: 5.7435e-04\n",
      "Epoch 344/1000\n",
      "524/524 [==============================] - 0s 534us/step - loss: 3.2724e-04 - mse: 3.2724e-04 - val_loss: 5.8373e-04 - val_mse: 5.8373e-04\n",
      "Epoch 345/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 3.2895e-04 - mse: 3.2895e-04 - val_loss: 5.8278e-04 - val_mse: 5.8278e-04\n",
      "Epoch 346/1000\n",
      "524/524 [==============================] - 0s 557us/step - loss: 3.2967e-04 - mse: 3.2967e-04 - val_loss: 5.7934e-04 - val_mse: 5.7934e-04\n",
      "Epoch 347/1000\n",
      "524/524 [==============================] - 0s 525us/step - loss: 3.2887e-04 - mse: 3.2887e-04 - val_loss: 5.7984e-04 - val_mse: 5.7984e-04\n",
      "Epoch 348/1000\n",
      "524/524 [==============================] - 0s 542us/step - loss: 3.2528e-04 - mse: 3.2528e-04 - val_loss: 5.7282e-04 - val_mse: 5.7282e-04\n",
      "Epoch 349/1000\n",
      "524/524 [==============================] - 0s 512us/step - loss: 3.2841e-04 - mse: 3.2841e-04 - val_loss: 5.7456e-04 - val_mse: 5.7456e-04\n",
      "Epoch 350/1000\n",
      "524/524 [==============================] - 0s 557us/step - loss: 3.2657e-04 - mse: 3.2657e-04 - val_loss: 5.7702e-04 - val_mse: 5.7702e-04\n",
      "Epoch 351/1000\n",
      "524/524 [==============================] - 0s 563us/step - loss: 3.2837e-04 - mse: 3.2837e-04 - val_loss: 5.7622e-04 - val_mse: 5.7622e-04\n",
      "Epoch 352/1000\n",
      "524/524 [==============================] - 0s 559us/step - loss: 3.2717e-04 - mse: 3.2717e-04 - val_loss: 5.7943e-04 - val_mse: 5.7943e-04\n",
      "Epoch 353/1000\n",
      "524/524 [==============================] - 0s 541us/step - loss: 3.2832e-04 - mse: 3.2832e-04 - val_loss: 5.7294e-04 - val_mse: 5.7294e-04\n",
      "Epoch 354/1000\n",
      "524/524 [==============================] - 0s 544us/step - loss: 3.2446e-04 - mse: 3.2446e-04 - val_loss: 5.6858e-04 - val_mse: 5.6858e-04\n",
      "Epoch 355/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 3.2765e-04 - mse: 3.2765e-04 - val_loss: 5.7215e-04 - val_mse: 5.7215e-04\n",
      "Epoch 356/1000\n",
      "524/524 [==============================] - 0s 532us/step - loss: 3.2459e-04 - mse: 3.2459e-04 - val_loss: 5.7958e-04 - val_mse: 5.7958e-04\n",
      "Epoch 357/1000\n",
      "524/524 [==============================] - 0s 537us/step - loss: 3.2432e-04 - mse: 3.2432e-04 - val_loss: 5.7019e-04 - val_mse: 5.7019e-04\n",
      "Epoch 358/1000\n",
      "524/524 [==============================] - 0s 534us/step - loss: 3.2456e-04 - mse: 3.2456e-04 - val_loss: 5.7381e-04 - val_mse: 5.7381e-04\n",
      "Epoch 359/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 3.2336e-04 - mse: 3.2336e-04 - val_loss: 5.8132e-04 - val_mse: 5.8132e-04\n",
      "Epoch 360/1000\n",
      "524/524 [==============================] - 0s 541us/step - loss: 3.2530e-04 - mse: 3.2530e-04 - val_loss: 5.6864e-04 - val_mse: 5.6864e-04\n",
      "Epoch 361/1000\n",
      "524/524 [==============================] - 0s 497us/step - loss: 3.2357e-04 - mse: 3.2357e-04 - val_loss: 5.6828e-04 - val_mse: 5.6828e-04\n",
      "Epoch 362/1000\n",
      "524/524 [==============================] - 0s 539us/step - loss: 3.2271e-04 - mse: 3.2271e-04 - val_loss: 5.8211e-04 - val_mse: 5.8211e-04\n",
      "Epoch 363/1000\n",
      "524/524 [==============================] - 0s 534us/step - loss: 3.2383e-04 - mse: 3.2383e-04 - val_loss: 5.8396e-04 - val_mse: 5.8396e-04\n",
      "Epoch 364/1000\n",
      "524/524 [==============================] - 0s 545us/step - loss: 3.2003e-04 - mse: 3.2003e-04 - val_loss: 5.7893e-04 - val_mse: 5.7893e-04\n",
      "Epoch 365/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 3.2261e-04 - mse: 3.2261e-04 - val_loss: 5.7023e-04 - val_mse: 5.7023e-04\n",
      "Epoch 366/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 3.2155e-04 - mse: 3.2155e-04 - val_loss: 5.7774e-04 - val_mse: 5.7774e-04\n",
      "Epoch 367/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 3.2051e-04 - mse: 3.2051e-04 - val_loss: 5.7549e-04 - val_mse: 5.7549e-04\n",
      "Epoch 368/1000\n",
      "524/524 [==============================] - 0s 512us/step - loss: 3.1448e-04 - mse: 3.1448e-04 - val_loss: 5.8699e-04 - val_mse: 5.8699e-04\n",
      "Epoch 369/1000\n",
      "524/524 [==============================] - 0s 549us/step - loss: 3.1921e-04 - mse: 3.1921e-04 - val_loss: 5.8116e-04 - val_mse: 5.8116e-04\n",
      "Epoch 370/1000\n",
      "524/524 [==============================] - 0s 541us/step - loss: 3.1746e-04 - mse: 3.1746e-04 - val_loss: 5.6627e-04 - val_mse: 5.6627e-04\n",
      "Epoch 371/1000\n",
      "524/524 [==============================] - 0s 542us/step - loss: 3.2029e-04 - mse: 3.2029e-04 - val_loss: 5.6457e-04 - val_mse: 5.6457e-04\n",
      "Epoch 372/1000\n",
      "524/524 [==============================] - 0s 532us/step - loss: 3.2015e-04 - mse: 3.2015e-04 - val_loss: 5.7597e-04 - val_mse: 5.7597e-04\n",
      "Epoch 373/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 3.1957e-04 - mse: 3.1957e-04 - val_loss: 5.6780e-04 - val_mse: 5.6780e-04\n",
      "Epoch 374/1000\n",
      "524/524 [==============================] - 0s 536us/step - loss: 3.1832e-04 - mse: 3.1832e-04 - val_loss: 5.6695e-04 - val_mse: 5.6695e-04\n",
      "Epoch 375/1000\n",
      "524/524 [==============================] - 0s 538us/step - loss: 3.1943e-04 - mse: 3.1943e-04 - val_loss: 5.6850e-04 - val_mse: 5.6850e-04\n",
      "Epoch 376/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 3.1609e-04 - mse: 3.1609e-04 - val_loss: 5.5640e-04 - val_mse: 5.5640e-04\n",
      "Epoch 377/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 3.1868e-04 - mse: 3.1868e-04 - val_loss: 5.7000e-04 - val_mse: 5.7000e-04\n",
      "Epoch 378/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 3.1475e-04 - mse: 3.1475e-04 - val_loss: 5.8919e-04 - val_mse: 5.8919e-04\n",
      "Epoch 379/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 3.1907e-04 - mse: 3.1907e-04 - val_loss: 5.7155e-04 - val_mse: 5.7155e-04\n",
      "Epoch 380/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 3.1736e-04 - mse: 3.1736e-04 - val_loss: 5.7661e-04 - val_mse: 5.7661e-04\n",
      "Epoch 381/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 3.1570e-04 - mse: 3.1570e-04 - val_loss: 5.7433e-04 - val_mse: 5.7433e-04\n",
      "Epoch 382/1000\n",
      "524/524 [==============================] - 0s 535us/step - loss: 3.1729e-04 - mse: 3.1729e-04 - val_loss: 5.5866e-04 - val_mse: 5.5866e-04\n",
      "Epoch 383/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 3.1558e-04 - mse: 3.1558e-04 - val_loss: 5.6925e-04 - val_mse: 5.6925e-04\n",
      "Epoch 384/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 3.1611e-04 - mse: 3.1611e-04 - val_loss: 5.7263e-04 - val_mse: 5.7263e-04\n",
      "Epoch 385/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 3.1659e-04 - mse: 3.1659e-04 - val_loss: 5.6980e-04 - val_mse: 5.6980e-04\n",
      "Epoch 386/1000\n",
      "524/524 [==============================] - 0s 539us/step - loss: 3.1514e-04 - mse: 3.1514e-04 - val_loss: 5.6022e-04 - val_mse: 5.6022e-04\n",
      "Epoch 387/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 3.1405e-04 - mse: 3.1405e-04 - val_loss: 5.7601e-04 - val_mse: 5.7601e-04\n",
      "Epoch 388/1000\n",
      "524/524 [==============================] - 0s 534us/step - loss: 3.1519e-04 - mse: 3.1519e-04 - val_loss: 5.7056e-04 - val_mse: 5.7056e-04\n",
      "Epoch 389/1000\n",
      "524/524 [==============================] - 0s 515us/step - loss: 3.1509e-04 - mse: 3.1509e-04 - val_loss: 5.7484e-04 - val_mse: 5.7484e-04\n",
      "Epoch 390/1000\n",
      "524/524 [==============================] - 0s 532us/step - loss: 3.1378e-04 - mse: 3.1378e-04 - val_loss: 5.7631e-04 - val_mse: 5.7631e-04\n",
      "Epoch 391/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 3.1341e-04 - mse: 3.1341e-04 - val_loss: 5.5722e-04 - val_mse: 5.5722e-04\n",
      "Epoch 392/1000\n",
      "524/524 [==============================] - 0s 525us/step - loss: 3.1295e-04 - mse: 3.1295e-04 - val_loss: 5.5762e-04 - val_mse: 5.5762e-04\n",
      "Epoch 393/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 3.1260e-04 - mse: 3.1260e-04 - val_loss: 5.5750e-04 - val_mse: 5.5750e-04\n",
      "Epoch 394/1000\n",
      "524/524 [==============================] - 0s 550us/step - loss: 3.1274e-04 - mse: 3.1274e-04 - val_loss: 5.6685e-04 - val_mse: 5.6685e-04\n",
      "Epoch 395/1000\n",
      "524/524 [==============================] - 0s 544us/step - loss: 3.1334e-04 - mse: 3.1334e-04 - val_loss: 5.5475e-04 - val_mse: 5.5475e-04\n",
      "Epoch 396/1000\n",
      "524/524 [==============================] - 0s 507us/step - loss: 3.1160e-04 - mse: 3.1160e-04 - val_loss: 5.6680e-04 - val_mse: 5.6680e-04\n",
      "Epoch 397/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 3.1253e-04 - mse: 3.1253e-04 - val_loss: 5.6589e-04 - val_mse: 5.6589e-04\n",
      "Epoch 398/1000\n",
      "524/524 [==============================] - 0s 541us/step - loss: 3.1139e-04 - mse: 3.1139e-04 - val_loss: 5.5783e-04 - val_mse: 5.5783e-04\n",
      "Epoch 399/1000\n",
      "524/524 [==============================] - 0s 543us/step - loss: 3.1176e-04 - mse: 3.1176e-04 - val_loss: 5.5345e-04 - val_mse: 5.5345e-04\n",
      "Epoch 400/1000\n",
      "524/524 [==============================] - 0s 501us/step - loss: 3.1045e-04 - mse: 3.1045e-04 - val_loss: 5.5988e-04 - val_mse: 5.5988e-04\n",
      "Epoch 401/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 3.1134e-04 - mse: 3.1134e-04 - val_loss: 5.5637e-04 - val_mse: 5.5637e-04\n",
      "Epoch 402/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 3.0943e-04 - mse: 3.0943e-04 - val_loss: 5.6257e-04 - val_mse: 5.6257e-04\n",
      "Epoch 403/1000\n",
      "524/524 [==============================] - 0s 536us/step - loss: 3.0785e-04 - mse: 3.0785e-04 - val_loss: 5.5756e-04 - val_mse: 5.5756e-04\n",
      "Epoch 404/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 3.1150e-04 - mse: 3.1150e-04 - val_loss: 5.6047e-04 - val_mse: 5.6047e-04\n",
      "Epoch 405/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 3.1013e-04 - mse: 3.1013e-04 - val_loss: 5.6147e-04 - val_mse: 5.6147e-04\n",
      "Epoch 406/1000\n",
      "524/524 [==============================] - 0s 468us/step - loss: 3.0899e-04 - mse: 3.0899e-04 - val_loss: 5.6347e-04 - val_mse: 5.6347e-04\n",
      "Epoch 407/1000\n",
      "524/524 [==============================] - 0s 536us/step - loss: 3.0648e-04 - mse: 3.0648e-04 - val_loss: 5.5716e-04 - val_mse: 5.5716e-04\n",
      "Epoch 408/1000\n",
      "524/524 [==============================] - 0s 569us/step - loss: 3.0838e-04 - mse: 3.0838e-04 - val_loss: 5.5816e-04 - val_mse: 5.5816e-04\n",
      "Epoch 409/1000\n",
      "524/524 [==============================] - 0s 546us/step - loss: 3.0882e-04 - mse: 3.0882e-04 - val_loss: 5.5589e-04 - val_mse: 5.5589e-04\n",
      "Epoch 410/1000\n",
      "524/524 [==============================] - 0s 592us/step - loss: 3.0827e-04 - mse: 3.0827e-04 - val_loss: 5.5508e-04 - val_mse: 5.5508e-04\n",
      "Epoch 411/1000\n",
      "524/524 [==============================] - 0s 588us/step - loss: 3.0850e-04 - mse: 3.0850e-04 - val_loss: 5.5232e-04 - val_mse: 5.5232e-04\n",
      "Epoch 412/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 3.0656e-04 - mse: 3.0656e-04 - val_loss: 5.6169e-04 - val_mse: 5.6169e-04\n",
      "Epoch 413/1000\n",
      "524/524 [==============================] - 0s 547us/step - loss: 3.0444e-04 - mse: 3.0444e-04 - val_loss: 5.5988e-04 - val_mse: 5.5988e-04\n",
      "Epoch 414/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 3.0682e-04 - mse: 3.0682e-04 - val_loss: 5.5906e-04 - val_mse: 5.5906e-04\n",
      "Epoch 415/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 3.0645e-04 - mse: 3.0645e-04 - val_loss: 5.5490e-04 - val_mse: 5.5490e-04\n",
      "Epoch 416/1000\n",
      "524/524 [==============================] - 0s 509us/step - loss: 3.0678e-04 - mse: 3.0678e-04 - val_loss: 5.6209e-04 - val_mse: 5.6209e-04\n",
      "Epoch 417/1000\n",
      "524/524 [==============================] - 0s 521us/step - loss: 3.0678e-04 - mse: 3.0678e-04 - val_loss: 5.5538e-04 - val_mse: 5.5538e-04\n",
      "Epoch 418/1000\n",
      "524/524 [==============================] - 0s 523us/step - loss: 3.0453e-04 - mse: 3.0453e-04 - val_loss: 5.5320e-04 - val_mse: 5.5320e-04\n",
      "Epoch 419/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 3.0546e-04 - mse: 3.0546e-04 - val_loss: 5.4840e-04 - val_mse: 5.4840e-04\n",
      "Epoch 420/1000\n",
      "524/524 [==============================] - 0s 517us/step - loss: 3.0611e-04 - mse: 3.0611e-04 - val_loss: 5.5272e-04 - val_mse: 5.5272e-04\n",
      "Epoch 421/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 3.0472e-04 - mse: 3.0472e-04 - val_loss: 5.5373e-04 - val_mse: 5.5373e-04\n",
      "Epoch 422/1000\n",
      "524/524 [==============================] - 0s 536us/step - loss: 3.0530e-04 - mse: 3.0530e-04 - val_loss: 5.5841e-04 - val_mse: 5.5841e-04\n",
      "Epoch 423/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 3.0352e-04 - mse: 3.0352e-04 - val_loss: 5.5837e-04 - val_mse: 5.5837e-04\n",
      "Epoch 424/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 3.0377e-04 - mse: 3.0377e-04 - val_loss: 5.5517e-04 - val_mse: 5.5517e-04\n",
      "Epoch 425/1000\n",
      "524/524 [==============================] - 0s 523us/step - loss: 2.9999e-04 - mse: 2.9999e-04 - val_loss: 5.6927e-04 - val_mse: 5.6927e-04\n",
      "Epoch 426/1000\n",
      "524/524 [==============================] - 0s 548us/step - loss: 3.0349e-04 - mse: 3.0349e-04 - val_loss: 5.4433e-04 - val_mse: 5.4433e-04\n",
      "Epoch 427/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 3.0293e-04 - mse: 3.0293e-04 - val_loss: 5.6344e-04 - val_mse: 5.6344e-04\n",
      "Epoch 428/1000\n",
      "524/524 [==============================] - 0s 519us/step - loss: 3.0091e-04 - mse: 3.0091e-04 - val_loss: 5.5394e-04 - val_mse: 5.5394e-04\n",
      "Epoch 429/1000\n",
      "524/524 [==============================] - 0s 517us/step - loss: 3.0338e-04 - mse: 3.0338e-04 - val_loss: 5.5747e-04 - val_mse: 5.5747e-04\n",
      "Epoch 430/1000\n",
      "524/524 [==============================] - 0s 511us/step - loss: 3.0299e-04 - mse: 3.0299e-04 - val_loss: 5.5090e-04 - val_mse: 5.5090e-04\n",
      "Epoch 431/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 3.0176e-04 - mse: 3.0176e-04 - val_loss: 5.5064e-04 - val_mse: 5.5064e-04\n",
      "Epoch 432/1000\n",
      "524/524 [==============================] - 0s 497us/step - loss: 3.0087e-04 - mse: 3.0087e-04 - val_loss: 5.5642e-04 - val_mse: 5.5642e-04\n",
      "Epoch 433/1000\n",
      "524/524 [==============================] - 0s 478us/step - loss: 2.9809e-04 - mse: 2.9809e-04 - val_loss: 5.3795e-04 - val_mse: 5.3795e-04\n",
      "Epoch 434/1000\n",
      "524/524 [==============================] - 0s 523us/step - loss: 3.0134e-04 - mse: 3.0134e-04 - val_loss: 5.4190e-04 - val_mse: 5.4190e-04\n",
      "Epoch 435/1000\n",
      "524/524 [==============================] - 0s 517us/step - loss: 3.0114e-04 - mse: 3.0114e-04 - val_loss: 5.4724e-04 - val_mse: 5.4724e-04\n",
      "Epoch 436/1000\n",
      "524/524 [==============================] - 0s 541us/step - loss: 2.9861e-04 - mse: 2.9861e-04 - val_loss: 5.6736e-04 - val_mse: 5.6736e-04\n",
      "Epoch 437/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 3.0134e-04 - mse: 3.0134e-04 - val_loss: 5.4361e-04 - val_mse: 5.4361e-04\n",
      "Epoch 438/1000\n",
      "524/524 [==============================] - 0s 519us/step - loss: 2.9952e-04 - mse: 2.9952e-04 - val_loss: 5.5395e-04 - val_mse: 5.5395e-04\n",
      "Epoch 439/1000\n",
      "524/524 [==============================] - 0s 518us/step - loss: 2.9821e-04 - mse: 2.9821e-04 - val_loss: 5.5814e-04 - val_mse: 5.5814e-04\n",
      "Epoch 440/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.9909e-04 - mse: 2.9909e-04 - val_loss: 5.5134e-04 - val_mse: 5.5134e-04\n",
      "Epoch 441/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.9975e-04 - mse: 2.9975e-04 - val_loss: 5.5301e-04 - val_mse: 5.5301e-04\n",
      "Epoch 442/1000\n",
      "524/524 [==============================] - 0s 529us/step - loss: 2.9834e-04 - mse: 2.9834e-04 - val_loss: 5.5704e-04 - val_mse: 5.5704e-04\n",
      "Epoch 443/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 2.9836e-04 - mse: 2.9836e-04 - val_loss: 5.4439e-04 - val_mse: 5.4439e-04\n",
      "Epoch 444/1000\n",
      "524/524 [==============================] - 0s 537us/step - loss: 2.9923e-04 - mse: 2.9923e-04 - val_loss: 5.3956e-04 - val_mse: 5.3956e-04\n",
      "Epoch 445/1000\n",
      "524/524 [==============================] - 0s 518us/step - loss: 2.9849e-04 - mse: 2.9849e-04 - val_loss: 5.4919e-04 - val_mse: 5.4919e-04\n",
      "Epoch 446/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.9528e-04 - mse: 2.9528e-04 - val_loss: 5.7361e-04 - val_mse: 5.7361e-04\n",
      "Epoch 447/1000\n",
      "524/524 [==============================] - 0s 535us/step - loss: 2.9884e-04 - mse: 2.9884e-04 - val_loss: 5.3499e-04 - val_mse: 5.3499e-04\n",
      "Epoch 448/1000\n",
      "524/524 [==============================] - 0s 534us/step - loss: 2.9828e-04 - mse: 2.9828e-04 - val_loss: 5.4097e-04 - val_mse: 5.4097e-04\n",
      "Epoch 449/1000\n",
      "524/524 [==============================] - 0s 535us/step - loss: 2.9704e-04 - mse: 2.9704e-04 - val_loss: 5.5165e-04 - val_mse: 5.5165e-04\n",
      "Epoch 450/1000\n",
      "524/524 [==============================] - 0s 533us/step - loss: 2.9794e-04 - mse: 2.9794e-04 - val_loss: 5.4369e-04 - val_mse: 5.4369e-04\n",
      "Epoch 451/1000\n",
      "524/524 [==============================] - 0s 516us/step - loss: 2.9709e-04 - mse: 2.9709e-04 - val_loss: 5.4842e-04 - val_mse: 5.4842e-04\n",
      "Epoch 452/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.9624e-04 - mse: 2.9624e-04 - val_loss: 5.5162e-04 - val_mse: 5.5162e-04\n",
      "Epoch 453/1000\n",
      "524/524 [==============================] - 0s 518us/step - loss: 2.9689e-04 - mse: 2.9689e-04 - val_loss: 5.3650e-04 - val_mse: 5.3650e-04\n",
      "Epoch 454/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.9653e-04 - mse: 2.9653e-04 - val_loss: 5.4676e-04 - val_mse: 5.4676e-04\n",
      "Epoch 455/1000\n",
      "524/524 [==============================] - 0s 507us/step - loss: 2.9423e-04 - mse: 2.9423e-04 - val_loss: 5.6380e-04 - val_mse: 5.6380e-04\n",
      "Epoch 456/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.9630e-04 - mse: 2.9630e-04 - val_loss: 5.5996e-04 - val_mse: 5.5996e-04\n",
      "Epoch 457/1000\n",
      "524/524 [==============================] - 0s 529us/step - loss: 2.9486e-04 - mse: 2.9486e-04 - val_loss: 5.5382e-04 - val_mse: 5.5382e-04\n",
      "Epoch 458/1000\n",
      "524/524 [==============================] - 0s 518us/step - loss: 2.9469e-04 - mse: 2.9469e-04 - val_loss: 5.5204e-04 - val_mse: 5.5204e-04\n",
      "Epoch 459/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.9516e-04 - mse: 2.9516e-04 - val_loss: 5.4472e-04 - val_mse: 5.4472e-04\n",
      "Epoch 460/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.9346e-04 - mse: 2.9346e-04 - val_loss: 5.4459e-04 - val_mse: 5.4459e-04\n",
      "Epoch 461/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 2.9400e-04 - mse: 2.9400e-04 - val_loss: 5.4217e-04 - val_mse: 5.4217e-04\n",
      "Epoch 462/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.9347e-04 - mse: 2.9347e-04 - val_loss: 5.4446e-04 - val_mse: 5.4446e-04\n",
      "Epoch 463/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.9360e-04 - mse: 2.9360e-04 - val_loss: 5.3872e-04 - val_mse: 5.3872e-04\n",
      "Epoch 464/1000\n",
      "524/524 [==============================] - 0s 533us/step - loss: 2.9246e-04 - mse: 2.9246e-04 - val_loss: 5.3999e-04 - val_mse: 5.3999e-04\n",
      "Epoch 465/1000\n",
      "524/524 [==============================] - 0s 541us/step - loss: 2.9293e-04 - mse: 2.9293e-04 - val_loss: 5.5230e-04 - val_mse: 5.5230e-04\n",
      "Epoch 466/1000\n",
      "524/524 [==============================] - 0s 555us/step - loss: 2.9322e-04 - mse: 2.9322e-04 - val_loss: 5.4517e-04 - val_mse: 5.4517e-04\n",
      "Epoch 467/1000\n",
      "524/524 [==============================] - 0s 626us/step - loss: 2.9181e-04 - mse: 2.9181e-04 - val_loss: 5.3099e-04 - val_mse: 5.3099e-04\n",
      "Epoch 468/1000\n",
      "524/524 [==============================] - 0s 556us/step - loss: 2.9281e-04 - mse: 2.9281e-04 - val_loss: 5.3998e-04 - val_mse: 5.3998e-04\n",
      "Epoch 469/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.8954e-04 - mse: 2.8954e-04 - val_loss: 5.3019e-04 - val_mse: 5.3019e-04\n",
      "Epoch 470/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 2.9304e-04 - mse: 2.9304e-04 - val_loss: 5.4264e-04 - val_mse: 5.4264e-04\n",
      "Epoch 471/1000\n",
      "524/524 [==============================] - 0s 537us/step - loss: 2.9201e-04 - mse: 2.9201e-04 - val_loss: 5.4152e-04 - val_mse: 5.4152e-04\n",
      "Epoch 472/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.9042e-04 - mse: 2.9042e-04 - val_loss: 5.4215e-04 - val_mse: 5.4215e-04\n",
      "Epoch 473/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 2.8945e-04 - mse: 2.8945e-04 - val_loss: 5.5858e-04 - val_mse: 5.5858e-04\n",
      "Epoch 474/1000\n",
      "524/524 [==============================] - 0s 519us/step - loss: 2.9198e-04 - mse: 2.9198e-04 - val_loss: 5.4675e-04 - val_mse: 5.4675e-04\n",
      "Epoch 475/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 2.9002e-04 - mse: 2.9002e-04 - val_loss: 5.3302e-04 - val_mse: 5.3302e-04\n",
      "Epoch 476/1000\n",
      "524/524 [==============================] - 0s 541us/step - loss: 2.8892e-04 - mse: 2.8892e-04 - val_loss: 5.4458e-04 - val_mse: 5.4458e-04\n",
      "Epoch 477/1000\n",
      "524/524 [==============================] - 0s 576us/step - loss: 2.9078e-04 - mse: 2.9078e-04 - val_loss: 5.3823e-04 - val_mse: 5.3823e-04\n",
      "Epoch 478/1000\n",
      "524/524 [==============================] - 0s 536us/step - loss: 2.8945e-04 - mse: 2.8945e-04 - val_loss: 5.4404e-04 - val_mse: 5.4404e-04\n",
      "Epoch 479/1000\n",
      "524/524 [==============================] - 0s 543us/step - loss: 2.8915e-04 - mse: 2.8915e-04 - val_loss: 5.4065e-04 - val_mse: 5.4065e-04\n",
      "Epoch 480/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.8925e-04 - mse: 2.8925e-04 - val_loss: 5.4740e-04 - val_mse: 5.4740e-04\n",
      "Epoch 481/1000\n",
      "524/524 [==============================] - 0s 519us/step - loss: 2.8760e-04 - mse: 2.8760e-04 - val_loss: 5.3580e-04 - val_mse: 5.3580e-04\n",
      "Epoch 482/1000\n",
      "524/524 [==============================] - 0s 562us/step - loss: 2.8975e-04 - mse: 2.8975e-04 - val_loss: 5.3138e-04 - val_mse: 5.3138e-04\n",
      "Epoch 483/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.8928e-04 - mse: 2.8928e-04 - val_loss: 5.4310e-04 - val_mse: 5.4310e-04\n",
      "Epoch 484/1000\n",
      "524/524 [==============================] - 0s 545us/step - loss: 2.8865e-04 - mse: 2.8865e-04 - val_loss: 5.3642e-04 - val_mse: 5.3642e-04\n",
      "Epoch 485/1000\n",
      "524/524 [==============================] - 0s 516us/step - loss: 2.8679e-04 - mse: 2.8679e-04 - val_loss: 5.3321e-04 - val_mse: 5.3321e-04\n",
      "Epoch 486/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.8820e-04 - mse: 2.8820e-04 - val_loss: 5.3261e-04 - val_mse: 5.3261e-04\n",
      "Epoch 487/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.8691e-04 - mse: 2.8691e-04 - val_loss: 5.3039e-04 - val_mse: 5.3039e-04\n",
      "Epoch 488/1000\n",
      "524/524 [==============================] - 0s 493us/step - loss: 2.8748e-04 - mse: 2.8748e-04 - val_loss: 5.3037e-04 - val_mse: 5.3037e-04\n",
      "Epoch 489/1000\n",
      "524/524 [==============================] - 0s 501us/step - loss: 2.8696e-04 - mse: 2.8696e-04 - val_loss: 5.5489e-04 - val_mse: 5.5489e-04\n",
      "Epoch 490/1000\n",
      "524/524 [==============================] - 0s 512us/step - loss: 2.8730e-04 - mse: 2.8730e-04 - val_loss: 5.3544e-04 - val_mse: 5.3544e-04\n",
      "Epoch 491/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 2.8693e-04 - mse: 2.8693e-04 - val_loss: 5.3327e-04 - val_mse: 5.3327e-04\n",
      "Epoch 492/1000\n",
      "524/524 [==============================] - 0s 469us/step - loss: 2.8616e-04 - mse: 2.8616e-04 - val_loss: 5.3473e-04 - val_mse: 5.3473e-04\n",
      "Epoch 493/1000\n",
      "524/524 [==============================] - 0s 547us/step - loss: 2.8647e-04 - mse: 2.8647e-04 - val_loss: 5.3411e-04 - val_mse: 5.3411e-04\n",
      "Epoch 494/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 2.8612e-04 - mse: 2.8612e-04 - val_loss: 5.4224e-04 - val_mse: 5.4224e-04\n",
      "Epoch 495/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 2.8509e-04 - mse: 2.8509e-04 - val_loss: 5.3140e-04 - val_mse: 5.3140e-04\n",
      "Epoch 496/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 2.8512e-04 - mse: 2.8512e-04 - val_loss: 5.3214e-04 - val_mse: 5.3214e-04\n",
      "Epoch 497/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.8573e-04 - mse: 2.8573e-04 - val_loss: 5.4499e-04 - val_mse: 5.4499e-04\n",
      "Epoch 498/1000\n",
      "524/524 [==============================] - 0s 533us/step - loss: 2.8570e-04 - mse: 2.8570e-04 - val_loss: 5.3214e-04 - val_mse: 5.3214e-04\n",
      "Epoch 499/1000\n",
      "524/524 [==============================] - 0s 507us/step - loss: 2.8557e-04 - mse: 2.8557e-04 - val_loss: 5.3635e-04 - val_mse: 5.3635e-04\n",
      "Epoch 500/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.8559e-04 - mse: 2.8559e-04 - val_loss: 5.3317e-04 - val_mse: 5.3317e-04\n",
      "Epoch 501/1000\n",
      "524/524 [==============================] - 0s 532us/step - loss: 2.8150e-04 - mse: 2.8150e-04 - val_loss: 5.4403e-04 - val_mse: 5.4403e-04\n",
      "Epoch 502/1000\n",
      "524/524 [==============================] - 0s 565us/step - loss: 2.8646e-04 - mse: 2.8646e-04 - val_loss: 5.4368e-04 - val_mse: 5.4368e-04\n",
      "Epoch 503/1000\n",
      "524/524 [==============================] - 0s 566us/step - loss: 2.8480e-04 - mse: 2.8480e-04 - val_loss: 5.2657e-04 - val_mse: 5.2657e-04\n",
      "Epoch 504/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.8481e-04 - mse: 2.8481e-04 - val_loss: 5.3200e-04 - val_mse: 5.3200e-04\n",
      "Epoch 505/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 2.8303e-04 - mse: 2.8303e-04 - val_loss: 5.2729e-04 - val_mse: 5.2729e-04\n",
      "Epoch 506/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.8354e-04 - mse: 2.8354e-04 - val_loss: 5.3473e-04 - val_mse: 5.3473e-04\n",
      "Epoch 507/1000\n",
      "524/524 [==============================] - 0s 488us/step - loss: 2.8436e-04 - mse: 2.8436e-04 - val_loss: 5.3497e-04 - val_mse: 5.3497e-04\n",
      "Epoch 508/1000\n",
      "524/524 [==============================] - 0s 529us/step - loss: 2.8217e-04 - mse: 2.8217e-04 - val_loss: 5.3610e-04 - val_mse: 5.3610e-04\n",
      "Epoch 509/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 2.8114e-04 - mse: 2.8114e-04 - val_loss: 5.4545e-04 - val_mse: 5.4545e-04\n",
      "Epoch 510/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.8109e-04 - mse: 2.8109e-04 - val_loss: 5.2757e-04 - val_mse: 5.2757e-04\n",
      "Epoch 511/1000\n",
      "524/524 [==============================] - 0s 519us/step - loss: 2.8218e-04 - mse: 2.8218e-04 - val_loss: 5.4807e-04 - val_mse: 5.4807e-04\n",
      "Epoch 512/1000\n",
      "524/524 [==============================] - 0s 541us/step - loss: 2.8307e-04 - mse: 2.8307e-04 - val_loss: 5.3360e-04 - val_mse: 5.3360e-04\n",
      "Epoch 513/1000\n",
      "524/524 [==============================] - 0s 541us/step - loss: 2.8177e-04 - mse: 2.8177e-04 - val_loss: 5.3835e-04 - val_mse: 5.3835e-04\n",
      "Epoch 514/1000\n",
      "524/524 [==============================] - 0s 550us/step - loss: 2.8138e-04 - mse: 2.8138e-04 - val_loss: 5.2532e-04 - val_mse: 5.2532e-04\n",
      "Epoch 515/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 2.8246e-04 - mse: 2.8246e-04 - val_loss: 5.3148e-04 - val_mse: 5.3148e-04\n",
      "Epoch 516/1000\n",
      "524/524 [==============================] - 0s 598us/step - loss: 2.8146e-04 - mse: 2.8146e-04 - val_loss: 5.2951e-04 - val_mse: 5.2951e-04\n",
      "Epoch 517/1000\n",
      "524/524 [==============================] - 0s 598us/step - loss: 2.8183e-04 - mse: 2.8183e-04 - val_loss: 5.2758e-04 - val_mse: 5.2758e-04\n",
      "Epoch 518/1000\n",
      "524/524 [==============================] - 0s 571us/step - loss: 2.8035e-04 - mse: 2.8035e-04 - val_loss: 5.4070e-04 - val_mse: 5.4070e-04\n",
      "Epoch 519/1000\n",
      "524/524 [==============================] - 0s 552us/step - loss: 2.8116e-04 - mse: 2.8116e-04 - val_loss: 5.2981e-04 - val_mse: 5.2981e-04\n",
      "Epoch 520/1000\n",
      "524/524 [==============================] - 0s 518us/step - loss: 2.7646e-04 - mse: 2.7646e-04 - val_loss: 5.2907e-04 - val_mse: 5.2907e-04\n",
      "Epoch 521/1000\n",
      "524/524 [==============================] - 0s 551us/step - loss: 2.7911e-04 - mse: 2.7911e-04 - val_loss: 5.3889e-04 - val_mse: 5.3889e-04\n",
      "Epoch 522/1000\n",
      "524/524 [==============================] - 0s 612us/step - loss: 2.7918e-04 - mse: 2.7918e-04 - val_loss: 5.3143e-04 - val_mse: 5.3143e-04\n",
      "Epoch 523/1000\n",
      "524/524 [==============================] - 0s 645us/step - loss: 2.7879e-04 - mse: 2.7879e-04 - val_loss: 5.2269e-04 - val_mse: 5.2269e-04\n",
      "Epoch 524/1000\n",
      "524/524 [==============================] - 0s 630us/step - loss: 2.7632e-04 - mse: 2.7632e-04 - val_loss: 5.3418e-04 - val_mse: 5.3418e-04\n",
      "Epoch 525/1000\n",
      "524/524 [==============================] - 0s 664us/step - loss: 2.8025e-04 - mse: 2.8025e-04 - val_loss: 5.2289e-04 - val_mse: 5.2289e-04\n",
      "Epoch 526/1000\n",
      "524/524 [==============================] - 0s 575us/step - loss: 2.7770e-04 - mse: 2.7770e-04 - val_loss: 5.2165e-04 - val_mse: 5.2165e-04\n",
      "Epoch 527/1000\n",
      "524/524 [==============================] - 0s 543us/step - loss: 2.8002e-04 - mse: 2.8002e-04 - val_loss: 5.1845e-04 - val_mse: 5.1845e-04\n",
      "Epoch 528/1000\n",
      "524/524 [==============================] - 0s 565us/step - loss: 2.7770e-04 - mse: 2.7770e-04 - val_loss: 5.4181e-04 - val_mse: 5.4181e-04\n",
      "Epoch 529/1000\n",
      "524/524 [==============================] - 0s 535us/step - loss: 2.7814e-04 - mse: 2.7814e-04 - val_loss: 5.4468e-04 - val_mse: 5.4468e-04\n",
      "Epoch 530/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.7781e-04 - mse: 2.7781e-04 - val_loss: 5.2376e-04 - val_mse: 5.2376e-04\n",
      "Epoch 531/1000\n",
      "524/524 [==============================] - 0s 521us/step - loss: 2.7652e-04 - mse: 2.7652e-04 - val_loss: 5.2584e-04 - val_mse: 5.2584e-04\n",
      "Epoch 532/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.7597e-04 - mse: 2.7597e-04 - val_loss: 5.3285e-04 - val_mse: 5.3285e-04\n",
      "Epoch 533/1000\n",
      "524/524 [==============================] - 0s 548us/step - loss: 2.7780e-04 - mse: 2.7780e-04 - val_loss: 5.2935e-04 - val_mse: 5.2935e-04\n",
      "Epoch 534/1000\n",
      "524/524 [==============================] - 0s 533us/step - loss: 2.7792e-04 - mse: 2.7792e-04 - val_loss: 5.1810e-04 - val_mse: 5.1810e-04\n",
      "Epoch 535/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 2.7419e-04 - mse: 2.7419e-04 - val_loss: 5.2217e-04 - val_mse: 5.2217e-04\n",
      "Epoch 536/1000\n",
      "524/524 [==============================] - 0s 533us/step - loss: 2.7695e-04 - mse: 2.7695e-04 - val_loss: 5.3818e-04 - val_mse: 5.3818e-04\n",
      "Epoch 537/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.7588e-04 - mse: 2.7588e-04 - val_loss: 5.4288e-04 - val_mse: 5.4288e-04\n",
      "Epoch 538/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.7390e-04 - mse: 2.7390e-04 - val_loss: 5.3828e-04 - val_mse: 5.3828e-04\n",
      "Epoch 539/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.7671e-04 - mse: 2.7671e-04 - val_loss: 5.2569e-04 - val_mse: 5.2569e-04\n",
      "Epoch 540/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 2.7659e-04 - mse: 2.7659e-04 - val_loss: 5.2133e-04 - val_mse: 5.2133e-04\n",
      "Epoch 541/1000\n",
      "524/524 [==============================] - 0s 533us/step - loss: 2.7582e-04 - mse: 2.7582e-04 - val_loss: 5.2588e-04 - val_mse: 5.2588e-04\n",
      "Epoch 542/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.7537e-04 - mse: 2.7537e-04 - val_loss: 5.2337e-04 - val_mse: 5.2337e-04\n",
      "Epoch 543/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.7681e-04 - mse: 2.7681e-04 - val_loss: 5.2382e-04 - val_mse: 5.2382e-04\n",
      "Epoch 544/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.7477e-04 - mse: 2.7477e-04 - val_loss: 5.1722e-04 - val_mse: 5.1722e-04\n",
      "Epoch 545/1000\n",
      "524/524 [==============================] - 0s 511us/step - loss: 2.7660e-04 - mse: 2.7660e-04 - val_loss: 5.2227e-04 - val_mse: 5.2227e-04\n",
      "Epoch 546/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 2.7529e-04 - mse: 2.7529e-04 - val_loss: 5.2952e-04 - val_mse: 5.2952e-04\n",
      "Epoch 547/1000\n",
      "524/524 [==============================] - 0s 549us/step - loss: 2.7485e-04 - mse: 2.7485e-04 - val_loss: 5.1670e-04 - val_mse: 5.1670e-04\n",
      "Epoch 548/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.7477e-04 - mse: 2.7477e-04 - val_loss: 5.2771e-04 - val_mse: 5.2771e-04\n",
      "Epoch 549/1000\n",
      "524/524 [==============================] - 0s 523us/step - loss: 2.7395e-04 - mse: 2.7395e-04 - val_loss: 5.3054e-04 - val_mse: 5.3054e-04\n",
      "Epoch 550/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.7434e-04 - mse: 2.7434e-04 - val_loss: 5.2863e-04 - val_mse: 5.2863e-04\n",
      "Epoch 551/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.7565e-04 - mse: 2.7565e-04 - val_loss: 5.2111e-04 - val_mse: 5.2111e-04\n",
      "Epoch 552/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 2.7368e-04 - mse: 2.7368e-04 - val_loss: 5.2892e-04 - val_mse: 5.2892e-04\n",
      "Epoch 553/1000\n",
      "524/524 [==============================] - 0s 521us/step - loss: 2.7391e-04 - mse: 2.7391e-04 - val_loss: 5.2821e-04 - val_mse: 5.2821e-04\n",
      "Epoch 554/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.7393e-04 - mse: 2.7393e-04 - val_loss: 5.2395e-04 - val_mse: 5.2395e-04\n",
      "Epoch 555/1000\n",
      "524/524 [==============================] - 0s 518us/step - loss: 2.7235e-04 - mse: 2.7235e-04 - val_loss: 5.2403e-04 - val_mse: 5.2403e-04\n",
      "Epoch 556/1000\n",
      "524/524 [==============================] - 0s 513us/step - loss: 2.7376e-04 - mse: 2.7376e-04 - val_loss: 5.2395e-04 - val_mse: 5.2395e-04\n",
      "Epoch 557/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.7221e-04 - mse: 2.7221e-04 - val_loss: 5.3449e-04 - val_mse: 5.3449e-04\n",
      "Epoch 558/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 2.7323e-04 - mse: 2.7323e-04 - val_loss: 5.2505e-04 - val_mse: 5.2505e-04\n",
      "Epoch 559/1000\n",
      "524/524 [==============================] - 0s 518us/step - loss: 2.7274e-04 - mse: 2.7274e-04 - val_loss: 5.2422e-04 - val_mse: 5.2422e-04\n",
      "Epoch 560/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 2.7170e-04 - mse: 2.7170e-04 - val_loss: 5.3213e-04 - val_mse: 5.3213e-04\n",
      "Epoch 561/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 2.7266e-04 - mse: 2.7266e-04 - val_loss: 5.2776e-04 - val_mse: 5.2776e-04\n",
      "Epoch 562/1000\n",
      "524/524 [==============================] - 0s 513us/step - loss: 2.7070e-04 - mse: 2.7070e-04 - val_loss: 5.2712e-04 - val_mse: 5.2712e-04\n",
      "Epoch 563/1000\n",
      "524/524 [==============================] - 0s 503us/step - loss: 2.7045e-04 - mse: 2.7045e-04 - val_loss: 5.1748e-04 - val_mse: 5.1748e-04\n",
      "Epoch 564/1000\n",
      "524/524 [==============================] - 0s 548us/step - loss: 2.7075e-04 - mse: 2.7075e-04 - val_loss: 5.1102e-04 - val_mse: 5.1102e-04\n",
      "Epoch 565/1000\n",
      "524/524 [==============================] - 0s 608us/step - loss: 2.7211e-04 - mse: 2.7211e-04 - val_loss: 5.1609e-04 - val_mse: 5.1609e-04\n",
      "Epoch 566/1000\n",
      "524/524 [==============================] - 0s 609us/step - loss: 2.7225e-04 - mse: 2.7225e-04 - val_loss: 5.2020e-04 - val_mse: 5.2020e-04\n",
      "Epoch 567/1000\n",
      "524/524 [==============================] - 0s 555us/step - loss: 2.7184e-04 - mse: 2.7184e-04 - val_loss: 5.2370e-04 - val_mse: 5.2370e-04\n",
      "Epoch 568/1000\n",
      "524/524 [==============================] - 0s 569us/step - loss: 2.6868e-04 - mse: 2.6868e-04 - val_loss: 5.1719e-04 - val_mse: 5.1719e-04\n",
      "Epoch 569/1000\n",
      "524/524 [==============================] - 0s 612us/step - loss: 2.6973e-04 - mse: 2.6973e-04 - val_loss: 5.1204e-04 - val_mse: 5.1204e-04\n",
      "Epoch 570/1000\n",
      "524/524 [==============================] - 0s 591us/step - loss: 2.6735e-04 - mse: 2.6735e-04 - val_loss: 5.3817e-04 - val_mse: 5.3817e-04\n",
      "Epoch 571/1000\n",
      "524/524 [==============================] - 0s 586us/step - loss: 2.7115e-04 - mse: 2.7115e-04 - val_loss: 5.3401e-04 - val_mse: 5.3401e-04\n",
      "Epoch 572/1000\n",
      "524/524 [==============================] - 0s 538us/step - loss: 2.7106e-04 - mse: 2.7106e-04 - val_loss: 5.3157e-04 - val_mse: 5.3157e-04\n",
      "Epoch 573/1000\n",
      "524/524 [==============================] - 0s 583us/step - loss: 2.6880e-04 - mse: 2.6880e-04 - val_loss: 5.1292e-04 - val_mse: 5.1292e-04\n",
      "Epoch 574/1000\n",
      "524/524 [==============================] - 0s 562us/step - loss: 2.7069e-04 - mse: 2.7069e-04 - val_loss: 5.2682e-04 - val_mse: 5.2682e-04\n",
      "Epoch 575/1000\n",
      "524/524 [==============================] - 0s 538us/step - loss: 2.6982e-04 - mse: 2.6982e-04 - val_loss: 5.1347e-04 - val_mse: 5.1347e-04\n",
      "Epoch 576/1000\n",
      "524/524 [==============================] - 0s 504us/step - loss: 2.6969e-04 - mse: 2.6969e-04 - val_loss: 5.1895e-04 - val_mse: 5.1895e-04\n",
      "Epoch 577/1000\n",
      "524/524 [==============================] - 0s 627us/step - loss: 2.7051e-04 - mse: 2.7051e-04 - val_loss: 5.2101e-04 - val_mse: 5.2101e-04\n",
      "Epoch 578/1000\n",
      "524/524 [==============================] - 0s 609us/step - loss: 2.6989e-04 - mse: 2.6989e-04 - val_loss: 5.1552e-04 - val_mse: 5.1552e-04\n",
      "Epoch 579/1000\n",
      "524/524 [==============================] - 0s 606us/step - loss: 2.6893e-04 - mse: 2.6893e-04 - val_loss: 5.2154e-04 - val_mse: 5.2154e-04\n",
      "Epoch 580/1000\n",
      "524/524 [==============================] - 0s 668us/step - loss: 2.6912e-04 - mse: 2.6912e-04 - val_loss: 5.1865e-04 - val_mse: 5.1865e-04\n",
      "Epoch 581/1000\n",
      "524/524 [==============================] - 0s 647us/step - loss: 2.6775e-04 - mse: 2.6775e-04 - val_loss: 5.1019e-04 - val_mse: 5.1019e-04\n",
      "Epoch 582/1000\n",
      "524/524 [==============================] - 0s 571us/step - loss: 2.6752e-04 - mse: 2.6752e-04 - val_loss: 5.2415e-04 - val_mse: 5.2415e-04\n",
      "Epoch 583/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 2.6798e-04 - mse: 2.6798e-04 - val_loss: 5.3029e-04 - val_mse: 5.3029e-04\n",
      "Epoch 584/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 2.6840e-04 - mse: 2.6840e-04 - val_loss: 5.1804e-04 - val_mse: 5.1804e-04\n",
      "Epoch 585/1000\n",
      "524/524 [==============================] - 0s 535us/step - loss: 2.6734e-04 - mse: 2.6734e-04 - val_loss: 5.0691e-04 - val_mse: 5.0691e-04\n",
      "Epoch 586/1000\n",
      "524/524 [==============================] - 0s 540us/step - loss: 2.6848e-04 - mse: 2.6848e-04 - val_loss: 5.2453e-04 - val_mse: 5.2453e-04\n",
      "Epoch 587/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.6685e-04 - mse: 2.6685e-04 - val_loss: 5.1846e-04 - val_mse: 5.1846e-04\n",
      "Epoch 588/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.6583e-04 - mse: 2.6583e-04 - val_loss: 5.1723e-04 - val_mse: 5.1723e-04\n",
      "Epoch 589/1000\n",
      "524/524 [==============================] - 0s 548us/step - loss: 2.6707e-04 - mse: 2.6707e-04 - val_loss: 5.0661e-04 - val_mse: 5.0661e-04\n",
      "Epoch 590/1000\n",
      "524/524 [==============================] - 0s 516us/step - loss: 2.6724e-04 - mse: 2.6724e-04 - val_loss: 5.1516e-04 - val_mse: 5.1516e-04\n",
      "Epoch 591/1000\n",
      "524/524 [==============================] - 0s 538us/step - loss: 2.6721e-04 - mse: 2.6721e-04 - val_loss: 5.1463e-04 - val_mse: 5.1463e-04\n",
      "Epoch 592/1000\n",
      "524/524 [==============================] - 0s 511us/step - loss: 2.6576e-04 - mse: 2.6576e-04 - val_loss: 5.2535e-04 - val_mse: 5.2535e-04\n",
      "Epoch 593/1000\n",
      "524/524 [==============================] - 0s 517us/step - loss: 2.6497e-04 - mse: 2.6497e-04 - val_loss: 5.1895e-04 - val_mse: 5.1895e-04\n",
      "Epoch 594/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 2.6581e-04 - mse: 2.6581e-04 - val_loss: 5.2127e-04 - val_mse: 5.2127e-04\n",
      "Epoch 595/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.6506e-04 - mse: 2.6506e-04 - val_loss: 5.3374e-04 - val_mse: 5.3374e-04\n",
      "Epoch 596/1000\n",
      "524/524 [==============================] - 0s 525us/step - loss: 2.6631e-04 - mse: 2.6631e-04 - val_loss: 5.0667e-04 - val_mse: 5.0667e-04\n",
      "Epoch 597/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.6605e-04 - mse: 2.6605e-04 - val_loss: 5.1162e-04 - val_mse: 5.1162e-04\n",
      "Epoch 598/1000\n",
      "524/524 [==============================] - 0s 521us/step - loss: 2.6441e-04 - mse: 2.6441e-04 - val_loss: 5.1764e-04 - val_mse: 5.1764e-04\n",
      "Epoch 599/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.6570e-04 - mse: 2.6570e-04 - val_loss: 5.0784e-04 - val_mse: 5.0784e-04\n",
      "Epoch 600/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.6468e-04 - mse: 2.6468e-04 - val_loss: 5.1175e-04 - val_mse: 5.1175e-04\n",
      "Epoch 601/1000\n",
      "524/524 [==============================] - 0s 515us/step - loss: 2.6583e-04 - mse: 2.6583e-04 - val_loss: 5.0823e-04 - val_mse: 5.0823e-04\n",
      "Epoch 602/1000\n",
      "524/524 [==============================] - 0s 512us/step - loss: 2.6237e-04 - mse: 2.6237e-04 - val_loss: 5.1306e-04 - val_mse: 5.1306e-04\n",
      "Epoch 603/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.6550e-04 - mse: 2.6550e-04 - val_loss: 5.1390e-04 - val_mse: 5.1390e-04\n",
      "Epoch 604/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.6474e-04 - mse: 2.6474e-04 - val_loss: 5.1168e-04 - val_mse: 5.1168e-04\n",
      "Epoch 605/1000\n",
      "524/524 [==============================] - 0s 517us/step - loss: 2.6452e-04 - mse: 2.6452e-04 - val_loss: 5.1982e-04 - val_mse: 5.1982e-04\n",
      "Epoch 606/1000\n",
      "524/524 [==============================] - 0s 537us/step - loss: 2.5972e-04 - mse: 2.5972e-04 - val_loss: 5.2011e-04 - val_mse: 5.2011e-04\n",
      "Epoch 607/1000\n",
      "524/524 [==============================] - 0s 554us/step - loss: 2.6568e-04 - mse: 2.6568e-04 - val_loss: 5.0941e-04 - val_mse: 5.0941e-04\n",
      "Epoch 608/1000\n",
      "524/524 [==============================] - 0s 556us/step - loss: 2.6355e-04 - mse: 2.6355e-04 - val_loss: 5.1488e-04 - val_mse: 5.1488e-04\n",
      "Epoch 609/1000\n",
      "524/524 [==============================] - 0s 519us/step - loss: 2.6364e-04 - mse: 2.6364e-04 - val_loss: 5.1502e-04 - val_mse: 5.1502e-04\n",
      "Epoch 610/1000\n",
      "524/524 [==============================] - 0s 512us/step - loss: 2.6387e-04 - mse: 2.6387e-04 - val_loss: 5.1133e-04 - val_mse: 5.1133e-04\n",
      "Epoch 611/1000\n",
      "524/524 [==============================] - 0s 525us/step - loss: 2.6118e-04 - mse: 2.6118e-04 - val_loss: 5.2296e-04 - val_mse: 5.2296e-04\n",
      "Epoch 612/1000\n",
      "524/524 [==============================] - 0s 535us/step - loss: 2.6219e-04 - mse: 2.6219e-04 - val_loss: 5.0489e-04 - val_mse: 5.0489e-04\n",
      "Epoch 613/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.6408e-04 - mse: 2.6408e-04 - val_loss: 5.0979e-04 - val_mse: 5.0979e-04\n",
      "Epoch 614/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.6355e-04 - mse: 2.6355e-04 - val_loss: 5.0891e-04 - val_mse: 5.0891e-04\n",
      "Epoch 615/1000\n",
      "524/524 [==============================] - 0s 521us/step - loss: 2.6107e-04 - mse: 2.6107e-04 - val_loss: 5.1626e-04 - val_mse: 5.1626e-04\n",
      "Epoch 616/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.6269e-04 - mse: 2.6269e-04 - val_loss: 5.1027e-04 - val_mse: 5.1027e-04\n",
      "Epoch 617/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.6240e-04 - mse: 2.6240e-04 - val_loss: 5.1090e-04 - val_mse: 5.1090e-04\n",
      "Epoch 618/1000\n",
      "524/524 [==============================] - 0s 516us/step - loss: 2.5867e-04 - mse: 2.5867e-04 - val_loss: 5.3925e-04 - val_mse: 5.3925e-04\n",
      "Epoch 619/1000\n",
      "524/524 [==============================] - 0s 525us/step - loss: 2.6112e-04 - mse: 2.6112e-04 - val_loss: 5.1571e-04 - val_mse: 5.1571e-04\n",
      "Epoch 620/1000\n",
      "524/524 [==============================] - 0s 545us/step - loss: 2.6205e-04 - mse: 2.6205e-04 - val_loss: 5.0885e-04 - val_mse: 5.0885e-04\n",
      "Epoch 621/1000\n",
      "524/524 [==============================] - 0s 518us/step - loss: 2.5892e-04 - mse: 2.5892e-04 - val_loss: 5.0972e-04 - val_mse: 5.0972e-04\n",
      "Epoch 622/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 2.6050e-04 - mse: 2.6050e-04 - val_loss: 5.0871e-04 - val_mse: 5.0871e-04\n",
      "Epoch 623/1000\n",
      "524/524 [==============================] - 0s 485us/step - loss: 2.5884e-04 - mse: 2.5884e-04 - val_loss: 5.1230e-04 - val_mse: 5.1230e-04\n",
      "Epoch 624/1000\n",
      "524/524 [==============================] - 0s 459us/step - loss: 2.5962e-04 - mse: 2.5962e-04 - val_loss: 5.3445e-04 - val_mse: 5.3445e-04\n",
      "Epoch 625/1000\n",
      "524/524 [==============================] - 0s 488us/step - loss: 2.6158e-04 - mse: 2.6158e-04 - val_loss: 5.0963e-04 - val_mse: 5.0963e-04\n",
      "Epoch 626/1000\n",
      "524/524 [==============================] - 0s 450us/step - loss: 2.6001e-04 - mse: 2.6001e-04 - val_loss: 4.9783e-04 - val_mse: 4.9783e-04\n",
      "Epoch 627/1000\n",
      "524/524 [==============================] - 0s 519us/step - loss: 2.6113e-04 - mse: 2.6113e-04 - val_loss: 5.0981e-04 - val_mse: 5.0981e-04\n",
      "Epoch 628/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.5907e-04 - mse: 2.5907e-04 - val_loss: 5.1954e-04 - val_mse: 5.1954e-04\n",
      "Epoch 629/1000\n",
      "524/524 [==============================] - 0s 534us/step - loss: 2.5980e-04 - mse: 2.5980e-04 - val_loss: 5.0880e-04 - val_mse: 5.0880e-04\n",
      "Epoch 630/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 2.5987e-04 - mse: 2.5987e-04 - val_loss: 5.1863e-04 - val_mse: 5.1863e-04\n",
      "Epoch 631/1000\n",
      "524/524 [==============================] - 0s 525us/step - loss: 2.5805e-04 - mse: 2.5805e-04 - val_loss: 5.0430e-04 - val_mse: 5.0430e-04\n",
      "Epoch 632/1000\n",
      "524/524 [==============================] - 0s 542us/step - loss: 2.5985e-04 - mse: 2.5985e-04 - val_loss: 5.1078e-04 - val_mse: 5.1078e-04\n",
      "Epoch 633/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 2.5805e-04 - mse: 2.5805e-04 - val_loss: 5.2410e-04 - val_mse: 5.2410e-04\n",
      "Epoch 634/1000\n",
      "524/524 [==============================] - 0s 589us/step - loss: 2.5944e-04 - mse: 2.5944e-04 - val_loss: 5.0238e-04 - val_mse: 5.0238e-04\n",
      "Epoch 635/1000\n",
      "524/524 [==============================] - 0s 622us/step - loss: 2.5740e-04 - mse: 2.5740e-04 - val_loss: 5.1469e-04 - val_mse: 5.1469e-04\n",
      "Epoch 636/1000\n",
      "524/524 [==============================] - 0s 579us/step - loss: 2.5894e-04 - mse: 2.5894e-04 - val_loss: 5.0661e-04 - val_mse: 5.0661e-04\n",
      "Epoch 637/1000\n",
      "524/524 [==============================] - 0s 629us/step - loss: 2.5713e-04 - mse: 2.5713e-04 - val_loss: 5.0563e-04 - val_mse: 5.0563e-04\n",
      "Epoch 638/1000\n",
      "524/524 [==============================] - 0s 609us/step - loss: 2.5889e-04 - mse: 2.5889e-04 - val_loss: 5.0576e-04 - val_mse: 5.0576e-04\n",
      "Epoch 639/1000\n",
      "524/524 [==============================] - 0s 548us/step - loss: 2.5831e-04 - mse: 2.5831e-04 - val_loss: 5.0767e-04 - val_mse: 5.0767e-04\n",
      "Epoch 640/1000\n",
      "524/524 [==============================] - 0s 537us/step - loss: 2.5910e-04 - mse: 2.5910e-04 - val_loss: 5.0938e-04 - val_mse: 5.0938e-04\n",
      "Epoch 641/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.5680e-04 - mse: 2.5680e-04 - val_loss: 5.0555e-04 - val_mse: 5.0555e-04\n",
      "Epoch 642/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.5628e-04 - mse: 2.5628e-04 - val_loss: 5.0579e-04 - val_mse: 5.0579e-04\n",
      "Epoch 643/1000\n",
      "524/524 [==============================] - 0s 547us/step - loss: 2.5820e-04 - mse: 2.5820e-04 - val_loss: 4.9519e-04 - val_mse: 4.9519e-04\n",
      "Epoch 644/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 2.5891e-04 - mse: 2.5891e-04 - val_loss: 5.0317e-04 - val_mse: 5.0317e-04\n",
      "Epoch 645/1000\n",
      "524/524 [==============================] - 0s 512us/step - loss: 2.5695e-04 - mse: 2.5695e-04 - val_loss: 5.0982e-04 - val_mse: 5.0982e-04\n",
      "Epoch 646/1000\n",
      "524/524 [==============================] - 0s 529us/step - loss: 2.5690e-04 - mse: 2.5690e-04 - val_loss: 5.0188e-04 - val_mse: 5.0188e-04\n",
      "Epoch 647/1000\n",
      "524/524 [==============================] - 0s 518us/step - loss: 2.5561e-04 - mse: 2.5561e-04 - val_loss: 5.1921e-04 - val_mse: 5.1921e-04\n",
      "Epoch 648/1000\n",
      "524/524 [==============================] - 0s 529us/step - loss: 2.5587e-04 - mse: 2.5587e-04 - val_loss: 5.0903e-04 - val_mse: 5.0903e-04\n",
      "Epoch 649/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.5726e-04 - mse: 2.5726e-04 - val_loss: 4.9981e-04 - val_mse: 4.9981e-04\n",
      "Epoch 650/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 2.5769e-04 - mse: 2.5769e-04 - val_loss: 5.0022e-04 - val_mse: 5.0022e-04\n",
      "Epoch 651/1000\n",
      "524/524 [==============================] - 0s 473us/step - loss: 2.5494e-04 - mse: 2.5494e-04 - val_loss: 5.1889e-04 - val_mse: 5.1889e-04\n",
      "Epoch 652/1000\n",
      "524/524 [==============================] - 0s 525us/step - loss: 2.5431e-04 - mse: 2.5431e-04 - val_loss: 5.0064e-04 - val_mse: 5.0064e-04\n",
      "Epoch 653/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.5523e-04 - mse: 2.5523e-04 - val_loss: 5.1214e-04 - val_mse: 5.1214e-04\n",
      "Epoch 654/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.5669e-04 - mse: 2.5669e-04 - val_loss: 5.0302e-04 - val_mse: 5.0302e-04\n",
      "Epoch 655/1000\n",
      "524/524 [==============================] - 0s 537us/step - loss: 2.5634e-04 - mse: 2.5634e-04 - val_loss: 5.0947e-04 - val_mse: 5.0947e-04\n",
      "Epoch 656/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.5458e-04 - mse: 2.5458e-04 - val_loss: 5.0031e-04 - val_mse: 5.0031e-04\n",
      "Epoch 657/1000\n",
      "524/524 [==============================] - 0s 529us/step - loss: 2.5577e-04 - mse: 2.5577e-04 - val_loss: 5.0032e-04 - val_mse: 5.0032e-04\n",
      "Epoch 658/1000\n",
      "524/524 [==============================] - 0s 538us/step - loss: 2.5450e-04 - mse: 2.5450e-04 - val_loss: 4.9859e-04 - val_mse: 4.9859e-04\n",
      "Epoch 659/1000\n",
      "524/524 [==============================] - 0s 463us/step - loss: 2.5616e-04 - mse: 2.5616e-04 - val_loss: 5.0207e-04 - val_mse: 5.0207e-04\n",
      "Epoch 660/1000\n",
      "524/524 [==============================] - 0s 529us/step - loss: 2.5605e-04 - mse: 2.5605e-04 - val_loss: 5.0410e-04 - val_mse: 5.0410e-04\n",
      "Epoch 661/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 2.5562e-04 - mse: 2.5562e-04 - val_loss: 5.0635e-04 - val_mse: 5.0635e-04\n",
      "Epoch 662/1000\n",
      "524/524 [==============================] - 0s 537us/step - loss: 2.5464e-04 - mse: 2.5464e-04 - val_loss: 4.9488e-04 - val_mse: 4.9488e-04\n",
      "Epoch 663/1000\n",
      "524/524 [==============================] - 0s 536us/step - loss: 2.5458e-04 - mse: 2.5458e-04 - val_loss: 5.0473e-04 - val_mse: 5.0473e-04\n",
      "Epoch 664/1000\n",
      "524/524 [==============================] - 0s 535us/step - loss: 2.5290e-04 - mse: 2.5290e-04 - val_loss: 4.9725e-04 - val_mse: 4.9725e-04\n",
      "Epoch 665/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.5407e-04 - mse: 2.5407e-04 - val_loss: 5.0092e-04 - val_mse: 5.0092e-04\n",
      "Epoch 666/1000\n",
      "524/524 [==============================] - 0s 533us/step - loss: 2.5405e-04 - mse: 2.5405e-04 - val_loss: 5.0897e-04 - val_mse: 5.0897e-04\n",
      "Epoch 667/1000\n",
      "524/524 [==============================] - 0s 514us/step - loss: 2.5493e-04 - mse: 2.5493e-04 - val_loss: 5.0038e-04 - val_mse: 5.0038e-04\n",
      "Epoch 668/1000\n",
      "524/524 [==============================] - 0s 533us/step - loss: 2.5320e-04 - mse: 2.5320e-04 - val_loss: 4.9753e-04 - val_mse: 4.9753e-04\n",
      "Epoch 669/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 2.5260e-04 - mse: 2.5260e-04 - val_loss: 5.1759e-04 - val_mse: 5.1759e-04\n",
      "Epoch 670/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 2.5407e-04 - mse: 2.5407e-04 - val_loss: 5.0409e-04 - val_mse: 5.0409e-04\n",
      "Epoch 671/1000\n",
      "524/524 [==============================] - 0s 529us/step - loss: 2.5205e-04 - mse: 2.5205e-04 - val_loss: 5.1028e-04 - val_mse: 5.1028e-04\n",
      "Epoch 672/1000\n",
      "524/524 [==============================] - 0s 532us/step - loss: 2.5273e-04 - mse: 2.5273e-04 - val_loss: 4.9141e-04 - val_mse: 4.9141e-04\n",
      "Epoch 673/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.5283e-04 - mse: 2.5283e-04 - val_loss: 4.9995e-04 - val_mse: 4.9995e-04\n",
      "Epoch 674/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.5299e-04 - mse: 2.5299e-04 - val_loss: 4.9950e-04 - val_mse: 4.9950e-04\n",
      "Epoch 675/1000\n",
      "524/524 [==============================] - 0s 532us/step - loss: 2.5295e-04 - mse: 2.5295e-04 - val_loss: 5.0984e-04 - val_mse: 5.0984e-04\n",
      "Epoch 676/1000\n",
      "524/524 [==============================] - 0s 516us/step - loss: 2.5137e-04 - mse: 2.5137e-04 - val_loss: 4.9659e-04 - val_mse: 4.9659e-04\n",
      "Epoch 677/1000\n",
      "524/524 [==============================] - 0s 534us/step - loss: 2.5265e-04 - mse: 2.5265e-04 - val_loss: 5.0502e-04 - val_mse: 5.0502e-04\n",
      "Epoch 678/1000\n",
      "524/524 [==============================] - 0s 477us/step - loss: 2.5034e-04 - mse: 2.5034e-04 - val_loss: 4.9574e-04 - val_mse: 4.9574e-04\n",
      "Epoch 679/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 2.5237e-04 - mse: 2.5237e-04 - val_loss: 5.0927e-04 - val_mse: 5.0927e-04\n",
      "Epoch 680/1000\n",
      "524/524 [==============================] - 0s 506us/step - loss: 2.5159e-04 - mse: 2.5159e-04 - val_loss: 5.0820e-04 - val_mse: 5.0820e-04\n",
      "Epoch 681/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 2.5270e-04 - mse: 2.5270e-04 - val_loss: 5.0134e-04 - val_mse: 5.0134e-04\n",
      "Epoch 682/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.5149e-04 - mse: 2.5149e-04 - val_loss: 4.9983e-04 - val_mse: 4.9983e-04\n",
      "Epoch 683/1000\n",
      "524/524 [==============================] - 0s 586us/step - loss: 2.4973e-04 - mse: 2.4973e-04 - val_loss: 5.1678e-04 - val_mse: 5.1678e-04\n",
      "Epoch 684/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.5217e-04 - mse: 2.5217e-04 - val_loss: 4.9926e-04 - val_mse: 4.9926e-04\n",
      "Epoch 685/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 2.4403e-04 - mse: 2.4403e-04 - val_loss: 5.3892e-04 - val_mse: 5.3892e-04\n",
      "Epoch 686/1000\n",
      "524/524 [==============================] - 0s 533us/step - loss: 2.5184e-04 - mse: 2.5184e-04 - val_loss: 4.9636e-04 - val_mse: 4.9636e-04\n",
      "Epoch 687/1000\n",
      "524/524 [==============================] - 0s 514us/step - loss: 2.5116e-04 - mse: 2.5116e-04 - val_loss: 4.9196e-04 - val_mse: 4.9196e-04\n",
      "Epoch 688/1000\n",
      "524/524 [==============================] - 0s 548us/step - loss: 2.5185e-04 - mse: 2.5185e-04 - val_loss: 5.0560e-04 - val_mse: 5.0560e-04\n",
      "Epoch 689/1000\n",
      "524/524 [==============================] - 0s 549us/step - loss: 2.5080e-04 - mse: 2.5080e-04 - val_loss: 5.0741e-04 - val_mse: 5.0741e-04\n",
      "Epoch 690/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 2.4947e-04 - mse: 2.4947e-04 - val_loss: 5.0991e-04 - val_mse: 5.0991e-04\n",
      "Epoch 691/1000\n",
      "524/524 [==============================] - 0s 578us/step - loss: 2.5108e-04 - mse: 2.5108e-04 - val_loss: 5.0625e-04 - val_mse: 5.0625e-04\n",
      "Epoch 692/1000\n",
      "524/524 [==============================] - 0s 633us/step - loss: 2.5056e-04 - mse: 2.5056e-04 - val_loss: 4.9992e-04 - val_mse: 4.9992e-04\n",
      "Epoch 693/1000\n",
      "524/524 [==============================] - 0s 650us/step - loss: 2.4889e-04 - mse: 2.4889e-04 - val_loss: 5.1108e-04 - val_mse: 5.1108e-04\n",
      "Epoch 694/1000\n",
      "524/524 [==============================] - 0s 660us/step - loss: 2.5099e-04 - mse: 2.5099e-04 - val_loss: 5.0101e-04 - val_mse: 5.0101e-04\n",
      "Epoch 695/1000\n",
      "524/524 [==============================] - 0s 613us/step - loss: 2.4813e-04 - mse: 2.4813e-04 - val_loss: 5.0670e-04 - val_mse: 5.0670e-04\n",
      "Epoch 696/1000\n",
      "524/524 [==============================] - 0s 555us/step - loss: 2.5086e-04 - mse: 2.5086e-04 - val_loss: 5.0329e-04 - val_mse: 5.0329e-04\n",
      "Epoch 697/1000\n",
      "524/524 [==============================] - 0s 534us/step - loss: 2.4854e-04 - mse: 2.4854e-04 - val_loss: 4.9630e-04 - val_mse: 4.9630e-04\n",
      "Epoch 698/1000\n",
      "524/524 [==============================] - 0s 540us/step - loss: 2.4835e-04 - mse: 2.4835e-04 - val_loss: 5.0851e-04 - val_mse: 5.0851e-04\n",
      "Epoch 699/1000\n",
      "524/524 [==============================] - 0s 521us/step - loss: 2.4932e-04 - mse: 2.4932e-04 - val_loss: 5.1245e-04 - val_mse: 5.1245e-04\n",
      "Epoch 700/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 2.4817e-04 - mse: 2.4817e-04 - val_loss: 5.0328e-04 - val_mse: 5.0328e-04\n",
      "Epoch 701/1000\n",
      "524/524 [==============================] - 0s 517us/step - loss: 2.4937e-04 - mse: 2.4937e-04 - val_loss: 4.9180e-04 - val_mse: 4.9180e-04\n",
      "Epoch 702/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.5033e-04 - mse: 2.5033e-04 - val_loss: 4.9576e-04 - val_mse: 4.9576e-04\n",
      "Epoch 703/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 2.4829e-04 - mse: 2.4829e-04 - val_loss: 5.1038e-04 - val_mse: 5.1038e-04\n",
      "Epoch 704/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.4904e-04 - mse: 2.4904e-04 - val_loss: 4.9165e-04 - val_mse: 4.9165e-04\n",
      "Epoch 705/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.4676e-04 - mse: 2.4676e-04 - val_loss: 4.9568e-04 - val_mse: 4.9568e-04\n",
      "Epoch 706/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.4775e-04 - mse: 2.4775e-04 - val_loss: 5.1182e-04 - val_mse: 5.1182e-04\n",
      "Epoch 707/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.4910e-04 - mse: 2.4910e-04 - val_loss: 4.9178e-04 - val_mse: 4.9178e-04\n",
      "Epoch 708/1000\n",
      "524/524 [==============================] - 0s 532us/step - loss: 2.4673e-04 - mse: 2.4673e-04 - val_loss: 5.0611e-04 - val_mse: 5.0611e-04\n",
      "Epoch 709/1000\n",
      "524/524 [==============================] - 0s 514us/step - loss: 2.4919e-04 - mse: 2.4919e-04 - val_loss: 5.0251e-04 - val_mse: 5.0251e-04\n",
      "Epoch 710/1000\n",
      "524/524 [==============================] - 0s 529us/step - loss: 2.4582e-04 - mse: 2.4582e-04 - val_loss: 5.0474e-04 - val_mse: 5.0474e-04\n",
      "Epoch 711/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 2.4771e-04 - mse: 2.4771e-04 - val_loss: 5.0486e-04 - val_mse: 5.0486e-04\n",
      "Epoch 712/1000\n",
      "524/524 [==============================] - 0s 547us/step - loss: 2.4713e-04 - mse: 2.4713e-04 - val_loss: 4.8542e-04 - val_mse: 4.8542e-04\n",
      "Epoch 713/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 2.4752e-04 - mse: 2.4752e-04 - val_loss: 4.9086e-04 - val_mse: 4.9086e-04\n",
      "Epoch 714/1000\n",
      "524/524 [==============================] - 0s 548us/step - loss: 2.4560e-04 - mse: 2.4560e-04 - val_loss: 4.8523e-04 - val_mse: 4.8523e-04\n",
      "Epoch 715/1000\n",
      "524/524 [==============================] - 0s 597us/step - loss: 2.4718e-04 - mse: 2.4718e-04 - val_loss: 4.9706e-04 - val_mse: 4.9706e-04\n",
      "Epoch 716/1000\n",
      "524/524 [==============================] - 0s 469us/step - loss: 2.4701e-04 - mse: 2.4701e-04 - val_loss: 4.8520e-04 - val_mse: 4.8520e-04\n",
      "Epoch 717/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.4585e-04 - mse: 2.4585e-04 - val_loss: 4.8853e-04 - val_mse: 4.8853e-04\n",
      "Epoch 718/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.4637e-04 - mse: 2.4637e-04 - val_loss: 4.8260e-04 - val_mse: 4.8260e-04\n",
      "Epoch 719/1000\n",
      "524/524 [==============================] - 0s 533us/step - loss: 2.4670e-04 - mse: 2.4670e-04 - val_loss: 4.9266e-04 - val_mse: 4.9266e-04\n",
      "Epoch 720/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.4588e-04 - mse: 2.4588e-04 - val_loss: 4.9369e-04 - val_mse: 4.9369e-04\n",
      "Epoch 721/1000\n",
      "524/524 [==============================] - 0s 525us/step - loss: 2.4581e-04 - mse: 2.4581e-04 - val_loss: 4.8897e-04 - val_mse: 4.8897e-04\n",
      "Epoch 722/1000\n",
      "524/524 [==============================] - 0s 525us/step - loss: 2.4686e-04 - mse: 2.4686e-04 - val_loss: 4.8838e-04 - val_mse: 4.8838e-04\n",
      "Epoch 723/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.4543e-04 - mse: 2.4543e-04 - val_loss: 4.9835e-04 - val_mse: 4.9835e-04\n",
      "Epoch 724/1000\n",
      "524/524 [==============================] - 0s 556us/step - loss: 2.4545e-04 - mse: 2.4545e-04 - val_loss: 4.9352e-04 - val_mse: 4.9352e-04\n",
      "Epoch 725/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.4269e-04 - mse: 2.4269e-04 - val_loss: 5.0545e-04 - val_mse: 5.0545e-04\n",
      "Epoch 726/1000\n",
      "524/524 [==============================] - 0s 539us/step - loss: 2.4230e-04 - mse: 2.4230e-04 - val_loss: 4.8472e-04 - val_mse: 4.8472e-04\n",
      "Epoch 727/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.4690e-04 - mse: 2.4690e-04 - val_loss: 4.9012e-04 - val_mse: 4.9012e-04\n",
      "Epoch 728/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.4523e-04 - mse: 2.4523e-04 - val_loss: 5.0135e-04 - val_mse: 5.0135e-04\n",
      "Epoch 729/1000\n",
      "524/524 [==============================] - 0s 539us/step - loss: 2.4480e-04 - mse: 2.4480e-04 - val_loss: 4.9527e-04 - val_mse: 4.9527e-04\n",
      "Epoch 730/1000\n",
      "524/524 [==============================] - 0s 537us/step - loss: 2.4387e-04 - mse: 2.4387e-04 - val_loss: 4.8181e-04 - val_mse: 4.8181e-04\n",
      "Epoch 731/1000\n",
      "524/524 [==============================] - 0s 517us/step - loss: 2.4325e-04 - mse: 2.4325e-04 - val_loss: 4.9896e-04 - val_mse: 4.9896e-04\n",
      "Epoch 732/1000\n",
      "524/524 [==============================] - 0s 564us/step - loss: 2.4444e-04 - mse: 2.4444e-04 - val_loss: 4.9387e-04 - val_mse: 4.9387e-04\n",
      "Epoch 733/1000\n",
      "524/524 [==============================] - 0s 523us/step - loss: 2.4386e-04 - mse: 2.4386e-04 - val_loss: 4.8876e-04 - val_mse: 4.8876e-04\n",
      "Epoch 734/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.4491e-04 - mse: 2.4491e-04 - val_loss: 4.8756e-04 - val_mse: 4.8756e-04\n",
      "Epoch 735/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.4553e-04 - mse: 2.4553e-04 - val_loss: 4.9712e-04 - val_mse: 4.9712e-04\n",
      "Epoch 736/1000\n",
      "524/524 [==============================] - 0s 516us/step - loss: 2.4240e-04 - mse: 2.4240e-04 - val_loss: 4.8636e-04 - val_mse: 4.8636e-04\n",
      "Epoch 737/1000\n",
      "524/524 [==============================] - 0s 532us/step - loss: 2.4455e-04 - mse: 2.4455e-04 - val_loss: 4.9182e-04 - val_mse: 4.9182e-04\n",
      "Epoch 738/1000\n",
      "524/524 [==============================] - 0s 519us/step - loss: 2.4293e-04 - mse: 2.4293e-04 - val_loss: 4.9190e-04 - val_mse: 4.9190e-04\n",
      "Epoch 739/1000\n",
      "524/524 [==============================] - 0s 529us/step - loss: 2.4378e-04 - mse: 2.4378e-04 - val_loss: 4.8463e-04 - val_mse: 4.8463e-04\n",
      "Epoch 740/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 2.4325e-04 - mse: 2.4325e-04 - val_loss: 4.9334e-04 - val_mse: 4.9334e-04\n",
      "Epoch 741/1000\n",
      "524/524 [==============================] - 0s 503us/step - loss: 2.4227e-04 - mse: 2.4227e-04 - val_loss: 4.8724e-04 - val_mse: 4.8724e-04\n",
      "Epoch 742/1000\n",
      "524/524 [==============================] - 0s 525us/step - loss: 2.4359e-04 - mse: 2.4359e-04 - val_loss: 4.9458e-04 - val_mse: 4.9458e-04\n",
      "Epoch 743/1000\n",
      "524/524 [==============================] - 0s 533us/step - loss: 2.4286e-04 - mse: 2.4286e-04 - val_loss: 4.9861e-04 - val_mse: 4.9861e-04\n",
      "Epoch 744/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.4216e-04 - mse: 2.4216e-04 - val_loss: 4.8204e-04 - val_mse: 4.8204e-04\n",
      "Epoch 745/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 2.4407e-04 - mse: 2.4407e-04 - val_loss: 4.8869e-04 - val_mse: 4.8869e-04\n",
      "Epoch 746/1000\n",
      "524/524 [==============================] - 0s 547us/step - loss: 2.3898e-04 - mse: 2.3898e-04 - val_loss: 5.0389e-04 - val_mse: 5.0389e-04\n",
      "Epoch 747/1000\n",
      "524/524 [==============================] - 0s 591us/step - loss: 2.4393e-04 - mse: 2.4393e-04 - val_loss: 4.9121e-04 - val_mse: 4.9121e-04\n",
      "Epoch 748/1000\n",
      "524/524 [==============================] - 0s 604us/step - loss: 2.4110e-04 - mse: 2.4110e-04 - val_loss: 4.9109e-04 - val_mse: 4.9109e-04\n",
      "Epoch 749/1000\n",
      "524/524 [==============================] - 0s 603us/step - loss: 2.4276e-04 - mse: 2.4276e-04 - val_loss: 4.9056e-04 - val_mse: 4.9056e-04\n",
      "Epoch 750/1000\n",
      "524/524 [==============================] - 0s 637us/step - loss: 2.4248e-04 - mse: 2.4248e-04 - val_loss: 4.9228e-04 - val_mse: 4.9228e-04\n",
      "Epoch 751/1000\n",
      "524/524 [==============================] - 0s 569us/step - loss: 2.3994e-04 - mse: 2.3994e-04 - val_loss: 5.0171e-04 - val_mse: 5.0171e-04\n",
      "Epoch 752/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 2.4276e-04 - mse: 2.4276e-04 - val_loss: 4.8818e-04 - val_mse: 4.8818e-04\n",
      "Epoch 753/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 2.4163e-04 - mse: 2.4163e-04 - val_loss: 4.8208e-04 - val_mse: 4.8208e-04\n",
      "Epoch 754/1000\n",
      "524/524 [==============================] - 0s 543us/step - loss: 2.4017e-04 - mse: 2.4017e-04 - val_loss: 4.8071e-04 - val_mse: 4.8071e-04\n",
      "Epoch 755/1000\n",
      "524/524 [==============================] - 0s 535us/step - loss: 2.4043e-04 - mse: 2.4043e-04 - val_loss: 4.9188e-04 - val_mse: 4.9188e-04\n",
      "Epoch 756/1000\n",
      "524/524 [==============================] - 0s 542us/step - loss: 2.4147e-04 - mse: 2.4147e-04 - val_loss: 4.9484e-04 - val_mse: 4.9484e-04\n",
      "Epoch 757/1000\n",
      "524/524 [==============================] - 0s 567us/step - loss: 2.4156e-04 - mse: 2.4156e-04 - val_loss: 4.9727e-04 - val_mse: 4.9727e-04\n",
      "Epoch 758/1000\n",
      "524/524 [==============================] - 0s 606us/step - loss: 2.3913e-04 - mse: 2.3913e-04 - val_loss: 4.8233e-04 - val_mse: 4.8233e-04\n",
      "Epoch 759/1000\n",
      "524/524 [==============================] - 0s 560us/step - loss: 2.4030e-04 - mse: 2.4030e-04 - val_loss: 5.0197e-04 - val_mse: 5.0197e-04\n",
      "Epoch 760/1000\n",
      "524/524 [==============================] - 0s 584us/step - loss: 2.3974e-04 - mse: 2.3974e-04 - val_loss: 4.9316e-04 - val_mse: 4.9316e-04\n",
      "Epoch 761/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.4095e-04 - mse: 2.4095e-04 - val_loss: 4.9042e-04 - val_mse: 4.9042e-04\n",
      "Epoch 762/1000\n",
      "524/524 [==============================] - 0s 537us/step - loss: 2.4093e-04 - mse: 2.4093e-04 - val_loss: 4.8669e-04 - val_mse: 4.8669e-04\n",
      "Epoch 763/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 2.4050e-04 - mse: 2.4050e-04 - val_loss: 4.9258e-04 - val_mse: 4.9258e-04\n",
      "Epoch 764/1000\n",
      "524/524 [==============================] - 0s 518us/step - loss: 2.3617e-04 - mse: 2.3617e-04 - val_loss: 5.0019e-04 - val_mse: 5.0019e-04\n",
      "Epoch 765/1000\n",
      "524/524 [==============================] - 0s 529us/step - loss: 2.4034e-04 - mse: 2.4034e-04 - val_loss: 4.8898e-04 - val_mse: 4.8898e-04\n",
      "Epoch 766/1000\n",
      "524/524 [==============================] - 0s 537us/step - loss: 2.3841e-04 - mse: 2.3841e-04 - val_loss: 4.8573e-04 - val_mse: 4.8573e-04\n",
      "Epoch 767/1000\n",
      "524/524 [==============================] - 0s 523us/step - loss: 2.4036e-04 - mse: 2.4036e-04 - val_loss: 4.8076e-04 - val_mse: 4.8076e-04\n",
      "Epoch 768/1000\n",
      "524/524 [==============================] - 0s 540us/step - loss: 2.3990e-04 - mse: 2.3990e-04 - val_loss: 4.9037e-04 - val_mse: 4.9037e-04\n",
      "Epoch 769/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.3752e-04 - mse: 2.3752e-04 - val_loss: 4.9705e-04 - val_mse: 4.9705e-04\n",
      "Epoch 770/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.4150e-04 - mse: 2.4150e-04 - val_loss: 4.8864e-04 - val_mse: 4.8864e-04\n",
      "Epoch 771/1000\n",
      "524/524 [==============================] - 0s 547us/step - loss: 2.3934e-04 - mse: 2.3934e-04 - val_loss: 4.7663e-04 - val_mse: 4.7663e-04\n",
      "Epoch 772/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 2.3902e-04 - mse: 2.3902e-04 - val_loss: 4.8839e-04 - val_mse: 4.8839e-04\n",
      "Epoch 773/1000\n",
      "524/524 [==============================] - 0s 533us/step - loss: 2.3650e-04 - mse: 2.3650e-04 - val_loss: 5.0813e-04 - val_mse: 5.0813e-04\n",
      "Epoch 774/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.3988e-04 - mse: 2.3988e-04 - val_loss: 4.8371e-04 - val_mse: 4.8371e-04\n",
      "Epoch 775/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.3892e-04 - mse: 2.3892e-04 - val_loss: 4.8537e-04 - val_mse: 4.8537e-04\n",
      "Epoch 776/1000\n",
      "524/524 [==============================] - 0s 638us/step - loss: 2.3883e-04 - mse: 2.3883e-04 - val_loss: 4.8269e-04 - val_mse: 4.8269e-04\n",
      "Epoch 777/1000\n",
      "524/524 [==============================] - 0s 587us/step - loss: 2.3761e-04 - mse: 2.3761e-04 - val_loss: 4.7452e-04 - val_mse: 4.7452e-04\n",
      "Epoch 778/1000\n",
      "524/524 [==============================] - 0s 563us/step - loss: 2.3750e-04 - mse: 2.3750e-04 - val_loss: 4.8461e-04 - val_mse: 4.8461e-04\n",
      "Epoch 779/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 2.3650e-04 - mse: 2.3650e-04 - val_loss: 5.0491e-04 - val_mse: 5.0491e-04\n",
      "Epoch 780/1000\n",
      "524/524 [==============================] - 0s 545us/step - loss: 2.3875e-04 - mse: 2.3875e-04 - val_loss: 4.8072e-04 - val_mse: 4.8072e-04\n",
      "Epoch 781/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.3827e-04 - mse: 2.3827e-04 - val_loss: 4.9140e-04 - val_mse: 4.9140e-04\n",
      "Epoch 782/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.3783e-04 - mse: 2.3783e-04 - val_loss: 4.9459e-04 - val_mse: 4.9459e-04\n",
      "Epoch 783/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.3885e-04 - mse: 2.3885e-04 - val_loss: 4.8671e-04 - val_mse: 4.8671e-04\n",
      "Epoch 784/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.3745e-04 - mse: 2.3745e-04 - val_loss: 4.8812e-04 - val_mse: 4.8812e-04\n",
      "Epoch 785/1000\n",
      "524/524 [==============================] - 0s 529us/step - loss: 2.3656e-04 - mse: 2.3656e-04 - val_loss: 5.0425e-04 - val_mse: 5.0425e-04\n",
      "Epoch 786/1000\n",
      "524/524 [==============================] - 0s 537us/step - loss: 2.3712e-04 - mse: 2.3712e-04 - val_loss: 4.8772e-04 - val_mse: 4.8772e-04\n",
      "Epoch 787/1000\n",
      "524/524 [==============================] - 0s 514us/step - loss: 2.3587e-04 - mse: 2.3587e-04 - val_loss: 4.9408e-04 - val_mse: 4.9408e-04\n",
      "Epoch 788/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.3674e-04 - mse: 2.3674e-04 - val_loss: 4.7584e-04 - val_mse: 4.7584e-04\n",
      "Epoch 789/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 2.3664e-04 - mse: 2.3664e-04 - val_loss: 4.8011e-04 - val_mse: 4.8011e-04\n",
      "Epoch 790/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.3587e-04 - mse: 2.3587e-04 - val_loss: 4.8345e-04 - val_mse: 4.8345e-04\n",
      "Epoch 791/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 2.3608e-04 - mse: 2.3608e-04 - val_loss: 4.8396e-04 - val_mse: 4.8396e-04\n",
      "Epoch 792/1000\n",
      "524/524 [==============================] - 0s 523us/step - loss: 2.3581e-04 - mse: 2.3581e-04 - val_loss: 4.7936e-04 - val_mse: 4.7936e-04\n",
      "Epoch 793/1000\n",
      "524/524 [==============================] - 0s 545us/step - loss: 2.3742e-04 - mse: 2.3742e-04 - val_loss: 4.8138e-04 - val_mse: 4.8138e-04\n",
      "Epoch 794/1000\n",
      "524/524 [==============================] - 0s 535us/step - loss: 2.3583e-04 - mse: 2.3583e-04 - val_loss: 4.9940e-04 - val_mse: 4.9940e-04\n",
      "Epoch 795/1000\n",
      "524/524 [==============================] - 0s 436us/step - loss: 2.3631e-04 - mse: 2.3631e-04 - val_loss: 4.9033e-04 - val_mse: 4.9033e-04\n",
      "Epoch 796/1000\n",
      "524/524 [==============================] - 0s 482us/step - loss: 2.3588e-04 - mse: 2.3588e-04 - val_loss: 4.8047e-04 - val_mse: 4.8047e-04\n",
      "Epoch 797/1000\n",
      "524/524 [==============================] - 0s 489us/step - loss: 2.3662e-04 - mse: 2.3662e-04 - val_loss: 4.8643e-04 - val_mse: 4.8643e-04\n",
      "Epoch 798/1000\n",
      "524/524 [==============================] - 0s 534us/step - loss: 2.3534e-04 - mse: 2.3534e-04 - val_loss: 4.8985e-04 - val_mse: 4.8985e-04\n",
      "Epoch 799/1000\n",
      "524/524 [==============================] - 0s 595us/step - loss: 2.3618e-04 - mse: 2.3618e-04 - val_loss: 4.8640e-04 - val_mse: 4.8640e-04\n",
      "Epoch 800/1000\n",
      "524/524 [==============================] - 0s 611us/step - loss: 2.3524e-04 - mse: 2.3524e-04 - val_loss: 4.9239e-04 - val_mse: 4.9239e-04\n",
      "Epoch 801/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 2.3483e-04 - mse: 2.3483e-04 - val_loss: 4.8414e-04 - val_mse: 4.8414e-04\n",
      "Epoch 802/1000\n",
      "524/524 [==============================] - 0s 603us/step - loss: 2.3633e-04 - mse: 2.3633e-04 - val_loss: 4.8071e-04 - val_mse: 4.8071e-04\n",
      "Epoch 803/1000\n",
      "524/524 [==============================] - 0s 652us/step - loss: 2.3628e-04 - mse: 2.3628e-04 - val_loss: 4.8277e-04 - val_mse: 4.8277e-04\n",
      "Epoch 804/1000\n",
      "524/524 [==============================] - 0s 635us/step - loss: 2.3384e-04 - mse: 2.3384e-04 - val_loss: 4.7387e-04 - val_mse: 4.7387e-04\n",
      "Epoch 805/1000\n",
      "524/524 [==============================] - 0s 672us/step - loss: 2.3552e-04 - mse: 2.3552e-04 - val_loss: 4.8029e-04 - val_mse: 4.8029e-04\n",
      "Epoch 806/1000\n",
      "524/524 [==============================] - 0s 670us/step - loss: 2.3404e-04 - mse: 2.3404e-04 - val_loss: 4.7208e-04 - val_mse: 4.7208e-04\n",
      "Epoch 807/1000\n",
      "524/524 [==============================] - 0s 586us/step - loss: 2.3438e-04 - mse: 2.3438e-04 - val_loss: 4.8507e-04 - val_mse: 4.8507e-04\n",
      "Epoch 808/1000\n",
      "524/524 [==============================] - 0s 577us/step - loss: 2.3484e-04 - mse: 2.3484e-04 - val_loss: 4.8822e-04 - val_mse: 4.8822e-04\n",
      "Epoch 809/1000\n",
      "524/524 [==============================] - 0s 539us/step - loss: 2.3552e-04 - mse: 2.3552e-04 - val_loss: 4.7684e-04 - val_mse: 4.7684e-04\n",
      "Epoch 810/1000\n",
      "524/524 [==============================] - 0s 603us/step - loss: 2.3358e-04 - mse: 2.3358e-04 - val_loss: 4.9145e-04 - val_mse: 4.9145e-04\n",
      "Epoch 811/1000\n",
      "524/524 [==============================] - 0s 529us/step - loss: 2.3405e-04 - mse: 2.3405e-04 - val_loss: 4.8316e-04 - val_mse: 4.8316e-04\n",
      "Epoch 812/1000\n",
      "524/524 [==============================] - 0s 465us/step - loss: 2.3426e-04 - mse: 2.3426e-04 - val_loss: 4.8732e-04 - val_mse: 4.8732e-04\n",
      "Epoch 813/1000\n",
      "524/524 [==============================] - 0s 477us/step - loss: 2.3357e-04 - mse: 2.3357e-04 - val_loss: 4.9809e-04 - val_mse: 4.9809e-04\n",
      "Epoch 814/1000\n",
      "524/524 [==============================] - 0s 533us/step - loss: 2.3303e-04 - mse: 2.3303e-04 - val_loss: 4.7529e-04 - val_mse: 4.7529e-04\n",
      "Epoch 815/1000\n",
      "524/524 [==============================] - 0s 515us/step - loss: 2.3451e-04 - mse: 2.3451e-04 - val_loss: 4.7395e-04 - val_mse: 4.7395e-04\n",
      "Epoch 816/1000\n",
      "524/524 [==============================] - 0s 541us/step - loss: 2.3330e-04 - mse: 2.3330e-04 - val_loss: 4.9341e-04 - val_mse: 4.9341e-04\n",
      "Epoch 817/1000\n",
      "524/524 [==============================] - 0s 537us/step - loss: 2.3343e-04 - mse: 2.3343e-04 - val_loss: 4.9276e-04 - val_mse: 4.9276e-04\n",
      "Epoch 818/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 2.3144e-04 - mse: 2.3144e-04 - val_loss: 4.7533e-04 - val_mse: 4.7533e-04\n",
      "Epoch 819/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 2.3464e-04 - mse: 2.3464e-04 - val_loss: 4.7935e-04 - val_mse: 4.7935e-04\n",
      "Epoch 820/1000\n",
      "524/524 [==============================] - 0s 565us/step - loss: 2.3305e-04 - mse: 2.3305e-04 - val_loss: 4.8600e-04 - val_mse: 4.8600e-04\n",
      "Epoch 821/1000\n",
      "524/524 [==============================] - 0s 569us/step - loss: 2.3119e-04 - mse: 2.3119e-04 - val_loss: 4.9727e-04 - val_mse: 4.9727e-04\n",
      "Epoch 822/1000\n",
      "524/524 [==============================] - 0s 532us/step - loss: 2.3265e-04 - mse: 2.3265e-04 - val_loss: 4.7547e-04 - val_mse: 4.7547e-04\n",
      "Epoch 823/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 2.3263e-04 - mse: 2.3263e-04 - val_loss: 4.7678e-04 - val_mse: 4.7678e-04\n",
      "Epoch 824/1000\n",
      "524/524 [==============================] - 0s 533us/step - loss: 2.3293e-04 - mse: 2.3293e-04 - val_loss: 4.9062e-04 - val_mse: 4.9062e-04\n",
      "Epoch 825/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.3267e-04 - mse: 2.3267e-04 - val_loss: 4.8144e-04 - val_mse: 4.8144e-04\n",
      "Epoch 826/1000\n",
      "524/524 [==============================] - 0s 518us/step - loss: 2.3018e-04 - mse: 2.3018e-04 - val_loss: 4.8221e-04 - val_mse: 4.8221e-04\n",
      "Epoch 827/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 2.3281e-04 - mse: 2.3281e-04 - val_loss: 4.8931e-04 - val_mse: 4.8931e-04\n",
      "Epoch 828/1000\n",
      "524/524 [==============================] - 0s 525us/step - loss: 2.2947e-04 - mse: 2.2947e-04 - val_loss: 4.8617e-04 - val_mse: 4.8617e-04\n",
      "Epoch 829/1000\n",
      "524/524 [==============================] - 0s 514us/step - loss: 2.3043e-04 - mse: 2.3043e-04 - val_loss: 4.8052e-04 - val_mse: 4.8052e-04\n",
      "Epoch 830/1000\n",
      "524/524 [==============================] - 0s 543us/step - loss: 2.3278e-04 - mse: 2.3278e-04 - val_loss: 4.7074e-04 - val_mse: 4.7074e-04\n",
      "Epoch 831/1000\n",
      "524/524 [==============================] - 0s 541us/step - loss: 2.3151e-04 - mse: 2.3151e-04 - val_loss: 4.7546e-04 - val_mse: 4.7546e-04\n",
      "Epoch 832/1000\n",
      "524/524 [==============================] - 0s 396us/step - loss: 2.3268e-04 - mse: 2.3268e-04 - val_loss: 4.7764e-04 - val_mse: 4.7764e-04\n",
      "Epoch 833/1000\n",
      "524/524 [==============================] - 0s 458us/step - loss: 2.3032e-04 - mse: 2.3032e-04 - val_loss: 4.8629e-04 - val_mse: 4.8629e-04\n",
      "Epoch 834/1000\n",
      "524/524 [==============================] - 0s 378us/step - loss: 2.3259e-04 - mse: 2.3259e-04 - val_loss: 4.8739e-04 - val_mse: 4.8739e-04\n",
      "Epoch 835/1000\n",
      "524/524 [==============================] - 0s 543us/step - loss: 2.3146e-04 - mse: 2.3146e-04 - val_loss: 4.6936e-04 - val_mse: 4.6936e-04\n",
      "Epoch 836/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.3034e-04 - mse: 2.3034e-04 - val_loss: 4.9016e-04 - val_mse: 4.9016e-04\n",
      "Epoch 837/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.3138e-04 - mse: 2.3138e-04 - val_loss: 4.7859e-04 - val_mse: 4.7859e-04\n",
      "Epoch 838/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.3159e-04 - mse: 2.3159e-04 - val_loss: 4.8520e-04 - val_mse: 4.8520e-04\n",
      "Epoch 839/1000\n",
      "524/524 [==============================] - 0s 537us/step - loss: 2.2977e-04 - mse: 2.2977e-04 - val_loss: 4.6781e-04 - val_mse: 4.6781e-04\n",
      "Epoch 840/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.3100e-04 - mse: 2.3100e-04 - val_loss: 4.6948e-04 - val_mse: 4.6948e-04\n",
      "Epoch 841/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.3041e-04 - mse: 2.3041e-04 - val_loss: 4.7584e-04 - val_mse: 4.7584e-04\n",
      "Epoch 842/1000\n",
      "524/524 [==============================] - 0s 532us/step - loss: 2.2949e-04 - mse: 2.2949e-04 - val_loss: 4.7213e-04 - val_mse: 4.7213e-04\n",
      "Epoch 843/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 2.3029e-04 - mse: 2.3029e-04 - val_loss: 4.7694e-04 - val_mse: 4.7694e-04\n",
      "Epoch 844/1000\n",
      "524/524 [==============================] - 0s 531us/step - loss: 2.2917e-04 - mse: 2.2917e-04 - val_loss: 4.9293e-04 - val_mse: 4.9293e-04\n",
      "Epoch 845/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 2.2999e-04 - mse: 2.2999e-04 - val_loss: 4.7235e-04 - val_mse: 4.7235e-04\n",
      "Epoch 846/1000\n",
      "524/524 [==============================] - 0s 533us/step - loss: 2.2919e-04 - mse: 2.2919e-04 - val_loss: 4.8790e-04 - val_mse: 4.8790e-04\n",
      "Epoch 847/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.3044e-04 - mse: 2.3044e-04 - val_loss: 4.7026e-04 - val_mse: 4.7026e-04\n",
      "Epoch 848/1000\n",
      "524/524 [==============================] - 0s 539us/step - loss: 2.3095e-04 - mse: 2.3095e-04 - val_loss: 4.7046e-04 - val_mse: 4.7046e-04\n",
      "Epoch 849/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.2959e-04 - mse: 2.2959e-04 - val_loss: 4.8356e-04 - val_mse: 4.8356e-04\n",
      "Epoch 850/1000\n",
      "524/524 [==============================] - 0s 533us/step - loss: 2.3030e-04 - mse: 2.3030e-04 - val_loss: 4.7516e-04 - val_mse: 4.7516e-04\n",
      "Epoch 851/1000\n",
      "524/524 [==============================] - 0s 532us/step - loss: 2.2994e-04 - mse: 2.2994e-04 - val_loss: 4.7602e-04 - val_mse: 4.7602e-04\n",
      "Epoch 852/1000\n",
      "524/524 [==============================] - 0s 521us/step - loss: 2.2931e-04 - mse: 2.2931e-04 - val_loss: 4.8268e-04 - val_mse: 4.8268e-04\n",
      "Epoch 853/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 2.3063e-04 - mse: 2.3063e-04 - val_loss: 4.8060e-04 - val_mse: 4.8060e-04\n",
      "Epoch 854/1000\n",
      "524/524 [==============================] - 0s 534us/step - loss: 2.2946e-04 - mse: 2.2946e-04 - val_loss: 4.8073e-04 - val_mse: 4.8073e-04\n",
      "Epoch 855/1000\n",
      "524/524 [==============================] - 0s 514us/step - loss: 2.2760e-04 - mse: 2.2760e-04 - val_loss: 4.8059e-04 - val_mse: 4.8059e-04\n",
      "Epoch 856/1000\n",
      "524/524 [==============================] - 0s 529us/step - loss: 2.2896e-04 - mse: 2.2896e-04 - val_loss: 4.7429e-04 - val_mse: 4.7429e-04\n",
      "Epoch 857/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.2919e-04 - mse: 2.2919e-04 - val_loss: 4.7286e-04 - val_mse: 4.7286e-04\n",
      "Epoch 858/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 2.2980e-04 - mse: 2.2980e-04 - val_loss: 4.7248e-04 - val_mse: 4.7248e-04\n",
      "Epoch 859/1000\n",
      "524/524 [==============================] - 0s 575us/step - loss: 2.2938e-04 - mse: 2.2938e-04 - val_loss: 4.7120e-04 - val_mse: 4.7120e-04\n",
      "Epoch 860/1000\n",
      "524/524 [==============================] - 0s 609us/step - loss: 2.2930e-04 - mse: 2.2930e-04 - val_loss: 4.7547e-04 - val_mse: 4.7547e-04\n",
      "Epoch 861/1000\n",
      "524/524 [==============================] - 0s 609us/step - loss: 2.2846e-04 - mse: 2.2846e-04 - val_loss: 4.7344e-04 - val_mse: 4.7344e-04\n",
      "Epoch 862/1000\n",
      "524/524 [==============================] - 0s 615us/step - loss: 2.2626e-04 - mse: 2.2626e-04 - val_loss: 4.8537e-04 - val_mse: 4.8537e-04\n",
      "Epoch 863/1000\n",
      "524/524 [==============================] - 0s 621us/step - loss: 2.2768e-04 - mse: 2.2768e-04 - val_loss: 4.8097e-04 - val_mse: 4.8097e-04\n",
      "Epoch 864/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 2.2818e-04 - mse: 2.2818e-04 - val_loss: 4.7711e-04 - val_mse: 4.7711e-04\n",
      "Epoch 865/1000\n",
      "524/524 [==============================] - 0s 515us/step - loss: 2.2742e-04 - mse: 2.2742e-04 - val_loss: 4.8357e-04 - val_mse: 4.8357e-04\n",
      "Epoch 866/1000\n",
      "524/524 [==============================] - 0s 514us/step - loss: 2.2762e-04 - mse: 2.2762e-04 - val_loss: 4.6942e-04 - val_mse: 4.6942e-04\n",
      "Epoch 867/1000\n",
      "524/524 [==============================] - 0s 516us/step - loss: 2.2613e-04 - mse: 2.2613e-04 - val_loss: 4.8862e-04 - val_mse: 4.8862e-04\n",
      "Epoch 868/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 2.2732e-04 - mse: 2.2732e-04 - val_loss: 4.9306e-04 - val_mse: 4.9306e-04\n",
      "Epoch 869/1000\n",
      "524/524 [==============================] - 0s 515us/step - loss: 2.2795e-04 - mse: 2.2795e-04 - val_loss: 4.6948e-04 - val_mse: 4.6948e-04\n",
      "Epoch 870/1000\n",
      "524/524 [==============================] - 0s 539us/step - loss: 2.2623e-04 - mse: 2.2623e-04 - val_loss: 4.7762e-04 - val_mse: 4.7762e-04\n",
      "Epoch 871/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 2.2612e-04 - mse: 2.2612e-04 - val_loss: 4.8362e-04 - val_mse: 4.8362e-04\n",
      "Epoch 872/1000\n",
      "524/524 [==============================] - 0s 515us/step - loss: 2.2672e-04 - mse: 2.2672e-04 - val_loss: 4.8678e-04 - val_mse: 4.8678e-04\n",
      "Epoch 873/1000\n",
      "524/524 [==============================] - 0s 516us/step - loss: 2.2732e-04 - mse: 2.2732e-04 - val_loss: 4.6948e-04 - val_mse: 4.6948e-04\n",
      "Epoch 874/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.2834e-04 - mse: 2.2834e-04 - val_loss: 4.7572e-04 - val_mse: 4.7572e-04\n",
      "Epoch 875/1000\n",
      "524/524 [==============================] - 0s 524us/step - loss: 2.2364e-04 - mse: 2.2364e-04 - val_loss: 5.0032e-04 - val_mse: 5.0032e-04\n",
      "Epoch 876/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.2714e-04 - mse: 2.2714e-04 - val_loss: 4.7379e-04 - val_mse: 4.7379e-04\n",
      "Epoch 877/1000\n",
      "524/524 [==============================] - 0s 542us/step - loss: 2.2532e-04 - mse: 2.2532e-04 - val_loss: 4.6400e-04 - val_mse: 4.6400e-04\n",
      "Epoch 878/1000\n",
      "524/524 [==============================] - 0s 515us/step - loss: 2.2682e-04 - mse: 2.2682e-04 - val_loss: 4.7624e-04 - val_mse: 4.7624e-04\n",
      "Epoch 879/1000\n",
      "524/524 [==============================] - 0s 514us/step - loss: 2.2632e-04 - mse: 2.2632e-04 - val_loss: 4.7839e-04 - val_mse: 4.7839e-04\n",
      "Epoch 880/1000\n",
      "524/524 [==============================] - 0s 514us/step - loss: 2.2638e-04 - mse: 2.2638e-04 - val_loss: 4.7729e-04 - val_mse: 4.7729e-04\n",
      "Epoch 881/1000\n",
      "524/524 [==============================] - 0s 508us/step - loss: 2.2626e-04 - mse: 2.2626e-04 - val_loss: 4.8158e-04 - val_mse: 4.8158e-04\n",
      "Epoch 882/1000\n",
      "524/524 [==============================] - 0s 544us/step - loss: 2.2698e-04 - mse: 2.2698e-04 - val_loss: 4.6844e-04 - val_mse: 4.6844e-04\n",
      "Epoch 883/1000\n",
      "524/524 [==============================] - 0s 571us/step - loss: 2.2593e-04 - mse: 2.2593e-04 - val_loss: 4.7286e-04 - val_mse: 4.7286e-04\n",
      "Epoch 884/1000\n",
      "524/524 [==============================] - 0s 544us/step - loss: 2.2670e-04 - mse: 2.2670e-04 - val_loss: 4.6896e-04 - val_mse: 4.6896e-04\n",
      "Epoch 885/1000\n",
      "524/524 [==============================] - 0s 540us/step - loss: 2.2530e-04 - mse: 2.2530e-04 - val_loss: 4.6574e-04 - val_mse: 4.6574e-04\n",
      "Epoch 886/1000\n",
      "524/524 [==============================] - 0s 588us/step - loss: 2.2622e-04 - mse: 2.2622e-04 - val_loss: 4.7357e-04 - val_mse: 4.7357e-04\n",
      "Epoch 887/1000\n",
      "524/524 [==============================] - 0s 562us/step - loss: 2.2320e-04 - mse: 2.2320e-04 - val_loss: 4.9484e-04 - val_mse: 4.9484e-04\n",
      "Epoch 888/1000\n",
      "524/524 [==============================] - 0s 550us/step - loss: 2.2571e-04 - mse: 2.2571e-04 - val_loss: 4.6529e-04 - val_mse: 4.6529e-04\n",
      "Epoch 889/1000\n",
      "524/524 [==============================] - 0s 581us/step - loss: 2.2456e-04 - mse: 2.2456e-04 - val_loss: 4.7516e-04 - val_mse: 4.7516e-04\n",
      "Epoch 890/1000\n",
      "524/524 [==============================] - 0s 560us/step - loss: 2.2501e-04 - mse: 2.2501e-04 - val_loss: 4.7492e-04 - val_mse: 4.7492e-04\n",
      "Epoch 891/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.2446e-04 - mse: 2.2446e-04 - val_loss: 4.7128e-04 - val_mse: 4.7128e-04\n",
      "Epoch 892/1000\n",
      "524/524 [==============================] - 0s 514us/step - loss: 2.2518e-04 - mse: 2.2518e-04 - val_loss: 4.7247e-04 - val_mse: 4.7247e-04\n",
      "Epoch 893/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.2407e-04 - mse: 2.2407e-04 - val_loss: 4.6752e-04 - val_mse: 4.6752e-04\n",
      "Epoch 894/1000\n",
      "524/524 [==============================] - 0s 537us/step - loss: 2.2414e-04 - mse: 2.2414e-04 - val_loss: 4.7905e-04 - val_mse: 4.7905e-04\n",
      "Epoch 895/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 2.2543e-04 - mse: 2.2543e-04 - val_loss: 4.6835e-04 - val_mse: 4.6835e-04\n",
      "Epoch 896/1000\n",
      "524/524 [==============================] - 0s 554us/step - loss: 2.2500e-04 - mse: 2.2500e-04 - val_loss: 4.6248e-04 - val_mse: 4.6248e-04\n",
      "Epoch 897/1000\n",
      "524/524 [==============================] - 0s 527us/step - loss: 2.2466e-04 - mse: 2.2466e-04 - val_loss: 4.7205e-04 - val_mse: 4.7205e-04\n",
      "Epoch 898/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.2478e-04 - mse: 2.2478e-04 - val_loss: 4.6688e-04 - val_mse: 4.6688e-04\n",
      "Epoch 899/1000\n",
      "524/524 [==============================] - 0s 512us/step - loss: 2.2466e-04 - mse: 2.2466e-04 - val_loss: 4.6481e-04 - val_mse: 4.6481e-04\n",
      "Epoch 900/1000\n",
      "524/524 [==============================] - 0s 523us/step - loss: 2.2155e-04 - mse: 2.2155e-04 - val_loss: 4.5995e-04 - val_mse: 4.5995e-04\n",
      "Epoch 901/1000\n",
      "524/524 [==============================] - 0s 512us/step - loss: 2.2397e-04 - mse: 2.2397e-04 - val_loss: 4.6551e-04 - val_mse: 4.6551e-04\n",
      "Epoch 902/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.2385e-04 - mse: 2.2385e-04 - val_loss: 4.8020e-04 - val_mse: 4.8020e-04\n",
      "Epoch 903/1000\n",
      "524/524 [==============================] - 0s 521us/step - loss: 2.2460e-04 - mse: 2.2460e-04 - val_loss: 4.6830e-04 - val_mse: 4.6830e-04\n",
      "Epoch 904/1000\n",
      "524/524 [==============================] - 0s 479us/step - loss: 2.2275e-04 - mse: 2.2275e-04 - val_loss: 4.5976e-04 - val_mse: 4.5976e-04\n",
      "Epoch 905/1000\n",
      "524/524 [==============================] - 0s 417us/step - loss: 2.2205e-04 - mse: 2.2205e-04 - val_loss: 4.8032e-04 - val_mse: 4.8032e-04\n",
      "Epoch 906/1000\n",
      "524/524 [==============================] - 0s 533us/step - loss: 2.2241e-04 - mse: 2.2241e-04 - val_loss: 4.9099e-04 - val_mse: 4.9099e-04\n",
      "Epoch 907/1000\n",
      "524/524 [==============================] - 0s 513us/step - loss: 2.2440e-04 - mse: 2.2440e-04 - val_loss: 4.7212e-04 - val_mse: 4.7212e-04\n",
      "Epoch 908/1000\n",
      "524/524 [==============================] - 0s 514us/step - loss: 2.2453e-04 - mse: 2.2453e-04 - val_loss: 4.6362e-04 - val_mse: 4.6362e-04\n",
      "Epoch 909/1000\n",
      "524/524 [==============================] - 0s 509us/step - loss: 2.2316e-04 - mse: 2.2316e-04 - val_loss: 4.6697e-04 - val_mse: 4.6697e-04\n",
      "Epoch 910/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.2238e-04 - mse: 2.2238e-04 - val_loss: 4.6820e-04 - val_mse: 4.6820e-04\n",
      "Epoch 911/1000\n",
      "524/524 [==============================] - 0s 514us/step - loss: 2.2251e-04 - mse: 2.2251e-04 - val_loss: 4.7437e-04 - val_mse: 4.7437e-04\n",
      "Epoch 912/1000\n",
      "524/524 [==============================] - 0s 514us/step - loss: 2.2306e-04 - mse: 2.2306e-04 - val_loss: 4.6506e-04 - val_mse: 4.6506e-04\n",
      "Epoch 913/1000\n",
      "524/524 [==============================] - 0s 513us/step - loss: 2.2171e-04 - mse: 2.2171e-04 - val_loss: 4.8287e-04 - val_mse: 4.8287e-04\n",
      "Epoch 914/1000\n",
      "524/524 [==============================] - 0s 518us/step - loss: 2.2269e-04 - mse: 2.2269e-04 - val_loss: 4.6957e-04 - val_mse: 4.6957e-04\n",
      "Epoch 915/1000\n",
      "524/524 [==============================] - 0s 533us/step - loss: 2.2170e-04 - mse: 2.2170e-04 - val_loss: 4.7326e-04 - val_mse: 4.7326e-04\n",
      "Epoch 916/1000\n",
      "524/524 [==============================] - 0s 568us/step - loss: 2.2133e-04 - mse: 2.2133e-04 - val_loss: 4.8765e-04 - val_mse: 4.8765e-04\n",
      "Epoch 917/1000\n",
      "524/524 [==============================] - 0s 610us/step - loss: 2.2279e-04 - mse: 2.2279e-04 - val_loss: 4.6767e-04 - val_mse: 4.6767e-04\n",
      "Epoch 918/1000\n",
      "524/524 [==============================] - 0s 624us/step - loss: 2.2161e-04 - mse: 2.2161e-04 - val_loss: 4.7409e-04 - val_mse: 4.7409e-04\n",
      "Epoch 919/1000\n",
      "524/524 [==============================] - 0s 606us/step - loss: 2.2247e-04 - mse: 2.2247e-04 - val_loss: 4.6425e-04 - val_mse: 4.6425e-04\n",
      "Epoch 920/1000\n",
      "524/524 [==============================] - 0s 639us/step - loss: 2.2087e-04 - mse: 2.2087e-04 - val_loss: 4.8061e-04 - val_mse: 4.8061e-04\n",
      "Epoch 921/1000\n",
      "524/524 [==============================] - 0s 533us/step - loss: 2.2228e-04 - mse: 2.2228e-04 - val_loss: 4.7458e-04 - val_mse: 4.7458e-04\n",
      "Epoch 922/1000\n",
      "524/524 [==============================] - 0s 508us/step - loss: 2.2180e-04 - mse: 2.2180e-04 - val_loss: 4.6196e-04 - val_mse: 4.6196e-04\n",
      "Epoch 923/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 2.2155e-04 - mse: 2.2155e-04 - val_loss: 4.6191e-04 - val_mse: 4.6191e-04\n",
      "Epoch 924/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 2.2136e-04 - mse: 2.2136e-04 - val_loss: 4.5952e-04 - val_mse: 4.5952e-04\n",
      "Epoch 925/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.2139e-04 - mse: 2.2139e-04 - val_loss: 4.6513e-04 - val_mse: 4.6513e-04\n",
      "Epoch 926/1000\n",
      "524/524 [==============================] - 0s 525us/step - loss: 2.2153e-04 - mse: 2.2153e-04 - val_loss: 4.6255e-04 - val_mse: 4.6255e-04\n",
      "Epoch 927/1000\n",
      "524/524 [==============================] - 0s 521us/step - loss: 2.2138e-04 - mse: 2.2138e-04 - val_loss: 4.7197e-04 - val_mse: 4.7197e-04\n",
      "Epoch 928/1000\n",
      "524/524 [==============================] - 0s 572us/step - loss: 2.2154e-04 - mse: 2.2154e-04 - val_loss: 4.7022e-04 - val_mse: 4.7022e-04\n",
      "Epoch 929/1000\n",
      "524/524 [==============================] - 0s 559us/step - loss: 2.2000e-04 - mse: 2.2000e-04 - val_loss: 4.6680e-04 - val_mse: 4.6680e-04\n",
      "Epoch 930/1000\n",
      "524/524 [==============================] - 0s 518us/step - loss: 2.1910e-04 - mse: 2.1910e-04 - val_loss: 4.5988e-04 - val_mse: 4.5988e-04\n",
      "Epoch 931/1000\n",
      "524/524 [==============================] - 0s 518us/step - loss: 2.1937e-04 - mse: 2.1937e-04 - val_loss: 4.6413e-04 - val_mse: 4.6413e-04\n",
      "Epoch 932/1000\n",
      "524/524 [==============================] - 0s 516us/step - loss: 2.2127e-04 - mse: 2.2127e-04 - val_loss: 4.6920e-04 - val_mse: 4.6920e-04\n",
      "Epoch 933/1000\n",
      "524/524 [==============================] - 0s 517us/step - loss: 2.2067e-04 - mse: 2.2067e-04 - val_loss: 4.6144e-04 - val_mse: 4.6144e-04\n",
      "Epoch 934/1000\n",
      "524/524 [==============================] - 0s 521us/step - loss: 2.2055e-04 - mse: 2.2055e-04 - val_loss: 4.6563e-04 - val_mse: 4.6563e-04\n",
      "Epoch 935/1000\n",
      "524/524 [==============================] - 0s 536us/step - loss: 2.2040e-04 - mse: 2.2040e-04 - val_loss: 4.6824e-04 - val_mse: 4.6824e-04\n",
      "Epoch 936/1000\n",
      "524/524 [==============================] - 0s 517us/step - loss: 2.2090e-04 - mse: 2.2090e-04 - val_loss: 4.6150e-04 - val_mse: 4.6150e-04\n",
      "Epoch 937/1000\n",
      "524/524 [==============================] - 0s 517us/step - loss: 2.2097e-04 - mse: 2.2097e-04 - val_loss: 4.6144e-04 - val_mse: 4.6144e-04\n",
      "Epoch 938/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 2.1965e-04 - mse: 2.1965e-04 - val_loss: 4.6765e-04 - val_mse: 4.6765e-04\n",
      "Epoch 939/1000\n",
      "524/524 [==============================] - 0s 514us/step - loss: 2.2134e-04 - mse: 2.2134e-04 - val_loss: 4.6479e-04 - val_mse: 4.6479e-04\n",
      "Epoch 940/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.1977e-04 - mse: 2.1977e-04 - val_loss: 4.7122e-04 - val_mse: 4.7122e-04\n",
      "Epoch 941/1000\n",
      "524/524 [==============================] - 0s 534us/step - loss: 2.1862e-04 - mse: 2.1862e-04 - val_loss: 4.8026e-04 - val_mse: 4.8026e-04\n",
      "Epoch 942/1000\n",
      "524/524 [==============================] - 0s 529us/step - loss: 2.2091e-04 - mse: 2.2091e-04 - val_loss: 4.6327e-04 - val_mse: 4.6327e-04\n",
      "Epoch 943/1000\n",
      "524/524 [==============================] - 0s 530us/step - loss: 2.1878e-04 - mse: 2.1878e-04 - val_loss: 4.6653e-04 - val_mse: 4.6653e-04\n",
      "Epoch 944/1000\n",
      "524/524 [==============================] - 0s 433us/step - loss: 2.1919e-04 - mse: 2.1919e-04 - val_loss: 4.4923e-04 - val_mse: 4.4923e-04\n",
      "Epoch 945/1000\n",
      "524/524 [==============================] - 0s 482us/step - loss: 2.1454e-04 - mse: 2.1454e-04 - val_loss: 4.8461e-04 - val_mse: 4.8461e-04\n",
      "Epoch 946/1000\n",
      "524/524 [==============================] - 0s 491us/step - loss: 2.1970e-04 - mse: 2.1970e-04 - val_loss: 4.7717e-04 - val_mse: 4.7717e-04\n",
      "Epoch 947/1000\n",
      "524/524 [==============================] - 0s 507us/step - loss: 2.1942e-04 - mse: 2.1942e-04 - val_loss: 4.6149e-04 - val_mse: 4.6149e-04\n",
      "Epoch 948/1000\n",
      "524/524 [==============================] - 0s 534us/step - loss: 2.1952e-04 - mse: 2.1952e-04 - val_loss: 4.6418e-04 - val_mse: 4.6418e-04\n",
      "Epoch 949/1000\n",
      "524/524 [==============================] - 0s 526us/step - loss: 2.1873e-04 - mse: 2.1873e-04 - val_loss: 4.6519e-04 - val_mse: 4.6519e-04\n",
      "Epoch 950/1000\n",
      "524/524 [==============================] - 0s 482us/step - loss: 2.1902e-04 - mse: 2.1902e-04 - val_loss: 4.6759e-04 - val_mse: 4.6759e-04\n",
      "Epoch 951/1000\n",
      "524/524 [==============================] - 0s 495us/step - loss: 2.1853e-04 - mse: 2.1853e-04 - val_loss: 4.7170e-04 - val_mse: 4.7170e-04\n",
      "Epoch 952/1000\n",
      "524/524 [==============================] - 0s 464us/step - loss: 2.1827e-04 - mse: 2.1827e-04 - val_loss: 4.6934e-04 - val_mse: 4.6934e-04\n",
      "Epoch 953/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 2.1598e-04 - mse: 2.1598e-04 - val_loss: 4.6171e-04 - val_mse: 4.6171e-04\n",
      "Epoch 954/1000\n",
      "524/524 [==============================] - 0s 518us/step - loss: 2.1809e-04 - mse: 2.1809e-04 - val_loss: 4.7658e-04 - val_mse: 4.7658e-04\n",
      "Epoch 955/1000\n",
      "524/524 [==============================] - 0s 512us/step - loss: 2.1890e-04 - mse: 2.1890e-04 - val_loss: 4.5982e-04 - val_mse: 4.5982e-04\n",
      "Epoch 956/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.1925e-04 - mse: 2.1925e-04 - val_loss: 4.6661e-04 - val_mse: 4.6661e-04\n",
      "Epoch 957/1000\n",
      "524/524 [==============================] - 0s 514us/step - loss: 2.1878e-04 - mse: 2.1878e-04 - val_loss: 4.6281e-04 - val_mse: 4.6281e-04\n",
      "Epoch 958/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.1782e-04 - mse: 2.1782e-04 - val_loss: 4.6093e-04 - val_mse: 4.6093e-04\n",
      "Epoch 959/1000\n",
      "524/524 [==============================] - 0s 521us/step - loss: 2.1755e-04 - mse: 2.1755e-04 - val_loss: 4.6930e-04 - val_mse: 4.6930e-04\n",
      "Epoch 960/1000\n",
      "524/524 [==============================] - 0s 517us/step - loss: 2.1534e-04 - mse: 2.1534e-04 - val_loss: 4.5527e-04 - val_mse: 4.5527e-04\n",
      "Epoch 961/1000\n",
      "524/524 [==============================] - 0s 535us/step - loss: 2.1886e-04 - mse: 2.1886e-04 - val_loss: 4.5721e-04 - val_mse: 4.5721e-04\n",
      "Epoch 962/1000\n",
      "524/524 [==============================] - 0s 516us/step - loss: 2.1765e-04 - mse: 2.1765e-04 - val_loss: 4.6355e-04 - val_mse: 4.6355e-04\n",
      "Epoch 963/1000\n",
      "524/524 [==============================] - 0s 516us/step - loss: 2.1801e-04 - mse: 2.1801e-04 - val_loss: 4.5768e-04 - val_mse: 4.5768e-04\n",
      "Epoch 964/1000\n",
      "524/524 [==============================] - 0s 532us/step - loss: 2.1704e-04 - mse: 2.1704e-04 - val_loss: 4.5174e-04 - val_mse: 4.5174e-04\n",
      "Epoch 965/1000\n",
      "524/524 [==============================] - 0s 514us/step - loss: 2.1821e-04 - mse: 2.1821e-04 - val_loss: 4.5742e-04 - val_mse: 4.5742e-04\n",
      "Epoch 966/1000\n",
      "524/524 [==============================] - 0s 510us/step - loss: 2.1603e-04 - mse: 2.1603e-04 - val_loss: 4.7718e-04 - val_mse: 4.7718e-04\n",
      "Epoch 967/1000\n",
      "524/524 [==============================] - 0s 522us/step - loss: 2.1693e-04 - mse: 2.1693e-04 - val_loss: 4.5652e-04 - val_mse: 4.5652e-04\n",
      "Epoch 968/1000\n",
      "524/524 [==============================] - 0s 518us/step - loss: 2.1702e-04 - mse: 2.1702e-04 - val_loss: 4.5400e-04 - val_mse: 4.5400e-04\n",
      "Epoch 969/1000\n",
      "524/524 [==============================] - 0s 528us/step - loss: 2.1720e-04 - mse: 2.1720e-04 - val_loss: 4.7143e-04 - val_mse: 4.7143e-04\n",
      "Epoch 970/1000\n",
      "524/524 [==============================] - 0s 520us/step - loss: 2.1609e-04 - mse: 2.1609e-04 - val_loss: 4.7159e-04 - val_mse: 4.7159e-04\n",
      "Epoch 971/1000\n",
      "524/524 [==============================] - 0s 546us/step - loss: 2.1769e-04 - mse: 2.1769e-04 - val_loss: 4.6222e-04 - val_mse: 4.6222e-04\n",
      "Epoch 972/1000\n",
      "524/524 [==============================] - 0s 592us/step - loss: 2.1606e-04 - mse: 2.1606e-04 - val_loss: 4.5801e-04 - val_mse: 4.5801e-04\n",
      "Epoch 973/1000\n",
      "524/524 [==============================] - 0s 606us/step - loss: 2.1621e-04 - mse: 2.1621e-04 - val_loss: 4.6857e-04 - val_mse: 4.6857e-04\n",
      "Epoch 974/1000\n",
      "524/524 [==============================] - 0s 689us/step - loss: 2.1516e-04 - mse: 2.1516e-04 - val_loss: 4.4778e-04 - val_mse: 4.4778e-04\n",
      "Epoch 975/1000\n",
      "524/524 [==============================] - 0s 675us/step - loss: 2.1719e-04 - mse: 2.1719e-04 - val_loss: 4.5919e-04 - val_mse: 4.5919e-04\n",
      "Epoch 976/1000\n",
      "524/524 [==============================] - 0s 680us/step - loss: 2.1582e-04 - mse: 2.1582e-04 - val_loss: 4.7614e-04 - val_mse: 4.7614e-04\n",
      "Epoch 977/1000\n",
      "524/524 [==============================] - 0s 618us/step - loss: 2.1636e-04 - mse: 2.1636e-04 - val_loss: 4.6271e-04 - val_mse: 4.6271e-04\n",
      "Epoch 978/1000\n",
      "524/524 [==============================] - 0s 563us/step - loss: 2.1756e-04 - mse: 2.1756e-04 - val_loss: 4.5725e-04 - val_mse: 4.5725e-04\n",
      "Epoch 979/1000\n",
      "524/524 [==============================] - 0s 609us/step - loss: 2.1573e-04 - mse: 2.1573e-04 - val_loss: 4.5310e-04 - val_mse: 4.5310e-04\n",
      "Epoch 980/1000\n",
      "524/524 [==============================] - 0s 573us/step - loss: 2.1629e-04 - mse: 2.1629e-04 - val_loss: 4.5008e-04 - val_mse: 4.5008e-04\n",
      "Epoch 981/1000\n",
      "524/524 [==============================] - 0s 596us/step - loss: 2.1414e-04 - mse: 2.1414e-04 - val_loss: 4.6795e-04 - val_mse: 4.6795e-04\n",
      "Epoch 982/1000\n",
      "524/524 [==============================] - 0s 601us/step - loss: 2.1483e-04 - mse: 2.1483e-04 - val_loss: 4.5332e-04 - val_mse: 4.5332e-04\n",
      "Epoch 983/1000\n",
      "524/524 [==============================] - 0s 496us/step - loss: 2.1369e-04 - mse: 2.1369e-04 - val_loss: 4.5915e-04 - val_mse: 4.5915e-04\n",
      "Epoch 984/1000\n",
      "524/524 [==============================] - 0s 478us/step - loss: 2.1538e-04 - mse: 2.1538e-04 - val_loss: 4.6977e-04 - val_mse: 4.6977e-04\n",
      "Epoch 985/1000\n",
      "524/524 [==============================] - 0s 490us/step - loss: 2.1449e-04 - mse: 2.1449e-04 - val_loss: 4.5630e-04 - val_mse: 4.5630e-04\n",
      "Epoch 986/1000\n",
      "524/524 [==============================] - 0s 533us/step - loss: 2.1464e-04 - mse: 2.1464e-04 - val_loss: 4.5754e-04 - val_mse: 4.5754e-04\n",
      "Epoch 987/1000\n",
      "524/524 [==============================] - 0s 574us/step - loss: 2.1414e-04 - mse: 2.1414e-04 - val_loss: 4.5138e-04 - val_mse: 4.5138e-04\n",
      "Epoch 988/1000\n",
      "524/524 [==============================] - 0s 578us/step - loss: 2.1546e-04 - mse: 2.1546e-04 - val_loss: 4.6417e-04 - val_mse: 4.6417e-04\n",
      "Epoch 989/1000\n",
      "524/524 [==============================] - 0s 588us/step - loss: 2.1355e-04 - mse: 2.1355e-04 - val_loss: 4.4793e-04 - val_mse: 4.4793e-04\n",
      "Epoch 990/1000\n",
      "524/524 [==============================] - 0s 609us/step - loss: 2.1521e-04 - mse: 2.1521e-04 - val_loss: 4.5443e-04 - val_mse: 4.5443e-04\n",
      "Epoch 991/1000\n",
      "524/524 [==============================] - 0s 565us/step - loss: 2.1518e-04 - mse: 2.1518e-04 - val_loss: 4.6995e-04 - val_mse: 4.6995e-04\n",
      "Epoch 992/1000\n",
      "524/524 [==============================] - 0s 593us/step - loss: 2.1369e-04 - mse: 2.1369e-04 - val_loss: 4.4964e-04 - val_mse: 4.4964e-04\n",
      "Epoch 993/1000\n",
      "524/524 [==============================] - 0s 588us/step - loss: 2.1473e-04 - mse: 2.1473e-04 - val_loss: 4.5712e-04 - val_mse: 4.5712e-04\n",
      "Epoch 994/1000\n",
      "524/524 [==============================] - 0s 495us/step - loss: 2.1237e-04 - mse: 2.1237e-04 - val_loss: 4.7470e-04 - val_mse: 4.7470e-04\n",
      "Epoch 995/1000\n",
      "524/524 [==============================] - 0s 489us/step - loss: 2.1422e-04 - mse: 2.1422e-04 - val_loss: 4.6707e-04 - val_mse: 4.6707e-04\n",
      "Epoch 996/1000\n",
      "524/524 [==============================] - 0s 484us/step - loss: 2.1530e-04 - mse: 2.1530e-04 - val_loss: 4.5252e-04 - val_mse: 4.5252e-04\n",
      "Epoch 997/1000\n",
      "524/524 [==============================] - 0s 400us/step - loss: 2.1387e-04 - mse: 2.1387e-04 - val_loss: 4.6447e-04 - val_mse: 4.6447e-04\n",
      "Epoch 998/1000\n",
      "524/524 [==============================] - 0s 287us/step - loss: 2.1400e-04 - mse: 2.1400e-04 - val_loss: 4.6202e-04 - val_mse: 4.6202e-04\n",
      "Epoch 999/1000\n",
      "524/524 [==============================] - 0s 498us/step - loss: 2.1496e-04 - mse: 2.1496e-04 - val_loss: 4.5285e-04 - val_mse: 4.5285e-04\n",
      "Epoch 1000/1000\n",
      "524/524 [==============================] - 0s 508us/step - loss: 2.1315e-04 - mse: 2.1315e-04 - val_loss: 4.7230e-04 - val_mse: 4.7230e-04\n"
     ]
    }
   ],
   "source": [
    "#Actual Model Training\n",
    "ANN, predict_test_scal,predict_test, history=ActualTraining(OTHERTUNEDDICT=OTHERTUNEDDICT,BEST_OPT=BEST_OPT,BEST_ACT_1=BEST_ACT_1,validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1388ea9f-95a1-4eda-bb75-1b663af13999",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fb2c0eae-f666-48cd-aaa3-1e74bb1ac6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003230120997722503\n",
      "0.8967045933082268\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_scal = scaler_Y.transform(Y_test.values.reshape(-1,1)).reshape(-1, get_N_output(Y_test))\n",
    "MSE_R_scal = MSE(Y_test_scal, predict_test_scal)\n",
    "MSE_R = MSE(Y_test.values, predict_test)\n",
    "print(MSE_R_scal)\n",
    "print(MSE_R)\n",
    "plot_history(history)\n",
    "# save the model\n",
    "# ANN.save(r'data_analysis/saved_model/ANN.h5')\n",
    "# pickle.dump(scaler_X, open('scaler_X.pkl','wb'))\n",
    "# pickle.dump(scaler_Y, open('scaler_Y.pkl','wb'))\n",
    "\n",
    "#for i in range(len(predict_test)):\n",
    "#get_plot(Y_test.iloc[i, :], predict_test[i], i)\n",
    "\n",
    "pred_results = []\n",
    "sim_results = []\n",
    "for i in range(len(predict_test)):\n",
    "    for j in range(len(predict_test[0])):\n",
    "        sim_results.append(Y_test.iloc[i, j])\n",
    "        pred_results.append(predict_test[i][j])\n",
    "\n",
    "max_results = max(max(pred_results,sim_results))\n",
    "min_results = min(min(pred_results,sim_results))\n",
    "fig,ax = plt.subplots(figsize=(6,6))\n",
    "ax.plot([min_results, max_results], [min_results, max_results],'b', linewidth=3)\n",
    "ax.scatter(pred_results, sim_results,s=10, c='r')\n",
    "ax.set_xlabel(\"Machine Learning predicted thermo-couple\", fontsize=24)\n",
    "ax.set_ylabel(\"Finite element simulated near field thermo-couple\", fontsize=24)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f6bbdb-8f77-492f-8c3e-4bc11e2f817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MSE_R_scal)\n",
    "print(MSE_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b564627-b1d8-413c-99a1-14f42ef6bfcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
